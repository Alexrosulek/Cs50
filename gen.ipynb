{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Alexrosulek/Cs50/blob/main/gen.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!curl https://ollama.ai/install.sh | sh\n",
        "\n",
        "!echo 'debconf debconf/frontend select Noninteractive' | sudo debconf-set-selections\n",
        "!sudo apt-get update && sudo apt-get install -y cuda-drivers\n",
        "\n",
        "import os\n",
        "\n",
        "# Set LD_LIBRARY_PATH so the system NVIDIA library\n",
        "os.environ.update({'LD_LIBRARY_PATH': '/usr/lib64-nvidia'})\n",
        "!nohup ollama serve &\n",
        "!pip install pyOpenSSL==24.2.1\n",
        "\n",
        "\n",
        "# Pull Ollama Models\n",
        "\n",
        "!ollama pull qwen3:0.6b\n",
        "\n",
        "!ollama pull gemma3:1b\n",
        "!ollama pull gemma3:4b\n",
        "# Install Packages\n",
        "!pip install -q ollama crawl4ai aiohttp pillow beautifulsoup4 wikipedia googlesearch-python playwright nest_asyncio\n",
        "!playwright install chromium\n",
        "!nohup ollama serve &\n",
        "\n"
      ],
      "metadata": {
        "id": "-b9oppEb4cm2",
        "outputId": "c2a29bee-e0b3-4aba-d9ae-d107ea4cd082",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 13281    0 13281    0     0  24680      0 --:--:-- --:--:-- --:--:-- 24685\n",
            ">>> Installing ollama to /usr/local\n",
            ">>> Downloading Linux amd64 bundle\n",
            "######################################################################## 100.0%\n",
            ">>> Creating ollama user...\n",
            ">>> Adding ollama user to video group...\n",
            ">>> Adding current user to ollama group...\n",
            ">>> Creating ollama systemd service...\n",
            "\u001b[1m\u001b[31mWARNING:\u001b[m systemd is not running\n",
            "\u001b[1m\u001b[31mWARNING:\u001b[m Unable to detect NVIDIA/AMD GPU. Install lspci or lshw to automatically detect and install GPU dependencies.\n",
            ">>> The Ollama API is now available at 127.0.0.1:11434.\n",
            ">>> Install complete. Run \"ollama\" from the command line.\n",
            "Get:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Get:2 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n",
            "Get:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [1,683 kB]\n",
            "Get:4 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:6 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Hit:8 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Get:9 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Get:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease [24.6 kB]\n",
            "Get:11 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2,934 kB]\n",
            "Get:12 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,725 kB]\n",
            "Get:13 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy/main amd64 Packages [77.3 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Get:15 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [4,363 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,546 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [4,517 kB]\n",
            "Get:18 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [8,944 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,245 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu jammy-backports/main amd64 Packages [83.2 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu jammy-backports/universe amd64 Packages [35.2 kB]\n",
            "Fetched 30.6 MB in 5s (6,318 kB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  cpp-12 cuda-drivers-575 dctrl-tools dkms fakeroot gcc-12\n",
            "  keyboard-configuration libasan8 libfakeroot libgail-common libgail18\n",
            "  libgcc-12-dev libgtk2.0-0 libgtk2.0-bin libgtk2.0-common libgudev-1.0-0\n",
            "  libjansson4 liblocale-gettext-perl libnvidia-cfg1-575 libnvidia-common-575\n",
            "  libnvidia-compute-575 libnvidia-decode-575 libnvidia-encode-575\n",
            "  libnvidia-extra-575 libnvidia-fbc1-575 libnvidia-gl-575\n",
            "  libnvidia-gpucomp-575 librsvg2-common libtsan2 libudev1 libxcvt0\n",
            "  nvidia-compute-utils-575 nvidia-dkms-575 nvidia-driver-575\n",
            "  nvidia-firmware-575-575.51.03 nvidia-kernel-common-575\n",
            "  nvidia-kernel-source-575 nvidia-modprobe nvidia-settings nvidia-utils-575\n",
            "  python3-xkit screen-resolution-extra switcheroo-control systemd-hwe-hwdb\n",
            "  udev xcvt xserver-xorg-core xserver-xorg-video-nvidia-575\n",
            "Suggested packages:\n",
            "  gcc-12-locales cpp-12-doc debtags menu gcc-12-multilib gcc-12-doc gvfs\n",
            "  xfonts-100dpi | xfonts-75dpi xfonts-scalable\n",
            "Recommended packages:\n",
            "  libnvidia-compute-575:i386 libnvidia-decode-575:i386\n",
            "  libnvidia-encode-575:i386 libnvidia-fbc1-575:i386 libnvidia-gl-575:i386\n",
            "The following NEW packages will be installed:\n",
            "  cpp-12 cuda-drivers cuda-drivers-575 dctrl-tools dkms fakeroot gcc-12\n",
            "  keyboard-configuration libasan8 libfakeroot libgail-common libgail18\n",
            "  libgcc-12-dev libgtk2.0-0 libgtk2.0-bin libgtk2.0-common libgudev-1.0-0\n",
            "  libjansson4 liblocale-gettext-perl libnvidia-cfg1-575 libnvidia-common-575\n",
            "  libnvidia-compute-575 libnvidia-decode-575 libnvidia-encode-575\n",
            "  libnvidia-extra-575 libnvidia-fbc1-575 libnvidia-gl-575\n",
            "  libnvidia-gpucomp-575 librsvg2-common libtsan2 libxcvt0\n",
            "  nvidia-compute-utils-575 nvidia-dkms-575 nvidia-driver-575\n",
            "  nvidia-firmware-575-575.51.03 nvidia-kernel-common-575\n",
            "  nvidia-kernel-source-575 nvidia-modprobe nvidia-settings nvidia-utils-575\n",
            "  python3-xkit screen-resolution-extra switcheroo-control systemd-hwe-hwdb\n",
            "  udev xcvt xserver-xorg-core xserver-xorg-video-nvidia-575\n",
            "The following packages will be upgraded:\n",
            "  libudev1\n",
            "1 upgraded, 48 newly installed, 0 to remove and 88 not upgraded.\n",
            "Need to get 418 MB of archives.\n",
            "After this operation, 1,292 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 liblocale-gettext-perl amd64 1.07-4build3 [17.1 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 keyboard-configuration all 1.205ubuntu3 [206 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 cpp-12 amd64 12.3.0-1ubuntu1~22.04 [10.8 MB]\n",
            "Get:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  libnvidia-decode-575 575.51.03-0ubuntu1 [2,556 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libasan8 amd64 12.3.0-1ubuntu1~22.04 [2,442 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libtsan2 amd64 12.3.0-1ubuntu1~22.04 [2,477 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgcc-12-dev amd64 12.3.0-1ubuntu1~22.04 [2,618 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 gcc-12 amd64 12.3.0-1ubuntu1~22.04 [21.7 MB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy/main amd64 dctrl-tools amd64 2.24-3build2 [66.9 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 dkms all 2.8.7-2ubuntu2.2 [70.1 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libudev1 amd64 249.11-0ubuntu3.15 [76.6 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 udev amd64 249.11-0ubuntu3.15 [1,557 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy/main amd64 libjansson4 amd64 2.13.1-1.1build3 [32.4 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxcvt0 amd64 0.1.1-3 [5,494 B]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 xserver-xorg-core amd64 2:21.1.4-2ubuntu1.7~22.04.14 [1,478 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy/main amd64 libfakeroot amd64 1.28-1ubuntu1 [31.5 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy/main amd64 fakeroot amd64 1.28-1ubuntu1 [60.4 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgtk2.0-common all 2.24.33-2ubuntu2.1 [125 kB]\n",
            "Get:19 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  libnvidia-gpucomp-575 575.51.03-0ubuntu1 [17.8 MB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgtk2.0-0 amd64 2.24.33-2ubuntu2.1 [2,038 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgail18 amd64 2.24.33-2ubuntu2.1 [15.9 kB]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgail-common amd64 2.24.33-2ubuntu2.1 [132 kB]\n",
            "Get:23 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgtk2.0-bin amd64 2.24.33-2ubuntu2.1 [7,936 B]\n",
            "Get:24 http://archive.ubuntu.com/ubuntu jammy/main amd64 libgudev-1.0-0 amd64 1:237-2build1 [16.3 kB]\n",
            "Get:25 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 librsvg2-common amd64 2.52.5+dfsg-3ubuntu0.2 [17.7 kB]\n",
            "Get:26 http://archive.ubuntu.com/ubuntu jammy/main amd64 python3-xkit all 0.5.0ubuntu5 [18.5 kB]\n",
            "Get:27 http://archive.ubuntu.com/ubuntu jammy/main amd64 screen-resolution-extra all 0.18.2 [4,396 B]\n",
            "Get:28 http://archive.ubuntu.com/ubuntu jammy/main amd64 switcheroo-control amd64 2.4-3build2 [16.5 kB]\n",
            "Get:29 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 systemd-hwe-hwdb all 249.11.5 [3,228 B]\n",
            "Get:30 http://archive.ubuntu.com/ubuntu jammy/main amd64 xcvt amd64 0.1.1-3 [7,140 B]\n",
            "Get:31 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  libnvidia-compute-575 575.51.03-0ubuntu1 [54.2 MB]\n",
            "Get:32 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  libnvidia-common-575 575.51.03-0ubuntu1 [15.9 kB]\n",
            "Get:33 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  libnvidia-gl-575 575.51.03-0ubuntu1 [132 MB]\n",
            "Get:34 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  nvidia-kernel-source-575 575.51.03-0ubuntu1 [85.5 MB]\n",
            "Get:35 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  nvidia-firmware-575-575.51.03 575.51.03-0ubuntu1 [74.7 MB]\n",
            "Get:36 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  nvidia-modprobe 575.51.03-0ubuntu1 [14.9 kB]\n",
            "Get:37 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  nvidia-kernel-common-575 575.51.03-0ubuntu1 [1,245 kB]\n",
            "Get:38 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  nvidia-dkms-575 575.51.03-0ubuntu1 [14.9 kB]\n",
            "Get:39 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  libnvidia-extra-575 575.51.03-0ubuntu1 [73.2 kB]\n",
            "Get:40 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  nvidia-compute-utils-575 575.51.03-0ubuntu1 [109 kB]\n",
            "Get:41 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  libnvidia-encode-575 575.51.03-0ubuntu1 [105 kB]\n",
            "Get:42 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  nvidia-utils-575 575.51.03-0ubuntu1 [534 kB]\n",
            "Get:43 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  libnvidia-cfg1-575 575.51.03-0ubuntu1 [146 kB]\n",
            "Get:44 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  xserver-xorg-video-nvidia-575 575.51.03-0ubuntu1 [1,696 kB]\n",
            "Get:45 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  libnvidia-fbc1-575 575.51.03-0ubuntu1 [98.1 kB]\n",
            "Get:46 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  nvidia-driver-575 575.51.03-0ubuntu1 [497 kB]\n",
            "Get:47 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  cuda-drivers-575 575.51.03-0ubuntu1 [2,538 B]\n",
            "Get:48 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  cuda-drivers 575.51.03-0ubuntu1 [2,490 B]\n",
            "Get:49 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  nvidia-settings 575.51.03-0ubuntu1 [957 kB]\n",
            "Fetched 418 MB in 50s (8,349 kB/s)\n",
            "Extracting templates from packages: 100%\n",
            "Preconfiguring packages ...\n",
            "Selecting previously unselected package liblocale-gettext-perl.\n",
            "(Reading database ... 126102 files and directories currently installed.)\n",
            "Preparing to unpack .../0-liblocale-gettext-perl_1.07-4build3_amd64.deb ...\n",
            "Unpacking liblocale-gettext-perl (1.07-4build3) ...\n",
            "Selecting previously unselected package keyboard-configuration.\n",
            "Preparing to unpack .../1-keyboard-configuration_1.205ubuntu3_all.deb ...\n",
            "Unpacking keyboard-configuration (1.205ubuntu3) ...\n",
            "Selecting previously unselected package cpp-12.\n",
            "Preparing to unpack .../2-cpp-12_12.3.0-1ubuntu1~22.04_amd64.deb ...\n",
            "Unpacking cpp-12 (12.3.0-1ubuntu1~22.04) ...\n",
            "Selecting previously unselected package libasan8:amd64.\n",
            "Preparing to unpack .../3-libasan8_12.3.0-1ubuntu1~22.04_amd64.deb ...\n",
            "Unpacking libasan8:amd64 (12.3.0-1ubuntu1~22.04) ...\n",
            "Selecting previously unselected package libtsan2:amd64.\n",
            "Preparing to unpack .../4-libtsan2_12.3.0-1ubuntu1~22.04_amd64.deb ...\n",
            "Unpacking libtsan2:amd64 (12.3.0-1ubuntu1~22.04) ...\n",
            "Selecting previously unselected package libgcc-12-dev:amd64.\n",
            "Preparing to unpack .../5-libgcc-12-dev_12.3.0-1ubuntu1~22.04_amd64.deb ...\n",
            "Unpacking libgcc-12-dev:amd64 (12.3.0-1ubuntu1~22.04) ...\n",
            "Selecting previously unselected package gcc-12.\n",
            "Preparing to unpack .../6-gcc-12_12.3.0-1ubuntu1~22.04_amd64.deb ...\n",
            "Unpacking gcc-12 (12.3.0-1ubuntu1~22.04) ...\n",
            "Selecting previously unselected package dctrl-tools.\n",
            "Preparing to unpack .../7-dctrl-tools_2.24-3build2_amd64.deb ...\n",
            "Unpacking dctrl-tools (2.24-3build2) ...\n",
            "Selecting previously unselected package dkms.\n",
            "Preparing to unpack .../8-dkms_2.8.7-2ubuntu2.2_all.deb ...\n",
            "Unpacking dkms (2.8.7-2ubuntu2.2) ...\n",
            "Preparing to unpack .../9-libudev1_249.11-0ubuntu3.15_amd64.deb ...\n",
            "Unpacking libudev1:amd64 (249.11-0ubuntu3.15) over (249.11-0ubuntu3.12) ...\n",
            "Setting up libudev1:amd64 (249.11-0ubuntu3.15) ...\n",
            "Selecting previously unselected package udev.\n",
            "(Reading database ... 126462 files and directories currently installed.)\n",
            "Preparing to unpack .../00-udev_249.11-0ubuntu3.15_amd64.deb ...\n",
            "Unpacking udev (249.11-0ubuntu3.15) ...\n",
            "Selecting previously unselected package libjansson4:amd64.\n",
            "Preparing to unpack .../01-libjansson4_2.13.1-1.1build3_amd64.deb ...\n",
            "Unpacking libjansson4:amd64 (2.13.1-1.1build3) ...\n",
            "Selecting previously unselected package libnvidia-decode-575:amd64.\n",
            "Preparing to unpack .../02-libnvidia-decode-575_575.51.03-0ubuntu1_amd64.deb ...\n",
            "Unpacking libnvidia-decode-575:amd64 (575.51.03-0ubuntu1) ...\n",
            "Selecting previously unselected package libnvidia-gpucomp-575:amd64.\n",
            "Preparing to unpack .../03-libnvidia-gpucomp-575_575.51.03-0ubuntu1_amd64.deb ...\n",
            "Unpacking libnvidia-gpucomp-575:amd64 (575.51.03-0ubuntu1) ...\n",
            "Selecting previously unselected package libnvidia-compute-575:amd64.\n",
            "Preparing to unpack .../04-libnvidia-compute-575_575.51.03-0ubuntu1_amd64.deb ...\n",
            "Unpacking libnvidia-compute-575:amd64 (575.51.03-0ubuntu1) ...\n",
            "Selecting previously unselected package libnvidia-common-575.\n",
            "Preparing to unpack .../05-libnvidia-common-575_575.51.03-0ubuntu1_all.deb ...\n",
            "Unpacking libnvidia-common-575 (575.51.03-0ubuntu1) ...\n",
            "Selecting previously unselected package libnvidia-gl-575:amd64.\n",
            "Preparing to unpack .../06-libnvidia-gl-575_575.51.03-0ubuntu1_amd64.deb ...\n",
            "dpkg-query: no packages found matching libnvidia-gl-535\n",
            "Unpacking libnvidia-gl-575:amd64 (575.51.03-0ubuntu1) ...\n",
            "Selecting previously unselected package nvidia-kernel-source-575.\n",
            "Preparing to unpack .../07-nvidia-kernel-source-575_575.51.03-0ubuntu1_amd64.deb ...\n",
            "Unpacking nvidia-kernel-source-575 (575.51.03-0ubuntu1) ...\n",
            "Selecting previously unselected package nvidia-firmware-575-575.51.03.\n",
            "Preparing to unpack .../08-nvidia-firmware-575-575.51.03_575.51.03-0ubuntu1_amd64.deb ...\n",
            "Unpacking nvidia-firmware-575-575.51.03 (575.51.03-0ubuntu1) ...\n",
            "Selecting previously unselected package nvidia-modprobe.\n",
            "Preparing to unpack .../09-nvidia-modprobe_575.51.03-0ubuntu1_amd64.deb ...\n",
            "Unpacking nvidia-modprobe (575.51.03-0ubuntu1) ...\n",
            "Selecting previously unselected package nvidia-kernel-common-575.\n",
            "Preparing to unpack .../10-nvidia-kernel-common-575_575.51.03-0ubuntu1_amd64.deb ...\n",
            "Unpacking nvidia-kernel-common-575 (575.51.03-0ubuntu1) ...\n",
            "Selecting previously unselected package nvidia-dkms-575.\n",
            "Preparing to unpack .../11-nvidia-dkms-575_575.51.03-0ubuntu1_amd64.deb ...\n",
            "Unpacking nvidia-dkms-575 (575.51.03-0ubuntu1) ...\n",
            "Selecting previously unselected package libnvidia-extra-575:amd64.\n",
            "Preparing to unpack .../12-libnvidia-extra-575_575.51.03-0ubuntu1_amd64.deb ...\n",
            "Unpacking libnvidia-extra-575:amd64 (575.51.03-0ubuntu1) ...\n",
            "Selecting previously unselected package nvidia-compute-utils-575.\n",
            "Preparing to unpack .../13-nvidia-compute-utils-575_575.51.03-0ubuntu1_amd64.deb ...\n",
            "Unpacking nvidia-compute-utils-575 (575.51.03-0ubuntu1) ...\n",
            "Selecting previously unselected package libnvidia-encode-575:amd64.\n",
            "Preparing to unpack .../14-libnvidia-encode-575_575.51.03-0ubuntu1_amd64.deb ...\n",
            "Unpacking libnvidia-encode-575:amd64 (575.51.03-0ubuntu1) ...\n",
            "Selecting previously unselected package nvidia-utils-575.\n",
            "Preparing to unpack .../15-nvidia-utils-575_575.51.03-0ubuntu1_amd64.deb ...\n",
            "Unpacking nvidia-utils-575 (575.51.03-0ubuntu1) ...\n",
            "Selecting previously unselected package libnvidia-cfg1-575:amd64.\n",
            "Preparing to unpack .../16-libnvidia-cfg1-575_575.51.03-0ubuntu1_amd64.deb ...\n",
            "Unpacking libnvidia-cfg1-575:amd64 (575.51.03-0ubuntu1) ...\n",
            "Selecting previously unselected package libxcvt0:amd64.\n",
            "Preparing to unpack .../17-libxcvt0_0.1.1-3_amd64.deb ...\n",
            "Unpacking libxcvt0:amd64 (0.1.1-3) ...\n",
            "Selecting previously unselected package xserver-xorg-core.\n",
            "Preparing to unpack .../18-xserver-xorg-core_2%3a21.1.4-2ubuntu1.7~22.04.14_amd64.deb ...\n",
            "Unpacking xserver-xorg-core (2:21.1.4-2ubuntu1.7~22.04.14) ...\n",
            "Selecting previously unselected package xserver-xorg-video-nvidia-575.\n",
            "Preparing to unpack .../19-xserver-xorg-video-nvidia-575_575.51.03-0ubuntu1_amd64.deb ...\n",
            "Unpacking xserver-xorg-video-nvidia-575 (575.51.03-0ubuntu1) ...\n",
            "Selecting previously unselected package libnvidia-fbc1-575:amd64.\n",
            "Preparing to unpack .../20-libnvidia-fbc1-575_575.51.03-0ubuntu1_amd64.deb ...\n",
            "Unpacking libnvidia-fbc1-575:amd64 (575.51.03-0ubuntu1) ...\n",
            "Selecting previously unselected package nvidia-driver-575.\n",
            "Preparing to unpack .../21-nvidia-driver-575_575.51.03-0ubuntu1_amd64.deb ...\n",
            "Unpacking nvidia-driver-575 (575.51.03-0ubuntu1) ...\n",
            "Selecting previously unselected package cuda-drivers-575.\n",
            "Preparing to unpack .../22-cuda-drivers-575_575.51.03-0ubuntu1_amd64.deb ...\n",
            "Unpacking cuda-drivers-575 (575.51.03-0ubuntu1) ...\n",
            "Selecting previously unselected package cuda-drivers.\n",
            "Preparing to unpack .../23-cuda-drivers_575.51.03-0ubuntu1_amd64.deb ...\n",
            "Unpacking cuda-drivers (575.51.03-0ubuntu1) ...\n",
            "Selecting previously unselected package libfakeroot:amd64.\n",
            "Preparing to unpack .../24-libfakeroot_1.28-1ubuntu1_amd64.deb ...\n",
            "Unpacking libfakeroot:amd64 (1.28-1ubuntu1) ...\n",
            "Selecting previously unselected package fakeroot.\n",
            "Preparing to unpack .../25-fakeroot_1.28-1ubuntu1_amd64.deb ...\n",
            "Unpacking fakeroot (1.28-1ubuntu1) ...\n",
            "Selecting previously unselected package libgtk2.0-common.\n",
            "Preparing to unpack .../26-libgtk2.0-common_2.24.33-2ubuntu2.1_all.deb ...\n",
            "Unpacking libgtk2.0-common (2.24.33-2ubuntu2.1) ...\n",
            "Selecting previously unselected package libgtk2.0-0:amd64.\n",
            "Preparing to unpack .../27-libgtk2.0-0_2.24.33-2ubuntu2.1_amd64.deb ...\n",
            "Unpacking libgtk2.0-0:amd64 (2.24.33-2ubuntu2.1) ...\n",
            "Selecting previously unselected package libgail18:amd64.\n",
            "Preparing to unpack .../28-libgail18_2.24.33-2ubuntu2.1_amd64.deb ...\n",
            "Unpacking libgail18:amd64 (2.24.33-2ubuntu2.1) ...\n",
            "Selecting previously unselected package libgail-common:amd64.\n",
            "Preparing to unpack .../29-libgail-common_2.24.33-2ubuntu2.1_amd64.deb ...\n",
            "Unpacking libgail-common:amd64 (2.24.33-2ubuntu2.1) ...\n",
            "Selecting previously unselected package libgtk2.0-bin.\n",
            "Preparing to unpack .../30-libgtk2.0-bin_2.24.33-2ubuntu2.1_amd64.deb ...\n",
            "Unpacking libgtk2.0-bin (2.24.33-2ubuntu2.1) ...\n",
            "Selecting previously unselected package libgudev-1.0-0:amd64.\n",
            "Preparing to unpack .../31-libgudev-1.0-0_1%3a237-2build1_amd64.deb ...\n",
            "Unpacking libgudev-1.0-0:amd64 (1:237-2build1) ...\n",
            "Selecting previously unselected package librsvg2-common:amd64.\n",
            "Preparing to unpack .../32-librsvg2-common_2.52.5+dfsg-3ubuntu0.2_amd64.deb ...\n",
            "Unpacking librsvg2-common:amd64 (2.52.5+dfsg-3ubuntu0.2) ...\n",
            "Selecting previously unselected package python3-xkit.\n",
            "Preparing to unpack .../33-python3-xkit_0.5.0ubuntu5_all.deb ...\n",
            "Unpacking python3-xkit (0.5.0ubuntu5) ...\n",
            "Selecting previously unselected package screen-resolution-extra.\n",
            "Preparing to unpack .../34-screen-resolution-extra_0.18.2_all.deb ...\n",
            "Unpacking screen-resolution-extra (0.18.2) ...\n",
            "Selecting previously unselected package nvidia-settings.\n",
            "Preparing to unpack .../35-nvidia-settings_575.51.03-0ubuntu1_amd64.deb ...\n",
            "Unpacking nvidia-settings (575.51.03-0ubuntu1) ...\n",
            "Selecting previously unselected package switcheroo-control.\n",
            "Preparing to unpack .../36-switcheroo-control_2.4-3build2_amd64.deb ...\n",
            "Unpacking switcheroo-control (2.4-3build2) ...\n",
            "Selecting previously unselected package systemd-hwe-hwdb.\n",
            "Preparing to unpack .../37-systemd-hwe-hwdb_249.11.5_all.deb ...\n",
            "Unpacking systemd-hwe-hwdb (249.11.5) ...\n",
            "Selecting previously unselected package xcvt.\n",
            "Preparing to unpack .../38-xcvt_0.1.1-3_amd64.deb ...\n",
            "Unpacking xcvt (0.1.1-3) ...\n",
            "Setting up cpp-12 (12.3.0-1ubuntu1~22.04) ...\n",
            "Setting up libnvidia-gpucomp-575:amd64 (575.51.03-0ubuntu1) ...\n",
            "Setting up libfakeroot:amd64 (1.28-1ubuntu1) ...\n",
            "Setting up libjansson4:amd64 (2.13.1-1.1build3) ...\n",
            "Setting up nvidia-modprobe (575.51.03-0ubuntu1) ...\n",
            "Setting up fakeroot (1.28-1ubuntu1) ...\n",
            "update-alternatives: using /usr/bin/fakeroot-sysv to provide /usr/bin/fakeroot (fakeroot) in auto mode\n",
            "Setting up nvidia-kernel-source-575 (575.51.03-0ubuntu1) ...\n",
            "Setting up libnvidia-fbc1-575:amd64 (575.51.03-0ubuntu1) ...\n",
            "Setting up udev (249.11-0ubuntu3.15) ...\n",
            "invoke-rc.d: could not determine current runlevel\n",
            "invoke-rc.d: policy-rc.d denied execution of start.\n",
            "Setting up librsvg2-common:amd64 (2.52.5+dfsg-3ubuntu0.2) ...\n",
            "Setting up systemd-hwe-hwdb (249.11.5) ...\n",
            "Setting up nvidia-firmware-575-575.51.03 (575.51.03-0ubuntu1) ...\n",
            "Setting up libasan8:amd64 (12.3.0-1ubuntu1~22.04) ...\n",
            "Setting up libxcvt0:amd64 (0.1.1-3) ...\n",
            "Setting up libnvidia-common-575 (575.51.03-0ubuntu1) ...\n",
            "Setting up libgtk2.0-common (2.24.33-2ubuntu2.1) ...\n",
            "Setting up libtsan2:amd64 (12.3.0-1ubuntu1~22.04) ...\n",
            "Setting up libnvidia-extra-575:amd64 (575.51.03-0ubuntu1) ...\n",
            "Setting up python3-xkit (0.5.0ubuntu5) ...\n",
            "Setting up libnvidia-cfg1-575:amd64 (575.51.03-0ubuntu1) ...\n",
            "Setting up liblocale-gettext-perl (1.07-4build3) ...\n",
            "Setting up libgudev-1.0-0:amd64 (1:237-2build1) ...\n",
            "Setting up dctrl-tools (2.24-3build2) ...\n",
            "Setting up libgtk2.0-0:amd64 (2.24.33-2ubuntu2.1) ...\n",
            "Setting up xcvt (0.1.1-3) ...\n",
            "Setting up libgcc-12-dev:amd64 (12.3.0-1ubuntu1~22.04) ...\n",
            "Setting up nvidia-kernel-common-575 (575.51.03-0ubuntu1) ...\n",
            "Setting up screen-resolution-extra (0.18.2) ...\n",
            "Setting up libgail18:amd64 (2.24.33-2ubuntu2.1) ...\n",
            "Setting up libgtk2.0-bin (2.24.33-2ubuntu2.1) ...\n",
            "Setting up switcheroo-control (2.4-3build2) ...\n",
            "Created symlink /etc/systemd/system/graphical.target.wants/switcheroo-control.service → /lib/systemd/system/switcheroo-control.service.\n",
            "Setting up nvidia-settings (575.51.03-0ubuntu1) ...\n",
            "Setting up keyboard-configuration (1.205ubuntu3) ...\n",
            "Your console font configuration will be updated the next time your system\n",
            "boots. If you want to update it now, run 'setupcon' from a virtual console.\n",
            "Setting up libgail-common:amd64 (2.24.33-2ubuntu2.1) ...\n",
            "Setting up xserver-xorg-core (2:21.1.4-2ubuntu1.7~22.04.14) ...\n",
            "Setting up xserver-xorg-video-nvidia-575 (575.51.03-0ubuntu1) ...\n",
            "Setting up gcc-12 (12.3.0-1ubuntu1~22.04) ...\n",
            "Setting up dkms (2.8.7-2ubuntu2.2) ...\n",
            "Setting up nvidia-dkms-575 (575.51.03-0ubuntu1) ...\n",
            "Loading new nvidia-575.51.03 DKMS files...\n",
            "It is likely that 6.1.123+ belongs to a chroot's host\n",
            "Building for 5.15.0-139-generic\n",
            "Building for architecture x86_64\n",
            "Building initial module for 5.15.0-139-generic\n",
            "Done.\n",
            "\n",
            "nvidia.ko:\n",
            "Running module version sanity check.\n",
            " - Original module\n",
            "   - No original module exists within this kernel\n",
            " - Installation\n",
            "   - Installing to /lib/modules/5.15.0-139-generic/updates/dkms/\n",
            "\n",
            "nvidia-modeset.ko:\n",
            "Running module version sanity check.\n",
            " - Original module\n",
            "   - No original module exists within this kernel\n",
            " - Installation\n",
            "   - Installing to /lib/modules/5.15.0-139-generic/updates/dkms/\n",
            "\n",
            "nvidia-drm.ko:\n",
            "Running module version sanity check.\n",
            " - Original module\n",
            "   - No original module exists within this kernel\n",
            " - Installation\n",
            "   - Installing to /lib/modules/5.15.0-139-generic/updates/dkms/\n",
            "\n",
            "nvidia-uvm.ko:\n",
            "Running module version sanity check.\n",
            " - Original module\n",
            "   - No original module exists within this kernel\n",
            " - Installation\n",
            "   - Installing to /lib/modules/5.15.0-139-generic/updates/dkms/\n",
            "\n",
            "nvidia-peermem.ko:\n",
            "Running module version sanity check.\n",
            " - Original module\n",
            "   - No original module exists within this kernel\n",
            " - Installation\n",
            "   - Installing to /lib/modules/5.15.0-139-generic/updates/dkms/\n",
            "\n",
            "depmod...\n",
            "Setting up libnvidia-decode-575:amd64 (575.51.03-0ubuntu1) ...\n",
            "Setting up libnvidia-compute-575:amd64 (575.51.03-0ubuntu1) ...\n",
            "Setting up libnvidia-encode-575:amd64 (575.51.03-0ubuntu1) ...\n",
            "Setting up nvidia-utils-575 (575.51.03-0ubuntu1) ...\n",
            "Setting up nvidia-compute-utils-575 (575.51.03-0ubuntu1) ...\n",
            "Setting up libnvidia-gl-575:amd64 (575.51.03-0ubuntu1) ...\n",
            "Setting up nvidia-driver-575 (575.51.03-0ubuntu1) ...\n",
            "Setting up cuda-drivers-575 (575.51.03-0ubuntu1) ...\n",
            "Setting up cuda-drivers (575.51.03-0ubuntu1) ...\n",
            "Processing triggers for libgdk-pixbuf-2.0-0:amd64 (2.42.8+dfsg-1ubuntu0.3) ...\n",
            "Processing triggers for mailcap (3.70+nmu1ubuntu1) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.8) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for dbus (1.12.20-2ubuntu4.1) ...\n",
            "nohup: appending output to 'nohup.out'\n",
            "Requirement already satisfied: pyOpenSSL==24.2.1 in /usr/local/lib/python3.11/dist-packages (24.2.1)\n",
            "Requirement already satisfied: cryptography<44,>=41.0.5 in /usr/local/lib/python3.11/dist-packages (from pyOpenSSL==24.2.1) (43.0.3)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography<44,>=41.0.5->pyOpenSSL==24.2.1) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography<44,>=41.0.5->pyOpenSSL==24.2.1) (2.22)\n",
            "\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\n",
            "\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\n",
            "\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m292.8/292.8 kB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m117.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.1/45.1 MB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m104.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m161.7/161.7 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.9/7.9 MB\u001b[0m \u001b[31m129.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.0/278.0 kB\u001b[0m \u001b[31m27.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.8/56.8 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.0/93.0 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m647.0/647.0 kB\u001b[0m \u001b[31m49.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for wikipedia (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "pydrive2 1.21.3 requires pyOpenSSL<=24.2.1,>=19.1.0, but you have pyopenssl 25.1.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mDownloading Chromium 136.0.7103.25 (playwright build v1169)\u001b[2m from https://cdn.playwright.dev/dbazure/download/playwright/builds/chromium/1169/chromium-linux.zip\u001b[22m\n",
            "\u001b[1G167.7 MiB [] 0% 0.0s\u001b[0K\u001b[1G167.7 MiB [] 0% 5.9s\u001b[0K\u001b[1G167.7 MiB [] 0% 3.8s\u001b[0K\u001b[1G167.7 MiB [] 1% 3.5s\u001b[0K\u001b[1G167.7 MiB [] 1% 3.4s\u001b[0K\u001b[1G167.7 MiB [] 2% 3.2s\u001b[0K\u001b[1G167.7 MiB [] 3% 3.1s\u001b[0K\u001b[1G167.7 MiB [] 3% 3.0s\u001b[0K\u001b[1G167.7 MiB [] 4% 2.7s\u001b[0K\u001b[1G167.7 MiB [] 5% 2.6s\u001b[0K\u001b[1G167.7 MiB [] 6% 2.8s\u001b[0K\u001b[1G167.7 MiB [] 6% 2.9s\u001b[0K\u001b[1G167.7 MiB [] 7% 2.7s\u001b[0K\u001b[1G167.7 MiB [] 8% 2.6s\u001b[0K\u001b[1G167.7 MiB [] 9% 2.6s\u001b[0K\u001b[1G167.7 MiB [] 10% 2.6s\u001b[0K\u001b[1G167.7 MiB [] 11% 2.5s\u001b[0K\u001b[1G167.7 MiB [] 11% 2.6s\u001b[0K\u001b[1G167.7 MiB [] 12% 2.5s\u001b[0K\u001b[1G167.7 MiB [] 13% 2.5s\u001b[0K\u001b[1G167.7 MiB [] 14% 2.4s\u001b[0K\u001b[1G167.7 MiB [] 15% 2.3s\u001b[0K\u001b[1G167.7 MiB [] 16% 2.2s\u001b[0K\u001b[1G167.7 MiB [] 17% 2.2s\u001b[0K\u001b[1G167.7 MiB [] 17% 2.3s\u001b[0K\u001b[1G167.7 MiB [] 18% 2.4s\u001b[0K\u001b[1G167.7 MiB [] 19% 2.4s\u001b[0K\u001b[1G167.7 MiB [] 20% 2.3s\u001b[0K\u001b[1G167.7 MiB [] 21% 2.3s\u001b[0K\u001b[1G167.7 MiB [] 21% 2.2s\u001b[0K\u001b[1G167.7 MiB [] 22% 2.2s\u001b[0K\u001b[1G167.7 MiB [] 22% 2.3s\u001b[0K\u001b[1G167.7 MiB [] 23% 2.2s\u001b[0K\u001b[1G167.7 MiB [] 24% 2.2s\u001b[0K\u001b[1G167.7 MiB [] 25% 2.1s\u001b[0K\u001b[1G167.7 MiB [] 26% 2.1s\u001b[0K\u001b[1G167.7 MiB [] 27% 2.0s\u001b[0K\u001b[1G167.7 MiB [] 28% 2.0s\u001b[0K\u001b[1G167.7 MiB [] 29% 1.9s\u001b[0K\u001b[1G167.7 MiB [] 30% 1.9s\u001b[0K\u001b[1G167.7 MiB [] 31% 1.8s\u001b[0K\u001b[1G167.7 MiB [] 32% 1.8s\u001b[0K\u001b[1G167.7 MiB [] 33% 1.8s\u001b[0K\u001b[1G167.7 MiB [] 34% 1.7s\u001b[0K\u001b[1G167.7 MiB [] 35% 1.6s\u001b[0K\u001b[1G167.7 MiB [] 36% 1.6s\u001b[0K\u001b[1G167.7 MiB [] 37% 1.6s\u001b[0K\u001b[1G167.7 MiB [] 38% 1.6s\u001b[0K\u001b[1G167.7 MiB [] 40% 1.5s\u001b[0K\u001b[1G167.7 MiB [] 41% 1.4s\u001b[0K\u001b[1G167.7 MiB [] 42% 1.4s\u001b[0K\u001b[1G167.7 MiB [] 43% 1.3s\u001b[0K\u001b[1G167.7 MiB [] 44% 1.3s\u001b[0K\u001b[1G167.7 MiB [] 46% 1.3s\u001b[0K\u001b[1G167.7 MiB [] 47% 1.2s\u001b[0K\u001b[1G167.7 MiB [] 48% 1.2s\u001b[0K\u001b[1G167.7 MiB [] 49% 1.2s\u001b[0K\u001b[1G167.7 MiB [] 50% 1.1s\u001b[0K\u001b[1G167.7 MiB [] 52% 1.1s\u001b[0K\u001b[1G167.7 MiB [] 53% 1.0s\u001b[0K\u001b[1G167.7 MiB [] 54% 1.0s\u001b[0K\u001b[1G167.7 MiB [] 55% 1.0s\u001b[0K\u001b[1G167.7 MiB [] 56% 1.0s\u001b[0K\u001b[1G167.7 MiB [] 57% 0.9s\u001b[0K\u001b[1G167.7 MiB [] 58% 0.9s\u001b[0K\u001b[1G167.7 MiB [] 60% 0.9s\u001b[0K\u001b[1G167.7 MiB [] 61% 0.8s\u001b[0K\u001b[1G167.7 MiB [] 62% 0.8s\u001b[0K\u001b[1G167.7 MiB [] 63% 0.8s\u001b[0K\u001b[1G167.7 MiB [] 65% 0.7s\u001b[0K\u001b[1G167.7 MiB [] 66% 0.7s\u001b[0K\u001b[1G167.7 MiB [] 67% 0.7s\u001b[0K\u001b[1G167.7 MiB [] 68% 0.6s\u001b[0K\u001b[1G167.7 MiB [] 69% 0.6s\u001b[0K\u001b[1G167.7 MiB [] 70% 0.6s\u001b[0K\u001b[1G167.7 MiB [] 71% 0.6s\u001b[0K\u001b[1G167.7 MiB [] 73% 0.5s\u001b[0K\u001b[1G167.7 MiB [] 74% 0.5s\u001b[0K\u001b[1G167.7 MiB [] 75% 0.5s\u001b[0K\u001b[1G167.7 MiB [] 76% 0.5s\u001b[0K\u001b[1G167.7 MiB [] 78% 0.4s\u001b[0K\u001b[1G167.7 MiB [] 79% 0.4s\u001b[0K\u001b[1G167.7 MiB [] 80% 0.4s\u001b[0K\u001b[1G167.7 MiB [] 81% 0.4s\u001b[0K\u001b[1G167.7 MiB [] 83% 0.3s\u001b[0K\u001b[1G167.7 MiB [] 84% 0.3s\u001b[0K\u001b[1G167.7 MiB [] 85% 0.3s\u001b[0K\u001b[1G167.7 MiB [] 86% 0.3s\u001b[0K\u001b[1G167.7 MiB [] 87% 0.2s\u001b[0K\u001b[1G167.7 MiB [] 88% 0.2s\u001b[0K\u001b[1G167.7 MiB [] 89% 0.2s\u001b[0K\u001b[1G167.7 MiB [] 90% 0.2s\u001b[0K\u001b[1G167.7 MiB [] 91% 0.2s\u001b[0K\u001b[1G167.7 MiB [] 92% 0.2s\u001b[0K\u001b[1G167.7 MiB [] 93% 0.1s\u001b[0K\u001b[1G167.7 MiB [] 94% 0.1s\u001b[0K\u001b[1G167.7 MiB [] 95% 0.1s\u001b[0K\u001b[1G167.7 MiB [] 96% 0.1s\u001b[0K\u001b[1G167.7 MiB [] 98% 0.0s\u001b[0K\u001b[1G167.7 MiB [] 99% 0.0s\u001b[0K\u001b[1G167.7 MiB [] 100% 0.0s\u001b[0K\n",
            "Chromium 136.0.7103.25 (playwright build v1169) downloaded to /root/.cache/ms-playwright/chromium-1169\n",
            "Downloading FFMPEG playwright build v1011\u001b[2m from https://cdn.playwright.dev/dbazure/download/playwright/builds/ffmpeg/1011/ffmpeg-linux.zip\u001b[22m\n",
            "\u001b[1G2.3 MiB [] 0% 0.0s\u001b[0K\u001b[1G2.3 MiB [] 23% 0.1s\u001b[0K\u001b[1G2.3 MiB [] 70% 0.0s\u001b[0K\u001b[1G2.3 MiB [] 100% 0.0s\u001b[0K\n",
            "FFMPEG playwright build v1011 downloaded to /root/.cache/ms-playwright/ffmpeg-1011\n",
            "Downloading Chromium Headless Shell 136.0.7103.25 (playwright build v1169)\u001b[2m from https://cdn.playwright.dev/dbazure/download/playwright/builds/chromium/1169/chromium-headless-shell-linux.zip\u001b[22m\n",
            "\u001b[1G101.4 MiB [] 0% 0.0s\u001b[0K\u001b[1G101.4 MiB [] 1% 1.4s\u001b[0K\u001b[1G101.4 MiB [] 2% 1.2s\u001b[0K\u001b[1G101.4 MiB [] 3% 1.2s\u001b[0K\u001b[1G101.4 MiB [] 5% 1.2s\u001b[0K\u001b[1G101.4 MiB [] 6% 1.1s\u001b[0K\u001b[1G101.4 MiB [] 8% 1.0s\u001b[0K\u001b[1G101.4 MiB [] 9% 1.1s\u001b[0K\u001b[1G101.4 MiB [] 10% 1.1s\u001b[0K\u001b[1G101.4 MiB [] 12% 1.0s\u001b[0K\u001b[1G101.4 MiB [] 13% 1.1s\u001b[0K\u001b[1G101.4 MiB [] 14% 1.1s\u001b[0K\u001b[1G101.4 MiB [] 15% 1.1s\u001b[0K\u001b[1G101.4 MiB [] 16% 1.1s\u001b[0K\u001b[1G101.4 MiB [] 17% 1.1s\u001b[0K\u001b[1G101.4 MiB [] 18% 1.1s\u001b[0K\u001b[1G101.4 MiB [] 20% 1.1s\u001b[0K\u001b[1G101.4 MiB [] 21% 1.1s\u001b[0K\u001b[1G101.4 MiB [] 22% 1.1s\u001b[0K\u001b[1G101.4 MiB [] 24% 1.0s\u001b[0K\u001b[1G101.4 MiB [] 26% 1.0s\u001b[0K\u001b[1G101.4 MiB [] 28% 0.9s\u001b[0K\u001b[1G101.4 MiB [] 30% 0.9s\u001b[0K\u001b[1G101.4 MiB [] 32% 0.8s\u001b[0K\u001b[1G101.4 MiB [] 33% 0.8s\u001b[0K\u001b[1G101.4 MiB [] 35% 0.8s\u001b[0K\u001b[1G101.4 MiB [] 37% 0.8s\u001b[0K\u001b[1G101.4 MiB [] 39% 0.7s\u001b[0K\u001b[1G101.4 MiB [] 42% 0.7s\u001b[0K\u001b[1G101.4 MiB [] 43% 0.7s\u001b[0K\u001b[1G101.4 MiB [] 45% 0.6s\u001b[0K\u001b[1G101.4 MiB [] 46% 0.6s\u001b[0K\u001b[1G101.4 MiB [] 47% 0.6s\u001b[0K\u001b[1G101.4 MiB [] 48% 0.6s\u001b[0K\u001b[1G101.4 MiB [] 49% 0.7s\u001b[0K\u001b[1G101.4 MiB [] 50% 0.7s\u001b[0K\u001b[1G101.4 MiB [] 51% 0.7s\u001b[0K\u001b[1G101.4 MiB [] 52% 0.7s\u001b[0K\u001b[1G101.4 MiB [] 54% 0.6s\u001b[0K\u001b[1G101.4 MiB [] 56% 0.6s\u001b[0K\u001b[1G101.4 MiB [] 58% 0.5s\u001b[0K\u001b[1G101.4 MiB [] 60% 0.5s\u001b[0K\u001b[1G101.4 MiB [] 62% 0.5s\u001b[0K\u001b[1G101.4 MiB [] 64% 0.4s\u001b[0K\u001b[1G101.4 MiB [] 66% 0.4s\u001b[0K\u001b[1G101.4 MiB [] 68% 0.4s\u001b[0K\u001b[1G101.4 MiB [] 71% 0.4s\u001b[0K\u001b[1G101.4 MiB [] 73% 0.3s\u001b[0K\u001b[1G101.4 MiB [] 75% 0.3s\u001b[0K\u001b[1G101.4 MiB [] 78% 0.3s\u001b[0K\u001b[1G101.4 MiB [] 80% 0.2s\u001b[0K\u001b[1G101.4 MiB [] 82% 0.2s\u001b[0K\u001b[1G101.4 MiB [] 84% 0.2s\u001b[0K\u001b[1G101.4 MiB [] 86% 0.1s\u001b[0K\u001b[1G101.4 MiB [] 89% 0.1s\u001b[0K\u001b[1G101.4 MiB [] 91% 0.1s\u001b[0K\u001b[1G101.4 MiB [] 93% 0.1s\u001b[0K\u001b[1G101.4 MiB [] 95% 0.1s\u001b[0K\u001b[1G101.4 MiB [] 97% 0.0s\u001b[0K\u001b[1G101.4 MiB [] 100% 0.0s\u001b[0K\n",
            "Chromium Headless Shell 136.0.7103.25 (playwright build v1169) downloaded to /root/.cache/ms-playwright/chromium_headless_shell-1169\n",
            "nohup: appending output to 'nohup.out'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nohup ollama serve &\n",
        "import random\n",
        "import subprocess\n",
        "import wikipedia\n",
        "import requests\n",
        "\n",
        "\n",
        "from urllib.parse import urlparse\n",
        "from bs4 import BeautifulSoup\n",
        "from googlesearch import search\n",
        "from crawl4ai import LLMConfig, LLMExtractionStrategy, CrawlerRunConfig,CacheMode\n",
        "from crawl4ai.deep_crawling.filters import FilterChain, ContentRelevanceFilter\n",
        "from crawl4ai.deep_crawling import BFSDeepCrawlStrategy\n",
        "import json\n",
        "\n",
        "from playwright.async_api import async_playwright\n",
        "\n",
        "from crawl4ai.extraction_strategy import CosineStrategy\n",
        "\n",
        "from crawl4ai.async_configs import BrowserConfig\n",
        "\n",
        "from crawl4ai import AsyncWebCrawler\n",
        "\n",
        "import requests\n",
        "from urllib.parse import urlparse\n",
        "\n",
        "import asyncio\n",
        "import time\n",
        "import requests\n",
        "import nest_asyncio\n",
        "\n",
        "\n",
        "API_BASE = \"https://www.nearestdoor.com\"  # Replace with actual server URL\n",
        "CLIENT_ID = \"client001\"\n",
        "HEARTBEAT_INTERVAL = 60  # seconds\n",
        "SHOP_FLOW_STATIC = [\n",
        "    \"search\", \"aggregate\", \"createplan\", \"create\",\n",
        "    \"find_available_fields\", \"extract_fields_from_aggregate\", \"fillintheshop\"\n",
        "]\n",
        "# --------------------------------------------------------------------------- #\n",
        "# 🧠  LIGHT‑WEIGHT LOCAL LLM EXECUTION                                       #\n",
        "# --------------------------------------------------------------------------- #\n",
        "class OllamaRunner:\n",
        "    \"\"\"\n",
        "    `ollama run …`\n",
        "\n",
        "    \"\"\"\n",
        "    def __init__(self, default_model: str = \"gemma3:1b\", default_timeout: int = 600):\n",
        "        self.default_model = default_model\n",
        "        self.default_timeout = default_timeout\n",
        "\n",
        "    def run(self, prompt: str, model: str | None = None, timeout: int | None = None) -> str:\n",
        "        model = model or self.default_model\n",
        "        timeout = timeout or self.default_timeout\n",
        "        print(f\"🧠 Running Ollama: {model}\")\n",
        "\n",
        "        try:\n",
        "            proc = subprocess.run(\n",
        "                [\"ollama\", \"run\", model],\n",
        "                input=prompt.encode(\"utf-8\"),\n",
        "                stdout=subprocess.PIPE,\n",
        "                stderr=subprocess.PIPE,\n",
        "                timeout=timeout,\n",
        "            )\n",
        "\n",
        "            raw_output = proc.stdout.decode(\"utf-8\").strip()\n",
        "            return re.sub(r\"<think>.*?</think>\", \"\", raw_output, flags=re.DOTALL).strip()\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Ollama execution failed: {e}\")\n",
        "            return \"\"\n",
        "\n",
        "\n",
        "# --------------------------------------------------------------------------- #\n",
        "# 🌐  LOOK‑UP ENGINE                                                          #\n",
        "# --------------------------------------------------------------------------- #\n",
        "class LookupEngine:\n",
        "    \"\"\"\n",
        "    – Validates every URL first\n",
        "    – Google results exclude Yelp & Reddit and are content‑checked\n",
        "    – Yelp & Reddit results are *also* content‑checked before ‘battling’\n",
        "    – At most one Yelp URL & one Reddit URL are returned\n",
        "    – Wikipedia returns at most one page (auto_suggest)\n",
        "    \"\"\"\n",
        "    def __init__(self,  ollama_runner: OllamaRunner | None = None):\n",
        "\n",
        "        self.llm_config = LLMConfig(provider=\"ollama/gemma3:1b\")\n",
        "        self.ollama = ollama_runner or OllamaRunner()\n",
        "        self.crawler_manager = self.CrawlerManager()\n",
        "    async def initialize(self):\n",
        "        await self.crawler_manager.start()\n",
        "\n",
        "\n",
        "    # ---------------------  LOW‑LEVEL HELPERS  ----------------------------- #\n",
        "    class CrawlerManager:\n",
        "        def __init__(self):\n",
        "            self.crawler = None\n",
        "        async def start(self):\n",
        "            if self.crawler is None:\n",
        "                self.crawler = AsyncWebCrawler(config=BrowserConfig())\n",
        "                await self.crawler.__aenter__()\n",
        "\n",
        "        async def stop(self):\n",
        "            if self.crawler:\n",
        "                await self.crawler.__aexit__(None, None, None)\n",
        "                self.crawler = None\n",
        "\n",
        "\n",
        "        async def crawl(self, url: str, config: CrawlerRunConfig | None = None):\n",
        "            if not self.crawler:\n",
        "                raise RuntimeError(\"Crawler not started\")\n",
        "\n",
        "            url = self._normalize_and_validate_url(url)\n",
        "            if not url:\n",
        "                return None\n",
        "\n",
        "            try:\n",
        "                result = await self.crawler.arun(url=url, config=config or CrawlerRunConfig())\n",
        "                return result\n",
        "            except Exception as e:\n",
        "                print(f\"❌ crawl error for {url}: {e}\")\n",
        "                return None\n",
        "\n",
        "\n",
        "        def _normalize_and_validate_url(self, url: str) -> str | None:\n",
        "            try:\n",
        "                url = url.lower()\n",
        "                if not url.startswith((\"http://\", \"https://\")):\n",
        "                    url = \"https://\" + url\n",
        "\n",
        "                parsed = urlparse(url)\n",
        "                if (\n",
        "                    parsed.scheme not in [\"http\", \"https\"]\n",
        "                    or not parsed.netloc\n",
        "                    or \".\" not in parsed.netloc\n",
        "                    or \" \" in parsed.netloc\n",
        "                    or \"/http\" in parsed.netloc\n",
        "                ):\n",
        "                    return None\n",
        "\n",
        "                # ✅ Check if the URL is reachable\n",
        "                try:\n",
        "                    response = requests.head(url, timeout=5)\n",
        "                    if response.status_code >= 400:\n",
        "                        print(f\"❌ URL unreachable: {url} (Status: {response.status_code})\")\n",
        "                        return None\n",
        "                except requests.RequestException as e:\n",
        "                    print(f\"❌ URL check failed: {url} ({e})\")\n",
        "                    return None\n",
        "\n",
        "                return url\n",
        "            except Exception as e:\n",
        "                print(f\"❌ URL normalization failed: {e}\")\n",
        "                return None\n",
        "\n",
        "\n",
        "    async def _extract_snippet(self, url, max_chars, min_chars):\n",
        "        try:\n",
        "            async with async_playwright() as p:\n",
        "                browser = await p.chromium.launch(headless=True)\n",
        "                context = await browser.new_context(\n",
        "                    user_agent=\"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/123.0.0.0 Safari/537.36\",\n",
        "                    locale=\"en-US\",\n",
        "                    java_script_enabled=True,\n",
        "                    permissions=[\"geolocation\"]\n",
        "                )\n",
        "                page = await context.new_page()\n",
        "                await page.wait_for_timeout(random.randint(1000, 3000))  # Randomized delay\n",
        "\n",
        "                print(f\"Fetching: {url}\")\n",
        "                await page.goto(url, wait_until=\"domcontentloaded\", timeout=30000)\n",
        "                await page.wait_for_selector(\"body\", timeout=5000)\n",
        "\n",
        "                title = await page.title()\n",
        "                desc = None\n",
        "\n",
        "                # Try standard meta description first\n",
        "                try:\n",
        "                    desc = await page.locator('meta[name=\"description\"]').get_attribute('content')\n",
        "                except Exception:\n",
        "                    # Try OpenGraph and Twitter metadata as fallback\n",
        "                    for meta_tag in [\"meta[property='og:description']\", \"meta[name='twitter:description']\"]:\n",
        "                        try:\n",
        "                            desc = await page.locator(meta_tag).get_attribute('content')\n",
        "                            if desc:\n",
        "                                break\n",
        "                        except Exception:\n",
        "                            continue\n",
        "                    if not desc:\n",
        "                        print(f\"No meta description found for {url}\")\n",
        "\n",
        "                heads = await page.locator(\"h1, h2, h3, h4, h5, h6\").all_inner_texts()\n",
        "                para_elements = await page.locator(\"p\").all_inner_texts()\n",
        "\n",
        "                parts = []\n",
        "                if title:\n",
        "                    parts.append(\"Meta Title: \" + title.strip())\n",
        "                if desc:\n",
        "                    parts.append(\"Meta Desc: \" + desc.strip())\n",
        "                parts.extend([\"Headers: \" + h.strip() for h in heads[:6] if h.strip()])\n",
        "\n",
        "                # Intelligent Paragraph Extraction\n",
        "                para_candidates = para_elements[1:5]  # Prefer 2nd to 5th paragraphs\n",
        "                paras = [p.strip() for p in para_candidates if len(p.strip()) > 30]\n",
        "\n",
        "                if len(paras) < 4:\n",
        "                    # Look for larger paragraphs in the remaining content\n",
        "                    remaining_paras = [p.strip() for p in para_elements[5:] if len(p.strip()) > 50]\n",
        "                    paras.extend(remaining_paras[:4 - len(paras)])\n",
        "\n",
        "                # Extract aria-label and alt attributes as additional context (Optional)\n",
        "                try:\n",
        "                    aria_labels = await page.locator(\"[aria-label]\").evaluate_all(\"els => els.map(e => e.getAttribute('aria-label'))\")\n",
        "                    alt_texts = await page.locator(\"[alt]\").evaluate_all(\"els => els.map(e => e.getAttribute('alt'))\")\n",
        "                    contextual_info = [text.strip() for text in (aria_labels + alt_texts) if text and len(text.strip()) > 30]\n",
        "                    paras.extend(contextual_info[:2])  # Add up to 2 contextual info pieces\n",
        "                except Exception:\n",
        "                    pass\n",
        "\n",
        "                for para in paras[:4]:  # Limit to top 4 paragraphs/info pieces\n",
        "                    parts.append(\"Paragraph: \" + para)\n",
        "\n",
        "                await browser.close()\n",
        "\n",
        "                result = \"\\n\".join(parts)\n",
        "                if len(result) < min_chars:\n",
        "                    print(f\"❌ Extracted content too short: {len(result)} chars\")\n",
        "                    return None\n",
        "\n",
        "                return f\"Snippet From {url}:\\n{result[:max_chars]}\"\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Playwright extraction failed for {url}: {e}\")\n",
        "            return None\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    async def _basic_url_checker(self, url: str, shop_name: str, shop_type: str, state: str, city:str) -> bool:\n",
        "        try:\n",
        "\n",
        "            \"\"\"\n",
        "            Improved relevance check for a URL:\n",
        "            1. Uses Crawl4AI's ContentRelevanceFilter for semantic similarity.\n",
        "            2. Falls back to LLM prompt decision if semantic check is inconclusive.\n",
        "            \"\"\"\n",
        "\n",
        "            if not url:\n",
        "                return False\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "            # Step 2: Fallback — Quick Snippet and LLM Yes/No Decision\n",
        "            snippet = await self._extract_snippet(url, 500, 100)\n",
        "            if not snippet:\n",
        "                print(\"no snippet\")\n",
        "                return False\n",
        "\n",
        "            prompt = (\n",
        "                f\"Is the following website related to {shop_type} named '{shop_name}' or the place? \"\n",
        "                f\"Be very lient and allow any page related to {shop_type}, {state}, {city}, Answer only `true` or `false` or `none`.\\n\\n{snippet}\"\n",
        "            )\n",
        "\n",
        "            decision = self.ollama.run(prompt, 'qwen3:0.6b')\n",
        "            print(decision)\n",
        "            if \"true\" in decision.lower():\n",
        "                print(f\"✅ LLM confirmed relevance for: {url}\")\n",
        "                return True\n",
        "            print(prompt)\n",
        "            print(f\"⚠️ URL deemed irrelevant: {url}\")\n",
        "            return False\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"error in basicc checker\", {url}, {shop_name}, {shop_type}, e)\n",
        "            return False\n",
        "    @staticmethod\n",
        "    def get_semantic_query(shop_type, shop_name):\n",
        "        queries = {\n",
        "            \"church\": f\"{shop_type}, {shop_name}, history, review, hours, muslim, phone, church, christian, church events, holiday schedules, mass times, sermons, church history, community programs, accessibility options, FAQs, donation methods, parking, contact information\",\n",
        "            \"plasma_center\": f\"{shop_type}, {shop_name}, history, review, stocked brands, review, hours, phone, plasma, plasma donation requirements, compensation rates, donor reward, donor eligibility, contact details, operating hours, health guidelines, FAQ, appointment scheduling, safety procedures\",\n",
        "            \"thrift_store\": f\"{shop_type}, {shop_name}, history, review, stocked brands, second hand,  review, hours, phone, thrift, store hours, donation guidelines, accepted items, discounts, sales events, store history, accessibility, contact info, volunteer programs, reviews\",\n",
        "            \"dog_park\": f\"{shop_type}, {shop_name}, history, review, water, shade, agility equipment, park, review, hours, phone, dog, dog park hours, leash rules, pet-friendly areas, dog-friendly facilities, park amenities, accessibility options, entry fees, safety tips, events, pet policies, reviews\",\n",
        "        }\n",
        "        return queries.get(shop_type.lower(), \"business information, contact details, operating hours, reviews, FAQs, history\")\n",
        "\n",
        "    async def _get_site_content(\n",
        "\n",
        "            self,\n",
        "            url: str,\n",
        "            shop_name: str,\n",
        "            shop_type: str,\n",
        "state:str, city:str\n",
        "            ) -> str | None:\n",
        "        try:\n",
        "        # Step 1: Semantic Filter Based on Shop Type\n",
        "            semantic_query = self.get_semantic_query(shop_type, shop_name)\n",
        "\n",
        "            llm_strategy = LLMExtractionStrategy(\n",
        "          llm_config = LLMConfig(provider=\"ollama/qwen3:0.6b\"),\n",
        "\n",
        "          extraction_type=\"block\",\n",
        "          instruction=f\"Extract all data and useful info related similar to, {state}, {city}, {semantic_query}, remove noise\",\n",
        "          chunk_token_threshold=1000,\n",
        "          overlap_rate=0.0,\n",
        "          apply_chunking=True,\n",
        "          input_format=\"markdown\",   # or \"html\", \"fit_markdown\"\n",
        "          extra_args={\"temperature\": 0.0, \"max_tokens\": 1200}\n",
        "\n",
        "      )\n",
        "\n",
        "\n",
        "\n",
        "            crawl_config = CrawlerRunConfig(\n",
        "                cache_mode=CacheMode.BYPASS,\n",
        "                extraction_strategy=llm_strategy,\n",
        "                excluded_tags=[\"script\", \"style\", \"header\", \"footer\", \"nav\"],\n",
        "                exclude_external_links=False,\n",
        "                exclude_social_media_links=False,\n",
        "                magic=True,\n",
        "                verbose = True,\n",
        "                word_count_threshold=20,\n",
        "                process_iframes=True,\n",
        "                remove_overlay_elements=True,\n",
        "                   wait_for=\"css:body\",          # Waits until the <body> tag appears in the DOM\n",
        "    page_timeout=60000,\n",
        "            )\n",
        "\n",
        "            # ✅ Use CrawlerManager properly\n",
        "            url = self.crawler_manager._normalize_and_validate_url(url)\n",
        "            if not url:\n",
        "                return None\n",
        "\n",
        "            result = await self.crawler_manager.crawl(url, config=crawl_config)\n",
        "            if not result or not hasattr(result, '__iter__'):\n",
        "              print(f\"❌ No crawl results for {url}\")\n",
        "              return None\n",
        "\n",
        "            successful_results = [r for r in result if getattr(r, 'success', False) and getattr(r, 'extracted_content', None)]\n",
        "\n",
        "            if not successful_results:\n",
        "                print(f\"❌ content extraction failed for {url}\")\n",
        "                return None\n",
        "\n",
        "            # Combine extracted content from successful results\n",
        "            content_chunks = [item.extracted_content for item in successful_results]\n",
        "            combined_content = \"\\n\\n\".join(content_chunks)\n",
        "            return combined_content\n",
        "\n",
        "\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Failed to parse site content: {e}\")\n",
        "            return None\n",
        "    # ---------------------  LOOK‑UP ROUTINES  ------------------------------ #\n",
        "    async def wikipedia_lookup(self, name: str, city: str, shop_type: str) -> str | None:\n",
        "        try:\n",
        "            query = f\"{name} {city} {shop_type}\".strip()\n",
        "            print(f\"📚 Wikipedia lookup → {query}\")\n",
        "            page = wikipedia.page(query, auto_suggest=True)\n",
        "            content = page.content\n",
        "\n",
        "            if len(content) <= 2000:\n",
        "                return content\n",
        "            chunks = [content[i:i + 500] for i in range(0, len(content), 500)]\n",
        "            # Fallback-safe middle extraction\n",
        "            if len(chunks) > 6:\n",
        "                middle = chunks[2:-2]  # Remove first and last 2 chunks\n",
        "                if not middle:\n",
        "                    middle = chunks  # If middle is empty, fallback to all chunks\n",
        "            else:\n",
        "                middle = chunks\n",
        "\n",
        "            # Intelligent selection\n",
        "            if len(middle) > 6:\n",
        "                selected = random.sample(middle, 6)  # Randomly select 6 if too many\n",
        "            else:\n",
        "                selected = middle  # Take all available if 6 or fewer\n",
        "            formatted_chunks = [f\"\\nWIKI CHUNK {idx + 1}:\\n{chunk}\" for idx, chunk in enumerate(selected)]\n",
        "\n",
        "            return f\"ALL EXTRACTED WIKIPEDIA SEARCH INFO FOR {name}:\\n\" + \"\\n\".join(formatted_chunks)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Wikipedia fetch failed: {e}\")\n",
        "            return None\n",
        "\n",
        "    async def search_lookup(self,  name: str,  shop_type: str, query: str, placename: str, amount: int,state:str, city:str, isyelp: bool=False) -> str | None:\n",
        "        try:\n",
        "            print(f\"🔎 Google search → {query}\")\n",
        "\n",
        "            raw = list(search(query, amount))\n",
        "            if not isyelp:\n",
        "                candidate_urls = [u for u in raw if \"yelp\" not in u.lower() and \"reddit\" not in u.lower() and 'wiki' not in u.lower() and 'nearestdoor' not in u.lower() and 'facebook' not in u.lower() and 'twitter' not in u.lower()]\n",
        "            else:\n",
        "\n",
        "                candidate_urls = [u for u in raw if \"yelp\" in u.lower() or \"reddit\" in u.lower() and 'wiki' not in u.lower() and 'nearestdoor' not in u.lower() and 'facebook' not in u.lower() and 'twitter' not in u.lower()]\n",
        "            good_content = []\n",
        "            for i, url in enumerate(candidate_urls):\n",
        "\n",
        "                url = self.crawler_manager._normalize_and_validate_url(url)\n",
        "                if not url:\n",
        "                    continue\n",
        "\n",
        "                if not await self._basic_url_checker(url, name, shop_type, state, city):\n",
        "                    continue\n",
        "\n",
        "                content = await self._get_site_content(url, name, shop_type,state, city)\n",
        "                if content:\n",
        "                    good_content.append(f\"\\n← {placename} SEARCH DATA SITE {i} FROM: {url}\\n {content}\")\n",
        "\n",
        "            return f\"ALL EXTRACTED {placename} SEARCH DATA FOR {name}\\n\".join(good_content) if good_content else None\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Failed to parse search lookup results: {e}\")\n",
        "            return None\n",
        "    # ---------------------  PUBLIC ENTRY POINT  ---------------------------- #\n",
        "    async def combined_search(self, name: str, city: str, state: str, shop_type: str, website_url: str) -> tuple[bool, str | None, None]:\n",
        "        print(\"🌐 Starting combined search…\")\n",
        "\n",
        "        Google_query = f\"{name} {city} {state} {shop_type} \"\n",
        "\n",
        "        Yelp_query = f\"{name} {city} {state} {shop_type} site: yelp.com \"\n",
        "\n",
        "        Reddit_query = f\"{name} {city} {state} {shop_type} site: reddit.com \"\n",
        "        if website_url:\n",
        "            Official_query = f\"{name} site: {website_url} \"\n",
        "\n",
        "        g_res = await self.search_lookup(name, shop_type, Google_query, \"Google\",state, city, 10, False)\n",
        "\n",
        "        y_res = await self.search_lookup(name, shop_type, Yelp_query, \"Yelp\", 5, state, city, True)\n",
        "\n",
        "        r_res = await self.search_lookup(name, shop_type, Reddit_query, \"Reddit\",state, city, 5, True)\n",
        "        w_res = await self.wikipedia_lookup(name, city, shop_type)\n",
        "        o_res = None\n",
        "        if website_url:\n",
        "            o_res = await self.search_lookup(name, shop_type, Official_query, f\"Official Website of {name}\", 5, True)\n",
        "        main = \"\"\n",
        "        if y_res:\n",
        "            main += y_res\n",
        "        if r_res:\n",
        "            main += r_res\n",
        "        if g_res:\n",
        "            main += g_res\n",
        "        if w_res:\n",
        "            main += w_res\n",
        "        if o_res:\n",
        "            main += o_res\n",
        "        if len(main) < 500:\n",
        "            print(\"❌ Not enough content gathered.\")\n",
        "            return False, None, None\n",
        "\n",
        "        print(\"✅ Combined search complete.\")\n",
        "        return True, main, None\n",
        "# --------------------------------------------------------------------------- #\n",
        "# 📦  HIGH‑LEVEL CONTENT SUMMARIZER                                          #\n",
        "# --------------------------------------------------------------------------- #\n",
        "class ContentSummarizer:\n",
        "    \"\"\"\n",
        "    Reduce a large blob of text about a specific business down to ≤ max_final_chars\n",
        "    while preserving high‑value facts. Uses multi-stage LLM summarisation with\n",
        "    chunk filtering and escalation if necessary.\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "        self,\n",
        "        ollama_runner: OllamaRunner,\n",
        "        shop_name: str,\n",
        "        shop_type: str,\n",
        "        city: str | None = None,\n",
        "        state: str | None = None,\n",
        "        max_final_chars: int = 6000,\n",
        "        min_final_chars: int = 500,\n",
        "    ):\n",
        "        self.ollama = ollama_runner\n",
        "        self.shop_name = shop_name\n",
        "        self.shop_type = shop_type\n",
        "        self.city = city or \"\"\n",
        "        self.state = state or \"\"\n",
        "        self.max_final_chars = max_final_chars\n",
        "        self.min_final_chars = min_final_chars\n",
        "\n",
        "    # ----------------- Internal Helpers ----------------- #\n",
        "    def _clean_raw_content(self, content: str) -> str:\n",
        "        lines = content.splitlines()\n",
        "        cleaned, seen = [], set()\n",
        "        NOISE = [\n",
        "            \"cookie policy\", \"all rights reserved\", \"subscribe\", \"advertisement\",\n",
        "            \"accept cookies\", \"privacy policy\", \"terms of service\", \"sign in\", \"cookie\"\n",
        "        ]\n",
        "        for line in lines:\n",
        "            line = line.strip()\n",
        "            lo = line.lower()\n",
        "            if len(line) < 30 or lo in seen:\n",
        "                continue\n",
        "            if any(noise in lo for noise in NOISE):\n",
        "                continue\n",
        "            seen.add(lo)\n",
        "            cleaned.append(line)\n",
        "        return \"\\n\".join(cleaned)\n",
        "\n",
        "    def _chunk_text(self, text: str, chunk_size: int) -> list[str]:\n",
        "        return [text[i:i + chunk_size] for i in range(0, len(text), chunk_size)]\n",
        "\n",
        "    def _filter_chunks(self, chunks: list[str], model: str = \"gemma3:1b\") -> list[str]:\n",
        "        try:\n",
        "            good = []\n",
        "            for chunk in chunks:\n",
        "                prompt = (\n",
        "                    f\"Is the following content useful for creating a profile for the {self.shop_type} \"\n",
        "                    f\"'{self.shop_name}'? Only reply 'true' or 'false'.\\n\\n{chunk}\"\n",
        "                )\n",
        "                decision = self.ollama.run(prompt, model=model).strip().lower()\n",
        "                if \"true\" in decision:\n",
        "                    good.append(chunk)\n",
        "\n",
        "            return good\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Failed to filter chunk: {e}\")\n",
        "            return None\n",
        "\n",
        "    def _build_prompt(self, text_chunk: str) -> str:\n",
        "        return (\n",
        "            f\"You are creating a SHORT high-quality summary for \"\n",
        "            f\"{self.shop_type} **{self.shop_name}** \"\n",
        "            f\"{'in ' + self.city if self.city else ''}{', ' + self.state if self.state else ''}.\\n\\n\"\n",
        "            f\"Keep ALL USEFUL DATA\"\n",
        "            \"KEEP SERVICES.\\n\"\n",
        "            f\"KEEP URLS ONLY WHEN IT IS THE LITERAL {self.shop_name}'s WEBSITE.\\n\"\n",
        "            f\"KEEP ALL GOOD INFO AND HISTORY, FACTS, INFO, Extract all usefull info, Example: \\n\"\n",
        "            f\"• Keep Contact info (phone, email)\\n\"\n",
        "            f\"• Keep Official website URLs only if directly related to {self.shop_name}\\n\"\n",
        "            f\"• Keep Operating hours, holiday hours, KEEP ALL USEFUL ANY DATA\\n\"\n",
        "            f\"• Keep Brands Price range, services, FAQs, key facts, reviews, history\\n\"\n",
        "            f\"• Keep Reviews sentiment, pros/cons, unique selling points\\n\"\n",
        "            f\"• Keep Awards, certifications, reviews, press articles\\n\\n\"\n",
        "            f\" remove unrelated info.\\n\"\n",
        "\n",
        "            f\"--- SOURCE TEXT START ---\\n{text_chunk}\\n--- SOURCE TEXT END ---\"\n",
        "\n",
        "        )\n",
        "\n",
        "    def _summarize_with_ollama(self, text: str, model: str) -> str:\n",
        "        try:\n",
        "\n",
        "            prompt = self._build_prompt(text)\n",
        "            return self.ollama.run(prompt, model=model)\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Failed to summarize w ollama: {e}\")\n",
        "            return None\n",
        "    def summarize_chunks(\n",
        "        self,\n",
        "        content: str,\n",
        "        chunk_size: int = 2000,\n",
        "        initial_model: str = \"gemma3:1b\",\n",
        "\n",
        "    ) -> str:\n",
        "        try:\n",
        "            chunks = self._chunk_text(content, chunk_size)\n",
        "            content = self._filter_chunks(chunks)\n",
        "            if not content:\n",
        "                content = chunks\n",
        "            filtered_content = ''.join(content)\n",
        "            if len(filtered_content) < self.min_final_chars:\n",
        "                return None\n",
        "            if len(filtered_content) < self.max_final_chars:\n",
        "                return filtered_content\n",
        "\n",
        "            summarized_chunks = []\n",
        "\n",
        "            for idx, chunk in enumerate(chunks, start=1):\n",
        "                print(f\"📚 Summarizing chunk {idx}/{len(chunks)}...\")\n",
        "                summary = self._summarize_with_ollama(chunk, model=initial_model)\n",
        "\n",
        "                if not summary or len(summary) < 50:\n",
        "                    print(f\"⚠️ Failed to summarize chunk {idx}, keeping raw content.\")\n",
        "                    summary = chunk  # Fallback to raw content if summary failed\n",
        "\n",
        "                summarized_chunks.append(f\"### CHUNK {idx} SUMMARY:\\n{summary}\")\n",
        "\n",
        "                # Early exit: check if adding all remaining raw chunks without summarizing fits within limit\n",
        "                combined_so_far = \"\\n\\n\".join(summarized_chunks)\n",
        "                remaining_raw = \"\".join(chunks[idx:])  # Remaining chunks after current one\n",
        "\n",
        "                if len(combined_so_far) + len(remaining_raw) <= self.max_final_chars:\n",
        "                    print(f\"✅ Early exit: current summary + remaining raw fits within limit. Skipping further summarization.\")\n",
        "                    for r_idx, remaining_chunk in enumerate(chunks[idx:], start=idx + 1):\n",
        "                        summarized_chunks.append(f\"### CHUNK {r_idx} (Raw):\\n{remaining_chunk}\")\n",
        "                    break\n",
        "\n",
        "            combined_summary = \"\\n\\n\".join(summarized_chunks)\n",
        "            if len(combined_summary) < self.min_final_chars:\n",
        "                return None\n",
        "            # Final trim if absolutely necessary\n",
        "            if len(combined_summary) > self.max_final_chars:\n",
        "                print(\"⚠️ Final combined summary exceeds character limit. Trimming result.\")\n",
        "                return combined_summary[:self.max_final_chars]\n",
        "\n",
        "            return combined_summary\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Failed to sumarrize chunks: {e}\")\n",
        "            return None\n",
        "\n",
        "\n",
        "    def summarize_content(self, raw_content: str) -> str:\n",
        "        print(\"🧹 Cleaning raw content...\")\n",
        "        cleaned = self._clean_raw_content(raw_content)\n",
        "        if len(cleaned) <= self.max_final_chars:\n",
        "            print(\"✅ Cleaned content fits within final character limit.\")\n",
        "            return cleaned\n",
        "\n",
        "        final_summary = self.summarize_chunks(\n",
        "        content=cleaned,           # The large raw text content you want to reduce\n",
        "        chunk_size=1500,                # Size of each chunk before summarizing\n",
        "        initial_model=\"gemma3:1b\",      # Start with the lightweight model\n",
        "\n",
        "    )\n",
        "        if final_summary is None:\n",
        "            print(\"❌ Summarization failed. Returning cleaned content instead.\")\n",
        "            return cleaned[:self.max_final_chars]\n",
        "\n",
        "        print(\"🎉 Final summarization complete.\")\n",
        "        return final_summary\n",
        "\n",
        "import re\n",
        "import json\n",
        "\n",
        "class Smartypants:\n",
        "    def __init__(self, ollama_runner: OllamaRunner):\n",
        "        self.ollama = ollama_runner\n",
        "\n",
        "    def _run4(self, prompt: str) -> str:\n",
        "        return self.ollama.run(prompt, model=\"gemma3:4b\",)\n",
        "    def _run1(self, prompt: str) -> str:\n",
        "        return self.ollama.run(prompt, model=\"gemma3:1b\")\n",
        "\n",
        "    # ------------ PLAN ------------ #\n",
        "    def create_plan(self, aggregate: str,shop_name: str, shop_type: str,  city: str, state: str) -> tuple[bool, list[str]]:\n",
        "        prompt = (\n",
        "            \"You have an aggregated summary about a \"\n",
        "\n",
        "            f\"place called {shop_name} {shop_type} in {city}, {state}\\n\\n\"\n",
        "            f\"{aggregate}\\n\\n\"\n",
        "            \"Which content sections can confidently be generated based on this?\\n\"\n",
        "            \"Options: article, faq, history.\\n\"\n",
        "            \"Reply with a correct python comma-separated list of available sections to write about, nothing else, Options: article, faq, history.\"\n",
        "        )\n",
        "        try:\n",
        "            count = 0\n",
        "            resp = self._run4(prompt).lower()\n",
        "            valid = {\"article\", \"faq\", \"history\"}\n",
        "            print(resp)\n",
        "            for s in valid:\n",
        "                if s not in resp:\n",
        "                    count +=1\n",
        "            if count == 3:\n",
        "                return False, []\n",
        "\n",
        "            return True, [s for s in valid if s in resp]\n",
        "        except Exception as e:\n",
        "            print(f\"❌ create_plan error: {e}\")\n",
        "            return False, []\n",
        "\n",
        "    def check_aggregate_quality(self, shop_name: str, aggregate: str,shop_type: str,  city: str, state: str) -> bool:\n",
        "        prompt = (\n",
        "            f\"Check if this content contains usefull info about {shop_name} {shop_type} in {city}, {state}.\\n\\n{aggregate}\\n\\n\"\n",
        "            \"Reply only `true` or `false`.\"\n",
        "        )\n",
        "        try:\n",
        "            return \"true\" in self._run1(prompt).lower()\n",
        "        except Exception as e:\n",
        "            print(f\"❌ quality check error: {e}\")\n",
        "            return False\n",
        "\n",
        "    # ------------ SECTION VALIDATION / FIX ------------ #\n",
        "    def validate_section_html(self, shop_name: str, section: str, text: str) -> bool:\n",
        "        prompt = (\n",
        "            f\"Validate the following text for section '{section}'. It is supposed to be about '{shop_name}'.\\n\\n{text}\\n\\n\"\n",
        "            \"Rules:\\n- No HTML.\\n- No irrelevant info. Is it useful and no format or weird characters? Nothing Else, Nothing before or after our content\\n\"\n",
        "            \"- Only factual, structured, and clear content.\\n- Reply `true` or `false` only.\"\n",
        "        )\n",
        "        return \"true\" in self._run1(prompt).lower()\n",
        "\n",
        "    def fix_section_html(self, shop_name: str, section: str, text: str) -> str | None:\n",
        "        prompt = (\n",
        "            f\"Clean and fix this section '{section}'s format. It is about '{shop_name}'.\\n\\n{text}\\n\\n\"\n",
        "            \"Rules:\\n- No HTML, Is it useful and and no format or weird characters? asterisks, or irrelevant info.\\n\"\n",
        "            \"Return only the final cleaned text for consumers on nearestdoor.com to read, no junk, no explanations, nothing else, nothing before or after our content. Only return the corrected text.\"\n",
        "        )\n",
        "        return self._run4(prompt).strip()\n",
        "\n",
        "    # ------------ JSON & FIELD EXTRACTION ------------ #\n",
        "    def extract_clean_json_structure(self, text: str) -> dict | None:\n",
        "        try:\n",
        "            match = re.search(r\"\\{.*?\\}\", text.strip(), re.DOTALL)\n",
        "            if not match:\n",
        "                return None\n",
        "\n",
        "            match_text = match.group(0).lower()\n",
        "            exclusion_keywords = ['n/a', 'n-a', 'none', 'false', 'na', 'cant', 'not', 'found', 'unable', '{{', '()', 'unavailable']\n",
        "\n",
        "            if any(bad in match_text for bad in exclusion_keywords):\n",
        "                return None\n",
        "\n",
        "            json_ready = match.group(0).replace(\"'\", '\"')\n",
        "            return json.loads(json_ready)\n",
        "\n",
        "        except Exception:\n",
        "            return None\n",
        "\n",
        "\n",
        "    def extract_available_fields(self, aggregate: str,shop_name: str, shop_type: str,  city: str, state: str) -> tuple[bool, list[str]]:\n",
        "        try:\n",
        "            field_list = list(FIELD_EXTRACTORS.keys())\n",
        "            field_str = ', '.join(field_list)\n",
        "            prompt = (\n",
        "                f\"Analyze the content:\\n\\n{aggregate}\\n\\n\"\n",
        "                f\"Whos data we want {shop_type}, {shop_name}. \"\n",
        "                f\"Which of these fields can be confidently extracted?\\n{field_str}\\n\"\n",
        "                \"Reply ONLY with the field keys that are present in the text, as ONLY the correct format requested. no junk. Nothing else. \"\n",
        "                \"If none, reply exactly 'FALSE'.\"\n",
        "            )\n",
        "            response = self._run4(prompt).strip().lower()\n",
        "            if \"false\" in response:\n",
        "                return True, []\n",
        "            detected = [field for field in field_list if field.lower() in response]\n",
        "            return True, detected\n",
        "        except Exception as e:\n",
        "            print(f\"❌ extract_available_fields error: {e}\")\n",
        "            return False, []\n",
        "    def validate_extracted_field_value(self, field: str, value) -> bool:\n",
        "        \"\"\"\n",
        "        Validate the extracted field value using LLM and manual schema checks.\n",
        "\n",
        "        - If it's a JSON list, remove invalid entries.\n",
        "        - If it's invalid after cleaning, return False.\n",
        "        \"\"\"\n",
        "        # LLM-Based Validation Prompt\n",
        "        prompt = (\n",
        "            f\"Validate this extracted value for field '{field}':\\n\\n{value}\\n\\n\"\n",
        "            \"Is this a valid and correct value and format for the specified field requested? Is it weird for the field or contain none values? Reply ONLY `true` or `false`.\"\n",
        "        )\n",
        "        llm_decision = \"true\" in self._run1(prompt).lower()\n",
        "\n",
        "        # If LLM says it's invalid, fail immediately\n",
        "        if not llm_decision:\n",
        "            print(f\"❌ LLM validation failed for field '{field}'.\")\n",
        "            return False\n",
        "\n",
        "\n",
        "\n",
        "        # Final check for singular values\n",
        "        return True\n",
        "\n",
        "    def extract_fields(\n",
        "        self, aggregate: str, available_fields: list[str],\n",
        "        shop_name: str, shop_type: str, city: str, state: str\n",
        "    ) -> tuple[bool, dict]:\n",
        "        extracted = {}\n",
        "        try:\n",
        "            for field in available_fields:\n",
        "                try:\n",
        "                    prompt = (\n",
        "                        f\"{FIELD_EXTRACTORS[field]}\\n\\nContent:\\n{aggregate}\\n\\n\"\n",
        "                        f\"Return ONLY the valid structure requested. Respond with nothing but the correct format requested. \"\n",
        "                        f\"If none, say 'none'. Nothing else, nothing before or after our content. Data about {shop_type}, {shop_name}.\"\n",
        "                    )\n",
        "                    raw_value = self._run4(prompt).strip()\n",
        "                    final_value = self.extract_clean_json_structure(raw_value) or raw_value\n",
        "\n",
        "                    if self.validate_extracted_field_value(field, final_value):\n",
        "\n",
        "                        extracted[field] = final_value\n",
        "\n",
        "                except Exception as inner_e:\n",
        "                    print(f\"⚠️ Field extraction failed for '{field}': {inner_e}\")\n",
        "                    continue\n",
        "\n",
        "            return True, extracted if extracted else {}\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"⚠️ extract_fields failed: {e}\")\n",
        "            return False, {}\n",
        "\n",
        "\n",
        "    # ------------ SECTION GENERATION ------------ #\n",
        "    def create_sections(\n",
        "        self, shop_name: str, shop_type: str, aggregate: str,\n",
        "        approved_sections: list[str], city: str | None = None, state: str | None = None\n",
        "    ) -> tuple[bool, dict]:\n",
        "        def _generate(section: str, prompt: str) -> str | None:\n",
        "            raw = self._run4(prompt).strip()\n",
        "            if self.validate_section_html(shop_name, section, raw):\n",
        "                return raw\n",
        "            fixed = self.fix_section_html(shop_name, section, raw)\n",
        "            return fixed if fixed and self.validate_section_html(shop_name, section, fixed) else None\n",
        "\n",
        "        location = f\"in {city}, {state}\" if city or state else \"\"\n",
        "        base_instr = (\n",
        "            f\"You are writing for nearestdoor.com about our listings, about the {shop_type} '{shop_name}' {location}. \"\n",
        "            \"You will get a summary and write useful information according to your assignment which consumers will read on the nearestdoor.com website about this place, no bad info or bad formatting\"\n",
        "            \"Be factual, SEO-friendly, help the users learn use this place and learn about it. no unrelated info, no HTML or asterisks. nothing else, nothing before or after our content. DO NOT USE * \"\n",
        "        )\n",
        "\n",
        "        sections = {}\n",
        "        try:\n",
        "            if \"article\" in approved_sections:\n",
        "                prompt = f\"{base_instr}\\n\\nContent:\\n{aggregate}\\n\\nAssignment: Write a detailed article. Write an article about {shop_name} for nearestdoor.com.\"\n",
        "                result = _generate(\"article\", prompt)\n",
        "                if result:\n",
        "                    sections[\"article\"] = result\n",
        "\n",
        "            if \"faq\" in approved_sections:\n",
        "                prompt = f\"{base_instr}\\n\\nContent:\\n{aggregate}\\n\\nAssignment: Write a detailed FAQ. Write an FAQ about {shop_name} for nearestdoor.com.\"\n",
        "                result = _generate(\"faq\", prompt)\n",
        "                if result:\n",
        "                    sections[\"faq\"] = result\n",
        "\n",
        "            if \"history\" in approved_sections:\n",
        "                prompt = f\"{base_instr}\\n\\nContent:\\n{aggregate}\\n\\nAssignment: Write the history section about {shop_name} for nearestdoor.com.\"\n",
        "                result = _generate(\"history\", prompt)\n",
        "                if result:\n",
        "                    sections[\"history\"] = result\n",
        "\n",
        "            return True, sections\n",
        "        except Exception as e:\n",
        "            print(f\"❌ create_sections error: {e}\")\n",
        "            return False, {}\n",
        "\n",
        "    # ------------ FULL WORKFLOW ------------ #\n",
        "    def process(\n",
        "        self, shop_name: str, shop_type: str, aggregate: str,\n",
        "        city: str | None = None, state: str | None = None\n",
        "    ) -> dict:\n",
        "        result = {\"plan\": [], \"sections\": {}, \"fields\": {}}\n",
        "\n",
        "        if not self.check_aggregate_quality(shop_name, aggregate, shop_type, city, state):\n",
        "            print(\"❌ Aggregate failed quality check.\")\n",
        "            return None\n",
        "\n",
        "        ok, plan = self.create_plan(aggregate, shop_name, shop_type, city, state)\n",
        "        if not ok or not plan:\n",
        "            print(\"❌ No sections can be created.\")\n",
        "            return None\n",
        "        result[\"plan\"] = plan\n",
        "\n",
        "        ok, sections = self.create_sections(shop_name, shop_type, aggregate, city, state)\n",
        "        if ok:\n",
        "            result[\"sections\"] = sections\n",
        "\n",
        "        ok, available = self.extract_available_fields(aggregate, shop_name, shop_type, city, state)\n",
        "        if ok and available:\n",
        "            ok, fields = self.extract_fields(aggregate, available,shop_name, shop_type,city, state)\n",
        "            if ok:\n",
        "                result[\"fields\"] = fields\n",
        "\n",
        "        return result\n",
        "\n",
        "import re\n",
        "import json\n",
        "\n",
        "def is_non_empty_string(value) -> bool:\n",
        "    return isinstance(value, str) and len(value.strip()) > 0\n",
        "\n",
        "def is_valid_json(value) -> bool:\n",
        "    try:\n",
        "        json.loads(value)\n",
        "        return True\n",
        "    except Exception:\n",
        "        return False\n",
        "\n",
        "def is_valid_phone(value) -> bool:\n",
        "    return bool(re.fullmatch(r\"\\d{3}-\\d{3}-\\d{4}\", value.strip()))\n",
        "\n",
        "def is_valid_email(value) -> bool:\n",
        "    return bool(re.fullmatch(r\"[^@\\s]+@[^@\\s]+\\.[a-zA-Z0-9]+\", value.strip()))\n",
        "\n",
        "def is_valid_url(value) -> bool:\n",
        "    return isinstance(value, str) and value.strip().startswith(\"http\")\n",
        "\n",
        "def is_valid_dict(value) -> bool:\n",
        "    try:\n",
        "        return isinstance(json.loads(value), dict)\n",
        "    except Exception:\n",
        "        return False\n",
        "\n",
        "def is_valid_list(value) -> bool:\n",
        "    try:\n",
        "        return isinstance(json.loads(value), list)\n",
        "    except Exception:\n",
        "        return False\n",
        "\n",
        "def is_positive_integer_or_string(value) -> bool:\n",
        "    try:\n",
        "        return int(str(value).strip()) > 0\n",
        "    except Exception:\n",
        "        return False\n",
        "\n",
        "FIELD_VALIDATORS = {\n",
        "    # Contact Info\n",
        "    \"extract_phone\": is_valid_phone,\n",
        "    \"extract_email\": is_valid_email,\n",
        "    \"extract_website\": is_valid_url,\n",
        "\n",
        "    # Structured Fields\n",
        "    \"extract_categories\": is_valid_list,\n",
        "    \"extract_operating_hours\": is_valid_dict,\n",
        "    \"extract_holiday_hours\": is_valid_dict,\n",
        "    \"extract_delivery_services\": is_valid_list,\n",
        "    \"extract_social_media\": is_valid_dict,\n",
        "    \"extract_stocked_brands\": is_valid_list,\n",
        "    \"extract_inventory_categories\": is_valid_dict,\n",
        "    \"extract_customer_reviews\": is_valid_list,\n",
        "\n",
        "    # Event / Misc\n",
        "    \"extract_admission\": is_non_empty_string,\n",
        "    \"extract_date_available\": is_non_empty_string,\n",
        "    \"extract_attendance_amount\": is_positive_integer_or_string,\n",
        "    \"extract_exhibitor_amount\": is_positive_integer_or_string,\n",
        "}\n",
        "FIELD_EXTRACTORS = {\n",
        "    # Contact Information\n",
        "    \"extract_phone\": (\n",
        "        \"Extract the phone number in this format: 727-237-2132. \"\n",
        "        \"Return ONLY the number, no quotes, no text, no comments, no markup.\"\n",
        "    ),\n",
        "    \"extract_email\": (\n",
        "        \"Extract the email address. Example: example@mail.com. \"\n",
        "        \"Return ONLY the email address, no quotes, no text, no extras.\"\n",
        "    ),\n",
        "    \"extract_website\": (\n",
        "        \"Extract the official website URL. Example: https://website.com. \"\n",
        "        \"Return ONLY the URL, no quotes, no text, no markup.\"\n",
        "    ),\n",
        "\n",
        "    # JSON / Structured Fields\n",
        "    \"extract_categories\": (\n",
        "        \"Extract the product/service categories in JSON list format. \"\n",
        "        \"Example: ['Thrift Store', 'Charity']. Return ONLY the JSON array.\"\n",
        "    ),\n",
        "    \"extract_operating_hours\": (\n",
        "        \"Extract weekly operating hours in JSON dictionary format. \"\n",
        "        \"Example: {'monday': '9:00 AM - 5:00 PM', 'sunday': 'Closed'}. \"\n",
        "        \"Return ONLY the JSON object.\"\n",
        "    ),\n",
        "    \"extract_holiday_hours\": (\n",
        "        \"Extract holiday-specific hours in JSON dictionary format. \"\n",
        "        \"Example: {'2024-12-25': 'Closed', '2024-12-31': '10:00 AM - 4:00 PM'}. \"\n",
        "        \"Return ONLY the JSON object.\"\n",
        "    ),\n",
        "    \"extract_delivery_services\": (\n",
        "        \"Extract available delivery services in JSON list format. \"\n",
        "        \"Example: ['Uber Eats', 'Self Delivery']. Return ONLY the JSON array.\"\n",
        "    ),\n",
        "    \"extract_social_media\": (\n",
        "        \"Extract social media links in JSON dictionary format. \"\n",
        "        \"Example: {'facebook': 'https://facebook.com/example', 'instagram': 'https://instagram.com/example'}. \"\n",
        "        \"Return ONLY the JSON object.\"\n",
        "    ),\n",
        "    \"extract_stocked_brands\": (\n",
        "        \"Extract stocked brands in JSON list format. \"\n",
        "        \"Example: ['Nike', 'Adidas']. Return ONLY the JSON array.\"\n",
        "    ),\n",
        "    \"extract_inventory_categories\": (\n",
        "        \"Extract inventory categories in JSON dictionary format. \"\n",
        "        \"Example: {'Apparel': ['Shirts', 'Hoodies']}. Return ONLY the JSON object.\"\n",
        "    ),\n",
        "    \"extract_customer_reviews\": (\n",
        "        \"Extract customer reviews in JSON list format. \"\n",
        "        \"Example: [{'user': 'John', 'comment': 'Great store!', 'rating': 5}]. \"\n",
        "        \"Return ONLY the JSON array.\"\n",
        "    ),\n",
        "\n",
        "    # Event / Scheduling\n",
        "    \"extract_admission\": (\n",
        "        \"Extract the admission cost or entry fee. Return ONLY the plain text, no prefixes or suffixes.\"\n",
        "    ),\n",
        "    \"extract_date_available\": (\n",
        "        \"Extract the available date range or date description. \"\n",
        "        \"Example: 'Available from May 1st to June 30th'. Return ONLY the plain text.\"\n",
        "    ),\n",
        "    \"extract_attendance_amount\": (\n",
        "        \"Extract expected attendance as a number. Example: 500. Return ONLY the number or numeric string.\"\n",
        "    ),\n",
        "    \"extract_exhibitor_amount\": (\n",
        "        \"Extract expected number of exhibitors. Example: 12. Return ONLY the number or numeric string.\"\n",
        "    ),\n",
        "}\n",
        "\n",
        "class NearestDoorClient:\n",
        "    def __init__(self, smartypants, lookup_engine, ollama,  client_id=CLIENT_ID, api_base=API_BASE):\n",
        "        self.client_id = client_id\n",
        "        self.api_base = api_base\n",
        "        self.ollama = ollama\n",
        "        self.lookup_engine = lookup_engine\n",
        "\n",
        "        self.last_heartbeat = 0\n",
        "\n",
        "\n",
        "        self.smartypants = smartypants\n",
        "\n",
        "    def _api_get(self, endpoint, params=None):\n",
        "        try:\n",
        "            print(f\"📡 GET → {endpoint}\")\n",
        "            response = requests.get(f\"{self.api_base}{endpoint}\", params=params or {}, timeout=30)\n",
        "            response.raise_for_status()\n",
        "            return response\n",
        "        except requests.RequestException as e:\n",
        "            print(f\"❌ GET failed: {e}\")\n",
        "            return None\n",
        "\n",
        "    def _api_post(self, endpoint, data):\n",
        "        try:\n",
        "            print(f\"📡 POST → {endpoint}\")\n",
        "            response = requests.post(f\"{self.api_base}{endpoint}\", json=data, timeout=30)\n",
        "            response.raise_for_status()\n",
        "            return response\n",
        "        except requests.RequestException as e:\n",
        "            print(f\"❌ POST failed: {e}\")\n",
        "            return None\n",
        "\n",
        "    def get_task(self):\n",
        "        res = self._api_get(\"/next-task\", params={\"client_id\": self.client_id})\n",
        "        if res and res.status_code == 200:\n",
        "            task = res.json()\n",
        "            if isinstance(task, dict) and \"task_id\" in task:\n",
        "                return task\n",
        "            print(f\"⚠️ Invalid task structure received: {task}\")\n",
        "        return None\n",
        "\n",
        "    def send_heartbeat(self, current_task_id=None):\n",
        "        data = {\"client_id\": self.client_id}\n",
        "        if current_task_id:\n",
        "            data[\"task_id\"] = current_task_id\n",
        "        self._api_post(\"/heartbeat\", data)\n",
        "        print(\"🫀 Heartbeat sent.\")\n",
        "\n",
        "    async def handle_task(self, task):\n",
        "        task_id =task.get(\"task_id\")\n",
        "        task_type =task.get(\"task_type\")\n",
        "        if not task_id or not task_type:\n",
        "            print(\"❌ Invalid task format.\")\n",
        "            return\n",
        "\n",
        "        print(f\"▶️ Handling task {task_type} (ID: {task_id})\")\n",
        "\n",
        "        result, summary, mainstring, images = False, None, None, None\n",
        "        aggregateplan, createdinfo, extractedfields, foundfields = None, None, None, None\n",
        "        print(task)\n",
        "        name = task['target'].get(\"name\")\n",
        "        city = task['target'].get(\"city\")\n",
        "        state = task['target'].get(\"state\")\n",
        "        website_url = task['target'].get(\"website\", None)\n",
        "\n",
        "        shop_type = task['target'].get(\"shop_type\")\n",
        "        aggregate = task['target'].get(\"aggregate\", \"\")\n",
        "        plan = task['target'].get(\"plan\", [])\n",
        "        fields = task['target'].get(\"fields\", [])\n",
        "\n",
        "        match task_type:\n",
        "            case \"search\":\n",
        "                result, mainstring, images = await self.lookup_engine.combined_search(name, city, state, shop_type, website_url)\n",
        "                result = str(result)\n",
        "            case \"aggregate\":\n",
        "                summarizer = ContentSummarizer(self.ollama, name, shop_type, city, state)\n",
        "                summary = summarizer.summarize_content(aggregate)\n",
        "                result = bool(summary)\n",
        "\n",
        "            case \"createplan\":\n",
        "                result, aggregateplan = self.smartypants.create_plan(aggregate, name, shop_type, city, state)\n",
        "\n",
        "            case \"create\":\n",
        "                result, createdinfo = self.smartypants.create_sections(name, shop_type, aggregate, plan, city, state)\n",
        "\n",
        "            case \"find_available_fields\":\n",
        "                result, foundfields = self.smartypants.extract_available_fields(aggregate, name, shop_type, city, state)\n",
        "\n",
        "            case \"extract_fields_from_aggregate\":\n",
        "                result, extractedfields = self.smartypants.extract_fields(aggregate, fields, name, shop_type, city, state)\n",
        "\n",
        "            case _:\n",
        "                print(f\"❌ Unknown task type: {task_type}\")\n",
        "                return\n",
        "        if result:\n",
        "                print(f\"📤 Submitting result for {task_type} ({task_id})\")\n",
        "                try:\n",
        "                    if task_type == 'search':\n",
        "                        res = self._api_post(f\"/submit/{task_id}\", {\"status\": \"success\", \"mainstring\": mainstring, \"client_id\": CLIENT_ID})\n",
        "\n",
        "                    if task_type == 'aggregate':\n",
        "                        if summary:\n",
        "                            res = self._api_post(f\"/submit/{task_id}\", {\"status\": \"success\", \"summary\": summary, \"client_id\": CLIENT_ID})\n",
        "                        else:\n",
        "                            print(\"nosummary\")\n",
        "                            res = self._api_post(f\"/submit/{task_id}\", {\"status\": \"fail\", \"client_id\": CLIENT_ID})\n",
        "\n",
        "\n",
        "                    if task_type == 'createplan':\n",
        "                        res = self._api_post(f\"/submit/{task_id}\", {\"status\": \"success\", \"aggregateplan\": aggregateplan, \"client_id\": CLIENT_ID})\n",
        "                    if task_type == 'create':\n",
        "                        res = self._api_post(f\"/submit/{task_id}\", {\"status\": \"success\", \"createdinfo\":createdinfo, \"client_id\": CLIENT_ID})\n",
        "                    if task_type == 'find_available_fields':\n",
        "                        res = self._api_post(f\"/submit/{task_id}\", {\"status\": \"success\", \"foundfields\": foundfields, \"client_id\": CLIENT_ID})\n",
        "                    if task_type == 'extract_fields_from_aggregate':\n",
        "                        res = self._api_post(f\"/submit/{task_id}\", {\"status\": \"success\", \"extractedfields\": extractedfields, \"client_id\": CLIENT_ID})\n",
        "\n",
        "                    print(f\"Server responded: {res.status_code} - {res.text}\")\n",
        "                    if res:\n",
        "                      if res.status_code == 200:\n",
        "                          print(f\"✅ Submitted: {task_type}\")\n",
        "                      else:\n",
        "                          print(f\"❌ Submit failed: {task_type} - {res.status_code}\")\n",
        "                    else:\n",
        "                      print(f\"❌ Submit failedd: {task_type} - {res.status_code}\")\n",
        "                except Exception as e:\n",
        "                    print(f\"Submit exception: {e}\")\n",
        "        else:\n",
        "\n",
        "            print(f\"Submit Failure {task_type}\")\n",
        "            res = self._api_post(f\"/submit/{task_id}\", {\"status\": \"fail\", \"client_id\": CLIENT_ID})\n",
        "\n",
        "\n",
        "\n",
        "    async def run(self):\n",
        "\n",
        "\n",
        "        try:\n",
        "            while True:\n",
        "                task = self.get_task()\n",
        "                if task:\n",
        "                    now = time.time()\n",
        "                    if now - self.last_heartbeat > HEARTBEAT_INTERVAL:\n",
        "                        self.send_heartbeat(task.get(\"task_id\"))\n",
        "                        self.last_heartbeat = now\n",
        "                    await self.handle_task(task)\n",
        "                else:\n",
        "                    print(\"⏳ No task available, sleeping...\")\n",
        "                    await asyncio.sleep(10)\n",
        "        finally:\n",
        "            print(\"main error\")\n",
        "if __name__ == \"__main__\":\n",
        "    import sys\n",
        "    import asyncio\n",
        "    import nest_asyncio\n",
        "\n",
        "    nest_asyncio.apply()\n",
        "\n",
        "    ollama = OllamaRunner()\n",
        "    smartypants = Smartypants(ollama)\n",
        "    lookup_engine = LookupEngine( ollama)  # Proper initialization\n",
        "\n",
        "    async def main():\n",
        "\n",
        "        await lookup_engine.crawler_manager.start()\n",
        "        client = NearestDoorClient(smartypants, lookup_engine, ollama)\n",
        "        await client.run()\n",
        "\n",
        "    try:\n",
        "\n",
        "        asyncio.run(main())\n",
        "    except KeyboardInterrupt:\n",
        "        print(\"\\n🛑 Shutting down gracefully...\")\n",
        "        sys.exit(0)"
      ],
      "metadata": {
        "id": "g-2rqy_rMlo7",
        "outputId": "0044a4a9-801d-4646-b998-0195f1ad0179",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nohup: appending output to 'nohup.out'\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;36m[\u001b[0m\u001b[36mINIT\u001b[0m\u001b[1;36m]\u001b[0m\u001b[36m...\u001b[0m\u001b[36m. → Crawl4AI \u001b[0m\u001b[1;36m0.6\u001b[0m\u001b[36m.\u001b[0m\u001b[1;36m3\u001b[0m\u001b[36m \u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080\">INIT</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">]</span><span style=\"color: #008080; text-decoration-color: #008080\">.... → Crawl4AI </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6</span><span style=\"color: #008080; text-decoration-color: #008080\">.</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"color: #008080; text-decoration-color: #008080\"> </span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📡 GET → /next-task\n",
            "📡 POST → /heartbeat\n"
          ]
        }
      ]
    }
  ]
}