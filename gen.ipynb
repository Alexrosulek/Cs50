{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Alexrosulek/Cs50/blob/main/gen.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!curl https://ollama.ai/install.sh | sh\n",
        "\n",
        "!echo 'debconf debconf/frontend select Noninteractive' | sudo debconf-set-selections\n",
        "!sudo apt-get update && sudo apt-get install -y cuda-drivers\n",
        "\n",
        "import os\n",
        "\n",
        "# Set LD_LIBRARY_PATH so the system NVIDIA library\n",
        "os.environ.update({'LD_LIBRARY_PATH': '/usr/lib64-nvidia'})\n",
        "!nohup ollama serve &\n",
        "!pip install pyOpenSSL==24.2.1\n",
        "\n",
        "\n",
        "# Pull Ollama Models\n",
        "\n",
        "!ollama pull qwen3:0.6b\n",
        "\n",
        "!ollama pull gemma3:1b\n",
        "!ollama pull gemma3:4b\n",
        "# Install Packages\n",
        "!pip install -q ollama crawl4ai aiohttp pillow beautifulsoup4 wikipedia googlesearch-python playwright nest_asyncio\n",
        "!playwright install chromium\n",
        "!nohup ollama serve &\n",
        "\n"
      ],
      "metadata": {
        "id": "-b9oppEb4cm2",
        "outputId": "f5c58052-9614-42c7-dd2a-1ae5be7c6799",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 13281    0 13281    0     0  35571      0 --:--:-- --:--:-- --:--:-- 35605\n",
            ">>> Installing ollama to /usr/local\n",
            ">>> Downloading Linux amd64 bundle\n",
            "######################################################################## 100.0%\n",
            ">>> Creating ollama user...\n",
            ">>> Adding ollama user to video group...\n",
            ">>> Adding current user to ollama group...\n",
            ">>> Creating ollama systemd service...\n",
            "\u001b[1m\u001b[31mWARNING:\u001b[m systemd is not running\n",
            "\u001b[1m\u001b[31mWARNING:\u001b[m Unable to detect NVIDIA/AMD GPU. Install lspci or lshw to automatically detect and install GPU dependencies.\n",
            ">>> The Ollama API is now available at 127.0.0.1:11434.\n",
            ">>> Install complete. Run \"ollama\" from the command line.\n",
            "Get:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n",
            "Get:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Hit:3 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Get:5 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Get:6 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Get:7 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [1,683 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Get:9 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [8,948 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,547 kB]\n",
            "Hit:11 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Get:12 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [4,379 kB]\n",
            "Hit:13 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,255 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [4,540 kB]\n",
            "Get:16 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease [24.6 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy-backports/main amd64 Packages [83.2 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu jammy-backports/universe amd64 Packages [35.2 kB]\n",
            "Get:19 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2,940 kB]\n",
            "Get:20 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,726 kB]\n",
            "Get:21 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,245 kB]\n",
            "Get:22 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy/main amd64 Packages [77.3 kB]\n",
            "Fetched 31.9 MB in 3s (12.1 MB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  cpp-12 cuda-drivers-575 dctrl-tools dkms fakeroot gcc-12\n",
            "  keyboard-configuration libasan8 libfakeroot libgail-common libgail18\n",
            "  libgcc-12-dev libgtk2.0-0 libgtk2.0-bin libgtk2.0-common libgudev-1.0-0\n",
            "  libjansson4 liblocale-gettext-perl libnvidia-cfg1-575 libnvidia-common-575\n",
            "  libnvidia-compute-575 libnvidia-decode-575 libnvidia-encode-575\n",
            "  libnvidia-extra-575 libnvidia-fbc1-575 libnvidia-gl-575\n",
            "  libnvidia-gpucomp-575 librsvg2-common libtsan2 libudev1 libxcvt0\n",
            "  nvidia-compute-utils-575 nvidia-dkms-575 nvidia-driver-575\n",
            "  nvidia-firmware-575-575.51.03 nvidia-kernel-common-575\n",
            "  nvidia-kernel-source-575 nvidia-modprobe nvidia-settings nvidia-utils-575\n",
            "  python3-xkit screen-resolution-extra switcheroo-control systemd-hwe-hwdb\n",
            "  udev xcvt xserver-xorg-core xserver-xorg-video-nvidia-575\n",
            "Suggested packages:\n",
            "  gcc-12-locales cpp-12-doc debtags menu gcc-12-multilib gcc-12-doc gvfs\n",
            "  xfonts-100dpi | xfonts-75dpi xfonts-scalable\n",
            "Recommended packages:\n",
            "  libnvidia-compute-575:i386 libnvidia-decode-575:i386\n",
            "  libnvidia-encode-575:i386 libnvidia-fbc1-575:i386 libnvidia-gl-575:i386\n",
            "The following NEW packages will be installed:\n",
            "  cpp-12 cuda-drivers cuda-drivers-575 dctrl-tools dkms fakeroot gcc-12\n",
            "  keyboard-configuration libasan8 libfakeroot libgail-common libgail18\n",
            "  libgcc-12-dev libgtk2.0-0 libgtk2.0-bin libgtk2.0-common libgudev-1.0-0\n",
            "  libjansson4 liblocale-gettext-perl libnvidia-cfg1-575 libnvidia-common-575\n",
            "  libnvidia-compute-575 libnvidia-decode-575 libnvidia-encode-575\n",
            "  libnvidia-extra-575 libnvidia-fbc1-575 libnvidia-gl-575\n",
            "  libnvidia-gpucomp-575 librsvg2-common libtsan2 libxcvt0\n",
            "  nvidia-compute-utils-575 nvidia-dkms-575 nvidia-driver-575\n",
            "  nvidia-firmware-575-575.51.03 nvidia-kernel-common-575\n",
            "  nvidia-kernel-source-575 nvidia-modprobe nvidia-settings nvidia-utils-575\n",
            "  python3-xkit screen-resolution-extra switcheroo-control systemd-hwe-hwdb\n",
            "  udev xcvt xserver-xorg-core xserver-xorg-video-nvidia-575\n",
            "The following packages will be upgraded:\n",
            "  libudev1\n",
            "1 upgraded, 48 newly installed, 0 to remove and 88 not upgraded.\n",
            "Need to get 418 MB of archives.\n",
            "After this operation, 1,292 MB of additional disk space will be used.\n",
            "Get:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  libnvidia-decode-575 575.51.03-0ubuntu1 [2,556 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 liblocale-gettext-perl amd64 1.07-4build3 [17.1 kB]\n",
            "Get:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  libnvidia-gpucomp-575 575.51.03-0ubuntu1 [17.8 MB]\n",
            "Get:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  libnvidia-compute-575 575.51.03-0ubuntu1 [54.2 MB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy/main amd64 keyboard-configuration all 1.205ubuntu3 [206 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 cpp-12 amd64 12.3.0-1ubuntu1~22.04 [10.8 MB]\n",
            "Get:7 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  libnvidia-common-575 575.51.03-0ubuntu1 [15.9 kB]\n",
            "Get:8 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  libnvidia-gl-575 575.51.03-0ubuntu1 [132 MB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libasan8 amd64 12.3.0-1ubuntu1~22.04 [2,442 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libtsan2 amd64 12.3.0-1ubuntu1~22.04 [2,477 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgcc-12-dev amd64 12.3.0-1ubuntu1~22.04 [2,618 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 gcc-12 amd64 12.3.0-1ubuntu1~22.04 [21.7 MB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy/main amd64 dctrl-tools amd64 2.24-3build2 [66.9 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 dkms all 2.8.7-2ubuntu2.2 [70.1 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libudev1 amd64 249.11-0ubuntu3.15 [76.6 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 udev amd64 249.11-0ubuntu3.15 [1,557 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy/main amd64 libjansson4 amd64 2.13.1-1.1build3 [32.4 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxcvt0 amd64 0.1.1-3 [5,494 B]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 xserver-xorg-core amd64 2:21.1.4-2ubuntu1.7~22.04.14 [1,478 kB]\n",
            "Get:20 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  nvidia-kernel-source-575 575.51.03-0ubuntu1 [85.5 MB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu jammy/main amd64 libfakeroot amd64 1.28-1ubuntu1 [31.5 kB]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu jammy/main amd64 fakeroot amd64 1.28-1ubuntu1 [60.4 kB]\n",
            "Get:23 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgtk2.0-common all 2.24.33-2ubuntu2.1 [125 kB]\n",
            "Get:24 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgtk2.0-0 amd64 2.24.33-2ubuntu2.1 [2,038 kB]\n",
            "Get:25 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgail18 amd64 2.24.33-2ubuntu2.1 [15.9 kB]\n",
            "Get:26 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgail-common amd64 2.24.33-2ubuntu2.1 [132 kB]\n",
            "Get:27 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgtk2.0-bin amd64 2.24.33-2ubuntu2.1 [7,936 B]\n",
            "Get:28 http://archive.ubuntu.com/ubuntu jammy/main amd64 libgudev-1.0-0 amd64 1:237-2build1 [16.3 kB]\n",
            "Get:29 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 librsvg2-common amd64 2.52.5+dfsg-3ubuntu0.2 [17.7 kB]\n",
            "Get:30 http://archive.ubuntu.com/ubuntu jammy/main amd64 python3-xkit all 0.5.0ubuntu5 [18.5 kB]\n",
            "Get:31 http://archive.ubuntu.com/ubuntu jammy/main amd64 screen-resolution-extra all 0.18.2 [4,396 B]\n",
            "Get:32 http://archive.ubuntu.com/ubuntu jammy/main amd64 switcheroo-control amd64 2.4-3build2 [16.5 kB]\n",
            "Get:33 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 systemd-hwe-hwdb all 249.11.5 [3,228 B]\n",
            "Get:34 http://archive.ubuntu.com/ubuntu jammy/main amd64 xcvt amd64 0.1.1-3 [7,140 B]\n",
            "Get:35 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  nvidia-firmware-575-575.51.03 575.51.03-0ubuntu1 [74.7 MB]\n",
            "Get:36 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  nvidia-modprobe 575.51.03-0ubuntu1 [14.9 kB]\n",
            "Get:37 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  nvidia-kernel-common-575 575.51.03-0ubuntu1 [1,245 kB]\n",
            "Get:38 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  nvidia-dkms-575 575.51.03-0ubuntu1 [14.9 kB]\n",
            "Get:39 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  libnvidia-extra-575 575.51.03-0ubuntu1 [73.2 kB]\n",
            "Get:40 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  nvidia-compute-utils-575 575.51.03-0ubuntu1 [109 kB]\n",
            "Get:41 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  libnvidia-encode-575 575.51.03-0ubuntu1 [105 kB]\n",
            "Get:42 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  nvidia-utils-575 575.51.03-0ubuntu1 [534 kB]\n",
            "Get:43 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  libnvidia-cfg1-575 575.51.03-0ubuntu1 [146 kB]\n",
            "Get:44 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  xserver-xorg-video-nvidia-575 575.51.03-0ubuntu1 [1,696 kB]\n",
            "Get:45 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  libnvidia-fbc1-575 575.51.03-0ubuntu1 [98.1 kB]\n",
            "Get:46 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  nvidia-driver-575 575.51.03-0ubuntu1 [497 kB]\n",
            "Get:47 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  cuda-drivers-575 575.51.03-0ubuntu1 [2,538 B]\n",
            "Get:48 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  cuda-drivers 575.51.03-0ubuntu1 [2,490 B]\n",
            "Get:49 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  nvidia-settings 575.51.03-0ubuntu1 [957 kB]\n",
            "Fetched 418 MB in 6s (71.8 MB/s)\n",
            "Extracting templates from packages: 100%\n",
            "Preconfiguring packages ...\n",
            "Selecting previously unselected package liblocale-gettext-perl.\n",
            "(Reading database ... 126102 files and directories currently installed.)\n",
            "Preparing to unpack .../0-liblocale-gettext-perl_1.07-4build3_amd64.deb ...\n",
            "Unpacking liblocale-gettext-perl (1.07-4build3) ...\n",
            "Selecting previously unselected package keyboard-configuration.\n",
            "Preparing to unpack .../1-keyboard-configuration_1.205ubuntu3_all.deb ...\n",
            "Unpacking keyboard-configuration (1.205ubuntu3) ...\n",
            "Selecting previously unselected package cpp-12.\n",
            "Preparing to unpack .../2-cpp-12_12.3.0-1ubuntu1~22.04_amd64.deb ...\n",
            "Unpacking cpp-12 (12.3.0-1ubuntu1~22.04) ...\n",
            "Selecting previously unselected package libasan8:amd64.\n",
            "Preparing to unpack .../3-libasan8_12.3.0-1ubuntu1~22.04_amd64.deb ...\n",
            "Unpacking libasan8:amd64 (12.3.0-1ubuntu1~22.04) ...\n",
            "Selecting previously unselected package libtsan2:amd64.\n",
            "Preparing to unpack .../4-libtsan2_12.3.0-1ubuntu1~22.04_amd64.deb ...\n",
            "Unpacking libtsan2:amd64 (12.3.0-1ubuntu1~22.04) ...\n",
            "Selecting previously unselected package libgcc-12-dev:amd64.\n",
            "Preparing to unpack .../5-libgcc-12-dev_12.3.0-1ubuntu1~22.04_amd64.deb ...\n",
            "Unpacking libgcc-12-dev:amd64 (12.3.0-1ubuntu1~22.04) ...\n",
            "Selecting previously unselected package gcc-12.\n",
            "Preparing to unpack .../6-gcc-12_12.3.0-1ubuntu1~22.04_amd64.deb ...\n",
            "Unpacking gcc-12 (12.3.0-1ubuntu1~22.04) ...\n",
            "Selecting previously unselected package dctrl-tools.\n",
            "Preparing to unpack .../7-dctrl-tools_2.24-3build2_amd64.deb ...\n",
            "Unpacking dctrl-tools (2.24-3build2) ...\n",
            "Selecting previously unselected package dkms.\n",
            "Preparing to unpack .../8-dkms_2.8.7-2ubuntu2.2_all.deb ...\n",
            "Unpacking dkms (2.8.7-2ubuntu2.2) ...\n",
            "Preparing to unpack .../9-libudev1_249.11-0ubuntu3.15_amd64.deb ...\n",
            "Unpacking libudev1:amd64 (249.11-0ubuntu3.15) over (249.11-0ubuntu3.12) ...\n",
            "Setting up libudev1:amd64 (249.11-0ubuntu3.15) ...\n",
            "Selecting previously unselected package udev.\n",
            "(Reading database ... 126462 files and directories currently installed.)\n",
            "Preparing to unpack .../00-udev_249.11-0ubuntu3.15_amd64.deb ...\n",
            "Unpacking udev (249.11-0ubuntu3.15) ...\n",
            "Selecting previously unselected package libjansson4:amd64.\n",
            "Preparing to unpack .../01-libjansson4_2.13.1-1.1build3_amd64.deb ...\n",
            "Unpacking libjansson4:amd64 (2.13.1-1.1build3) ...\n",
            "Selecting previously unselected package libnvidia-decode-575:amd64.\n",
            "Preparing to unpack .../02-libnvidia-decode-575_575.51.03-0ubuntu1_amd64.deb ...\n",
            "Unpacking libnvidia-decode-575:amd64 (575.51.03-0ubuntu1) ...\n",
            "Selecting previously unselected package libnvidia-gpucomp-575:amd64.\n",
            "Preparing to unpack .../03-libnvidia-gpucomp-575_575.51.03-0ubuntu1_amd64.deb ...\n",
            "Unpacking libnvidia-gpucomp-575:amd64 (575.51.03-0ubuntu1) ...\n",
            "Selecting previously unselected package libnvidia-compute-575:amd64.\n",
            "Preparing to unpack .../04-libnvidia-compute-575_575.51.03-0ubuntu1_amd64.deb ...\n",
            "Unpacking libnvidia-compute-575:amd64 (575.51.03-0ubuntu1) ...\n",
            "Selecting previously unselected package libnvidia-common-575.\n",
            "Preparing to unpack .../05-libnvidia-common-575_575.51.03-0ubuntu1_all.deb ...\n",
            "Unpacking libnvidia-common-575 (575.51.03-0ubuntu1) ...\n",
            "Selecting previously unselected package libnvidia-gl-575:amd64.\n",
            "Preparing to unpack .../06-libnvidia-gl-575_575.51.03-0ubuntu1_amd64.deb ...\n",
            "dpkg-query: no packages found matching libnvidia-gl-535\n",
            "Unpacking libnvidia-gl-575:amd64 (575.51.03-0ubuntu1) ...\n",
            "Selecting previously unselected package nvidia-kernel-source-575.\n",
            "Preparing to unpack .../07-nvidia-kernel-source-575_575.51.03-0ubuntu1_amd64.deb ...\n",
            "Unpacking nvidia-kernel-source-575 (575.51.03-0ubuntu1) ...\n",
            "Selecting previously unselected package nvidia-firmware-575-575.51.03.\n",
            "Preparing to unpack .../08-nvidia-firmware-575-575.51.03_575.51.03-0ubuntu1_amd64.deb ...\n",
            "Unpacking nvidia-firmware-575-575.51.03 (575.51.03-0ubuntu1) ...\n",
            "Selecting previously unselected package nvidia-modprobe.\n",
            "Preparing to unpack .../09-nvidia-modprobe_575.51.03-0ubuntu1_amd64.deb ...\n",
            "Unpacking nvidia-modprobe (575.51.03-0ubuntu1) ...\n",
            "Selecting previously unselected package nvidia-kernel-common-575.\n",
            "Preparing to unpack .../10-nvidia-kernel-common-575_575.51.03-0ubuntu1_amd64.deb ...\n",
            "Unpacking nvidia-kernel-common-575 (575.51.03-0ubuntu1) ...\n",
            "Selecting previously unselected package nvidia-dkms-575.\n",
            "Preparing to unpack .../11-nvidia-dkms-575_575.51.03-0ubuntu1_amd64.deb ...\n",
            "Unpacking nvidia-dkms-575 (575.51.03-0ubuntu1) ...\n",
            "Selecting previously unselected package libnvidia-extra-575:amd64.\n",
            "Preparing to unpack .../12-libnvidia-extra-575_575.51.03-0ubuntu1_amd64.deb ...\n",
            "Unpacking libnvidia-extra-575:amd64 (575.51.03-0ubuntu1) ...\n",
            "Selecting previously unselected package nvidia-compute-utils-575.\n",
            "Preparing to unpack .../13-nvidia-compute-utils-575_575.51.03-0ubuntu1_amd64.deb ...\n",
            "Unpacking nvidia-compute-utils-575 (575.51.03-0ubuntu1) ...\n",
            "Selecting previously unselected package libnvidia-encode-575:amd64.\n",
            "Preparing to unpack .../14-libnvidia-encode-575_575.51.03-0ubuntu1_amd64.deb ...\n",
            "Unpacking libnvidia-encode-575:amd64 (575.51.03-0ubuntu1) ...\n",
            "Selecting previously unselected package nvidia-utils-575.\n",
            "Preparing to unpack .../15-nvidia-utils-575_575.51.03-0ubuntu1_amd64.deb ...\n",
            "Unpacking nvidia-utils-575 (575.51.03-0ubuntu1) ...\n",
            "Selecting previously unselected package libnvidia-cfg1-575:amd64.\n",
            "Preparing to unpack .../16-libnvidia-cfg1-575_575.51.03-0ubuntu1_amd64.deb ...\n",
            "Unpacking libnvidia-cfg1-575:amd64 (575.51.03-0ubuntu1) ...\n",
            "Selecting previously unselected package libxcvt0:amd64.\n",
            "Preparing to unpack .../17-libxcvt0_0.1.1-3_amd64.deb ...\n",
            "Unpacking libxcvt0:amd64 (0.1.1-3) ...\n",
            "Selecting previously unselected package xserver-xorg-core.\n",
            "Preparing to unpack .../18-xserver-xorg-core_2%3a21.1.4-2ubuntu1.7~22.04.14_amd64.deb ...\n",
            "Unpacking xserver-xorg-core (2:21.1.4-2ubuntu1.7~22.04.14) ...\n",
            "Selecting previously unselected package xserver-xorg-video-nvidia-575.\n",
            "Preparing to unpack .../19-xserver-xorg-video-nvidia-575_575.51.03-0ubuntu1_amd64.deb ...\n",
            "Unpacking xserver-xorg-video-nvidia-575 (575.51.03-0ubuntu1) ...\n",
            "Selecting previously unselected package libnvidia-fbc1-575:amd64.\n",
            "Preparing to unpack .../20-libnvidia-fbc1-575_575.51.03-0ubuntu1_amd64.deb ...\n",
            "Unpacking libnvidia-fbc1-575:amd64 (575.51.03-0ubuntu1) ...\n",
            "Selecting previously unselected package nvidia-driver-575.\n",
            "Preparing to unpack .../21-nvidia-driver-575_575.51.03-0ubuntu1_amd64.deb ...\n",
            "Unpacking nvidia-driver-575 (575.51.03-0ubuntu1) ...\n",
            "Selecting previously unselected package cuda-drivers-575.\n",
            "Preparing to unpack .../22-cuda-drivers-575_575.51.03-0ubuntu1_amd64.deb ...\n",
            "Unpacking cuda-drivers-575 (575.51.03-0ubuntu1) ...\n",
            "Selecting previously unselected package cuda-drivers.\n",
            "Preparing to unpack .../23-cuda-drivers_575.51.03-0ubuntu1_amd64.deb ...\n",
            "Unpacking cuda-drivers (575.51.03-0ubuntu1) ...\n",
            "Selecting previously unselected package libfakeroot:amd64.\n",
            "Preparing to unpack .../24-libfakeroot_1.28-1ubuntu1_amd64.deb ...\n",
            "Unpacking libfakeroot:amd64 (1.28-1ubuntu1) ...\n",
            "Selecting previously unselected package fakeroot.\n",
            "Preparing to unpack .../25-fakeroot_1.28-1ubuntu1_amd64.deb ...\n",
            "Unpacking fakeroot (1.28-1ubuntu1) ...\n",
            "Selecting previously unselected package libgtk2.0-common.\n",
            "Preparing to unpack .../26-libgtk2.0-common_2.24.33-2ubuntu2.1_all.deb ...\n",
            "Unpacking libgtk2.0-common (2.24.33-2ubuntu2.1) ...\n",
            "Selecting previously unselected package libgtk2.0-0:amd64.\n",
            "Preparing to unpack .../27-libgtk2.0-0_2.24.33-2ubuntu2.1_amd64.deb ...\n",
            "Unpacking libgtk2.0-0:amd64 (2.24.33-2ubuntu2.1) ...\n",
            "Selecting previously unselected package libgail18:amd64.\n",
            "Preparing to unpack .../28-libgail18_2.24.33-2ubuntu2.1_amd64.deb ...\n",
            "Unpacking libgail18:amd64 (2.24.33-2ubuntu2.1) ...\n",
            "Selecting previously unselected package libgail-common:amd64.\n",
            "Preparing to unpack .../29-libgail-common_2.24.33-2ubuntu2.1_amd64.deb ...\n",
            "Unpacking libgail-common:amd64 (2.24.33-2ubuntu2.1) ...\n",
            "Selecting previously unselected package libgtk2.0-bin.\n",
            "Preparing to unpack .../30-libgtk2.0-bin_2.24.33-2ubuntu2.1_amd64.deb ...\n",
            "Unpacking libgtk2.0-bin (2.24.33-2ubuntu2.1) ...\n",
            "Selecting previously unselected package libgudev-1.0-0:amd64.\n",
            "Preparing to unpack .../31-libgudev-1.0-0_1%3a237-2build1_amd64.deb ...\n",
            "Unpacking libgudev-1.0-0:amd64 (1:237-2build1) ...\n",
            "Selecting previously unselected package librsvg2-common:amd64.\n",
            "Preparing to unpack .../32-librsvg2-common_2.52.5+dfsg-3ubuntu0.2_amd64.deb ...\n",
            "Unpacking librsvg2-common:amd64 (2.52.5+dfsg-3ubuntu0.2) ...\n",
            "Selecting previously unselected package python3-xkit.\n",
            "Preparing to unpack .../33-python3-xkit_0.5.0ubuntu5_all.deb ...\n",
            "Unpacking python3-xkit (0.5.0ubuntu5) ...\n",
            "Selecting previously unselected package screen-resolution-extra.\n",
            "Preparing to unpack .../34-screen-resolution-extra_0.18.2_all.deb ...\n",
            "Unpacking screen-resolution-extra (0.18.2) ...\n",
            "Selecting previously unselected package nvidia-settings.\n",
            "Preparing to unpack .../35-nvidia-settings_575.51.03-0ubuntu1_amd64.deb ...\n",
            "Unpacking nvidia-settings (575.51.03-0ubuntu1) ...\n",
            "Selecting previously unselected package switcheroo-control.\n",
            "Preparing to unpack .../36-switcheroo-control_2.4-3build2_amd64.deb ...\n",
            "Unpacking switcheroo-control (2.4-3build2) ...\n",
            "Selecting previously unselected package systemd-hwe-hwdb.\n",
            "Preparing to unpack .../37-systemd-hwe-hwdb_249.11.5_all.deb ...\n",
            "Unpacking systemd-hwe-hwdb (249.11.5) ...\n",
            "Selecting previously unselected package xcvt.\n",
            "Preparing to unpack .../38-xcvt_0.1.1-3_amd64.deb ...\n",
            "Unpacking xcvt (0.1.1-3) ...\n",
            "Setting up cpp-12 (12.3.0-1ubuntu1~22.04) ...\n",
            "Setting up libnvidia-gpucomp-575:amd64 (575.51.03-0ubuntu1) ...\n",
            "Setting up libfakeroot:amd64 (1.28-1ubuntu1) ...\n",
            "Setting up libjansson4:amd64 (2.13.1-1.1build3) ...\n",
            "Setting up nvidia-modprobe (575.51.03-0ubuntu1) ...\n",
            "Setting up fakeroot (1.28-1ubuntu1) ...\n",
            "update-alternatives: using /usr/bin/fakeroot-sysv to provide /usr/bin/fakeroot (fakeroot) in auto mode\n",
            "Setting up nvidia-kernel-source-575 (575.51.03-0ubuntu1) ...\n",
            "Setting up libnvidia-fbc1-575:amd64 (575.51.03-0ubuntu1) ...\n",
            "Setting up udev (249.11-0ubuntu3.15) ...\n",
            "invoke-rc.d: could not determine current runlevel\n",
            "invoke-rc.d: policy-rc.d denied execution of start.\n",
            "Setting up librsvg2-common:amd64 (2.52.5+dfsg-3ubuntu0.2) ...\n",
            "Setting up systemd-hwe-hwdb (249.11.5) ...\n",
            "Setting up nvidia-firmware-575-575.51.03 (575.51.03-0ubuntu1) ...\n",
            "Setting up libasan8:amd64 (12.3.0-1ubuntu1~22.04) ...\n",
            "Setting up libxcvt0:amd64 (0.1.1-3) ...\n",
            "Setting up libnvidia-common-575 (575.51.03-0ubuntu1) ...\n",
            "Setting up libgtk2.0-common (2.24.33-2ubuntu2.1) ...\n",
            "Setting up libtsan2:amd64 (12.3.0-1ubuntu1~22.04) ...\n",
            "Setting up libnvidia-extra-575:amd64 (575.51.03-0ubuntu1) ...\n",
            "Setting up python3-xkit (0.5.0ubuntu5) ...\n",
            "Setting up libnvidia-cfg1-575:amd64 (575.51.03-0ubuntu1) ...\n",
            "Setting up liblocale-gettext-perl (1.07-4build3) ...\n",
            "Setting up libgudev-1.0-0:amd64 (1:237-2build1) ...\n",
            "Setting up dctrl-tools (2.24-3build2) ...\n",
            "Setting up libgtk2.0-0:amd64 (2.24.33-2ubuntu2.1) ...\n",
            "Setting up xcvt (0.1.1-3) ...\n",
            "Setting up libgcc-12-dev:amd64 (12.3.0-1ubuntu1~22.04) ...\n",
            "Setting up nvidia-kernel-common-575 (575.51.03-0ubuntu1) ...\n",
            "Setting up screen-resolution-extra (0.18.2) ...\n",
            "Setting up libgail18:amd64 (2.24.33-2ubuntu2.1) ...\n",
            "Setting up libgtk2.0-bin (2.24.33-2ubuntu2.1) ...\n",
            "Setting up switcheroo-control (2.4-3build2) ...\n",
            "Created symlink /etc/systemd/system/graphical.target.wants/switcheroo-control.service â†’ /lib/systemd/system/switcheroo-control.service.\n",
            "Setting up nvidia-settings (575.51.03-0ubuntu1) ...\n",
            "Setting up keyboard-configuration (1.205ubuntu3) ...\n",
            "Your console font configuration will be updated the next time your system\n",
            "boots. If you want to update it now, run 'setupcon' from a virtual console.\n",
            "Setting up libgail-common:amd64 (2.24.33-2ubuntu2.1) ...\n",
            "Setting up xserver-xorg-core (2:21.1.4-2ubuntu1.7~22.04.14) ...\n",
            "Setting up xserver-xorg-video-nvidia-575 (575.51.03-0ubuntu1) ...\n",
            "Setting up gcc-12 (12.3.0-1ubuntu1~22.04) ...\n",
            "Setting up dkms (2.8.7-2ubuntu2.2) ...\n",
            "Setting up nvidia-dkms-575 (575.51.03-0ubuntu1) ...\n",
            "Loading new nvidia-575.51.03 DKMS files...\n",
            "It is likely that 6.1.123+ belongs to a chroot's host\n",
            "Building for 5.15.0-139-generic\n",
            "Building for architecture x86_64\n",
            "Building initial module for 5.15.0-139-generic\n",
            "Done.\n",
            "\n",
            "nvidia.ko:\n",
            "Running module version sanity check.\n",
            " - Original module\n",
            "   - No original module exists within this kernel\n",
            " - Installation\n",
            "   - Installing to /lib/modules/5.15.0-139-generic/updates/dkms/\n",
            "\n",
            "nvidia-modeset.ko:\n",
            "Running module version sanity check.\n",
            " - Original module\n",
            "   - No original module exists within this kernel\n",
            " - Installation\n",
            "   - Installing to /lib/modules/5.15.0-139-generic/updates/dkms/\n",
            "\n",
            "nvidia-drm.ko:\n",
            "Running module version sanity check.\n",
            " - Original module\n",
            "   - No original module exists within this kernel\n",
            " - Installation\n",
            "   - Installing to /lib/modules/5.15.0-139-generic/updates/dkms/\n",
            "\n",
            "nvidia-uvm.ko:\n",
            "Running module version sanity check.\n",
            " - Original module\n",
            "   - No original module exists within this kernel\n",
            " - Installation\n",
            "   - Installing to /lib/modules/5.15.0-139-generic/updates/dkms/\n",
            "\n",
            "nvidia-peermem.ko:\n",
            "Running module version sanity check.\n",
            " - Original module\n",
            "   - No original module exists within this kernel\n",
            " - Installation\n",
            "   - Installing to /lib/modules/5.15.0-139-generic/updates/dkms/\n",
            "\n",
            "depmod...\n",
            "Setting up libnvidia-decode-575:amd64 (575.51.03-0ubuntu1) ...\n",
            "Setting up libnvidia-compute-575:amd64 (575.51.03-0ubuntu1) ...\n",
            "Setting up libnvidia-encode-575:amd64 (575.51.03-0ubuntu1) ...\n",
            "Setting up nvidia-utils-575 (575.51.03-0ubuntu1) ...\n",
            "Setting up nvidia-compute-utils-575 (575.51.03-0ubuntu1) ...\n",
            "Setting up libnvidia-gl-575:amd64 (575.51.03-0ubuntu1) ...\n",
            "Setting up nvidia-driver-575 (575.51.03-0ubuntu1) ...\n",
            "Setting up cuda-drivers-575 (575.51.03-0ubuntu1) ...\n",
            "Setting up cuda-drivers (575.51.03-0ubuntu1) ...\n",
            "Processing triggers for libgdk-pixbuf-2.0-0:amd64 (2.42.8+dfsg-1ubuntu0.3) ...\n",
            "Processing triggers for mailcap (3.70+nmu1ubuntu1) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.8) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for dbus (1.12.20-2ubuntu4.1) ...\n",
            "nohup: appending output to 'nohup.out'\n",
            "Requirement already satisfied: pyOpenSSL==24.2.1 in /usr/local/lib/python3.11/dist-packages (24.2.1)\n",
            "Requirement already satisfied: cryptography<44,>=41.0.5 in /usr/local/lib/python3.11/dist-packages (from pyOpenSSL==24.2.1) (43.0.3)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography<44,>=41.0.5->pyOpenSSL==24.2.1) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography<44,>=41.0.5->pyOpenSSL==24.2.1) (2.22)\n",
            "\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\n",
            "\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\n",
            "\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m292.8/292.8 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m71.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m45.1/45.1 MB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m92.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m161.7/161.7 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m7.9/7.9 MB\u001b[0m \u001b[31m112.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m278.0/278.0 kB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.8/56.8 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m93.0/93.0 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m647.0/647.0 kB\u001b[0m \u001b[31m43.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for wikipedia (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "pydrive2 1.21.3 requires pyOpenSSL<=24.2.1,>=19.1.0, but you have pyopenssl 25.1.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mDownloading Chromium 136.0.7103.25 (playwright build v1169)\u001b[2m from https://cdn.playwright.dev/dbazure/download/playwright/builds/chromium/1169/chromium-linux.zip\u001b[22m\n",
            "\u001b[1G167.7 MiB [] 0% 127.6s\u001b[0K\u001b[1G167.7 MiB [] 0% 22.9s\u001b[0K\u001b[1G167.7 MiB [] 0% 9.8s\u001b[0K\u001b[1G167.7 MiB [] 1% 4.5s\u001b[0K\u001b[1G167.7 MiB [] 1% 3.2s\u001b[0K\u001b[1G167.7 MiB [] 3% 2.6s\u001b[0K\u001b[1G167.7 MiB [] 4% 2.2s\u001b[0K\u001b[1G167.7 MiB [] 5% 2.0s\u001b[0K\u001b[1G167.7 MiB [] 5% 2.1s\u001b[0K\u001b[1G167.7 MiB [] 6% 2.0s\u001b[0K\u001b[1G167.7 MiB [] 7% 1.9s\u001b[0K\u001b[1G167.7 MiB [] 9% 1.8s\u001b[0K\u001b[1G167.7 MiB [] 11% 1.7s\u001b[0K\u001b[1G167.7 MiB [] 12% 1.5s\u001b[0K\u001b[1G167.7 MiB [] 13% 1.6s\u001b[0K\u001b[1G167.7 MiB [] 14% 1.5s\u001b[0K\u001b[1G167.7 MiB [] 16% 1.4s\u001b[0K\u001b[1G167.7 MiB [] 17% 1.4s\u001b[0K\u001b[1G167.7 MiB [] 18% 1.3s\u001b[0K\u001b[1G167.7 MiB [] 20% 1.3s\u001b[0K\u001b[1G167.7 MiB [] 21% 1.2s\u001b[0K\u001b[1G167.7 MiB [] 22% 1.2s\u001b[0K\u001b[1G167.7 MiB [] 24% 1.2s\u001b[0K\u001b[1G167.7 MiB [] 25% 1.1s\u001b[0K\u001b[1G167.7 MiB [] 27% 1.1s\u001b[0K\u001b[1G167.7 MiB [] 28% 1.1s\u001b[0K\u001b[1G167.7 MiB [] 29% 1.1s\u001b[0K\u001b[1G167.7 MiB [] 31% 1.0s\u001b[0K\u001b[1G167.7 MiB [] 33% 1.0s\u001b[0K\u001b[1G167.7 MiB [] 34% 1.0s\u001b[0K\u001b[1G167.7 MiB [] 35% 0.9s\u001b[0K\u001b[1G167.7 MiB [] 37% 0.9s\u001b[0K\u001b[1G167.7 MiB [] 39% 0.9s\u001b[0K\u001b[1G167.7 MiB [] 40% 0.9s\u001b[0K\u001b[1G167.7 MiB [] 41% 0.8s\u001b[0K\u001b[1G167.7 MiB [] 42% 0.8s\u001b[0K\u001b[1G167.7 MiB [] 43% 0.8s\u001b[0K\u001b[1G167.7 MiB [] 43% 0.9s\u001b[0K\u001b[1G167.7 MiB [] 44% 0.8s\u001b[0K\u001b[1G167.7 MiB [] 45% 0.8s\u001b[0K\u001b[1G167.7 MiB [] 46% 0.8s\u001b[0K\u001b[1G167.7 MiB [] 47% 0.8s\u001b[0K\u001b[1G167.7 MiB [] 48% 0.8s\u001b[0K\u001b[1G167.7 MiB [] 49% 0.8s\u001b[0K\u001b[1G167.7 MiB [] 51% 0.8s\u001b[0K\u001b[1G167.7 MiB [] 53% 0.7s\u001b[0K\u001b[1G167.7 MiB [] 54% 0.7s\u001b[0K\u001b[1G167.7 MiB [] 55% 0.7s\u001b[0K\u001b[1G167.7 MiB [] 56% 0.7s\u001b[0K\u001b[1G167.7 MiB [] 57% 0.7s\u001b[0K\u001b[1G167.7 MiB [] 59% 0.6s\u001b[0K\u001b[1G167.7 MiB [] 60% 0.6s\u001b[0K\u001b[1G167.7 MiB [] 61% 0.6s\u001b[0K\u001b[1G167.7 MiB [] 62% 0.6s\u001b[0K\u001b[1G167.7 MiB [] 64% 0.6s\u001b[0K\u001b[1G167.7 MiB [] 65% 0.5s\u001b[0K\u001b[1G167.7 MiB [] 66% 0.5s\u001b[0K\u001b[1G167.7 MiB [] 67% 0.5s\u001b[0K\u001b[1G167.7 MiB [] 68% 0.5s\u001b[0K\u001b[1G167.7 MiB [] 69% 0.5s\u001b[0K\u001b[1G167.7 MiB [] 71% 0.4s\u001b[0K\u001b[1G167.7 MiB [] 72% 0.4s\u001b[0K\u001b[1G167.7 MiB [] 73% 0.4s\u001b[0K\u001b[1G167.7 MiB [] 74% 0.4s\u001b[0K\u001b[1G167.7 MiB [] 76% 0.4s\u001b[0K\u001b[1G167.7 MiB [] 77% 0.3s\u001b[0K\u001b[1G167.7 MiB [] 78% 0.3s\u001b[0K\u001b[1G167.7 MiB [] 79% 0.3s\u001b[0K\u001b[1G167.7 MiB [] 80% 0.3s\u001b[0K\u001b[1G167.7 MiB [] 82% 0.3s\u001b[0K\u001b[1G167.7 MiB [] 83% 0.2s\u001b[0K\u001b[1G167.7 MiB [] 84% 0.2s\u001b[0K\u001b[1G167.7 MiB [] 85% 0.2s\u001b[0K\u001b[1G167.7 MiB [] 87% 0.2s\u001b[0K\u001b[1G167.7 MiB [] 88% 0.2s\u001b[0K\u001b[1G167.7 MiB [] 89% 0.2s\u001b[0K\u001b[1G167.7 MiB [] 90% 0.1s\u001b[0K\u001b[1G167.7 MiB [] 92% 0.1s\u001b[0K\u001b[1G167.7 MiB [] 93% 0.1s\u001b[0K\u001b[1G167.7 MiB [] 94% 0.1s\u001b[0K\u001b[1G167.7 MiB [] 95% 0.1s\u001b[0K\u001b[1G167.7 MiB [] 96% 0.0s\u001b[0K\u001b[1G167.7 MiB [] 98% 0.0s\u001b[0K\u001b[1G167.7 MiB [] 100% 0.0s\u001b[0K\n",
            "Chromium 136.0.7103.25 (playwright build v1169) downloaded to /root/.cache/ms-playwright/chromium-1169\n",
            "Downloading FFMPEG playwright build v1011\u001b[2m from https://cdn.playwright.dev/dbazure/download/playwright/builds/ffmpeg/1011/ffmpeg-linux.zip\u001b[22m\n",
            "\u001b[1G2.3 MiB [] 0% 0.0s\u001b[0K\u001b[1G2.3 MiB [] 6% 0.2s\u001b[0K\u001b[1G2.3 MiB [] 32% 0.1s\u001b[0K\u001b[1G2.3 MiB [] 95% 0.0s\u001b[0K\u001b[1G2.3 MiB [] 100% 0.0s\u001b[0K\n",
            "FFMPEG playwright build v1011 downloaded to /root/.cache/ms-playwright/ffmpeg-1011\n",
            "Downloading Chromium Headless Shell 136.0.7103.25 (playwright build v1169)\u001b[2m from https://cdn.playwright.dev/dbazure/download/playwright/builds/chromium/1169/chromium-headless-shell-linux.zip\u001b[22m\n",
            "\u001b[1G101.4 MiB [] 0% 0.0s\u001b[0K\u001b[1G101.4 MiB [] 0% 17.7s\u001b[0K\u001b[1G101.4 MiB [] 0% 9.9s\u001b[0K\u001b[1G101.4 MiB [] 1% 4.7s\u001b[0K\u001b[1G101.4 MiB [] 2% 2.4s\u001b[0K\u001b[1G101.4 MiB [] 4% 1.9s\u001b[0K\u001b[1G101.4 MiB [] 6% 1.5s\u001b[0K\u001b[1G101.4 MiB [] 7% 1.4s\u001b[0K\u001b[1G101.4 MiB [] 9% 1.3s\u001b[0K\u001b[1G101.4 MiB [] 11% 1.2s\u001b[0K\u001b[1G101.4 MiB [] 13% 1.2s\u001b[0K\u001b[1G101.4 MiB [] 15% 1.1s\u001b[0K\u001b[1G101.4 MiB [] 16% 1.1s\u001b[0K\u001b[1G101.4 MiB [] 17% 1.0s\u001b[0K\u001b[1G101.4 MiB [] 19% 1.0s\u001b[0K\u001b[1G101.4 MiB [] 22% 0.9s\u001b[0K\u001b[1G101.4 MiB [] 23% 0.9s\u001b[0K\u001b[1G101.4 MiB [] 25% 0.8s\u001b[0K\u001b[1G101.4 MiB [] 27% 0.8s\u001b[0K\u001b[1G101.4 MiB [] 30% 0.7s\u001b[0K\u001b[1G101.4 MiB [] 33% 0.7s\u001b[0K\u001b[1G101.4 MiB [] 35% 0.6s\u001b[0K\u001b[1G101.4 MiB [] 38% 0.6s\u001b[0K\u001b[1G101.4 MiB [] 40% 0.6s\u001b[0K\u001b[1G101.4 MiB [] 42% 0.5s\u001b[0K\u001b[1G101.4 MiB [] 43% 0.5s\u001b[0K\u001b[1G101.4 MiB [] 44% 0.5s\u001b[0K\u001b[1G101.4 MiB [] 46% 0.5s\u001b[0K\u001b[1G101.4 MiB [] 49% 0.5s\u001b[0K\u001b[1G101.4 MiB [] 51% 0.5s\u001b[0K\u001b[1G101.4 MiB [] 54% 0.4s\u001b[0K\u001b[1G101.4 MiB [] 56% 0.4s\u001b[0K\u001b[1G101.4 MiB [] 60% 0.4s\u001b[0K\u001b[1G101.4 MiB [] 63% 0.3s\u001b[0K\u001b[1G101.4 MiB [] 66% 0.3s\u001b[0K\u001b[1G101.4 MiB [] 67% 0.3s\u001b[0K\u001b[1G101.4 MiB [] 69% 0.3s\u001b[0K\u001b[1G101.4 MiB [] 71% 0.2s\u001b[0K\u001b[1G101.4 MiB [] 72% 0.2s\u001b[0K\u001b[1G101.4 MiB [] 74% 0.2s\u001b[0K\u001b[1G101.4 MiB [] 76% 0.2s\u001b[0K\u001b[1G101.4 MiB [] 77% 0.2s\u001b[0K\u001b[1G101.4 MiB [] 79% 0.2s\u001b[0K\u001b[1G101.4 MiB [] 80% 0.2s\u001b[0K\u001b[1G101.4 MiB [] 83% 0.1s\u001b[0K\u001b[1G101.4 MiB [] 85% 0.1s\u001b[0K\u001b[1G101.4 MiB [] 87% 0.1s\u001b[0K\u001b[1G101.4 MiB [] 90% 0.1s\u001b[0K\u001b[1G101.4 MiB [] 93% 0.1s\u001b[0K\u001b[1G101.4 MiB [] 95% 0.0s\u001b[0K\u001b[1G101.4 MiB [] 98% 0.0s\u001b[0K\u001b[1G101.4 MiB [] 100% 0.0s\u001b[0K\n",
            "Chromium Headless Shell 136.0.7103.25 (playwright build v1169) downloaded to /root/.cache/ms-playwright/chromium_headless_shell-1169\n",
            "nohup: appending output to 'nohup.out'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nohup ollama serve &\n",
        "import random\n",
        "import subprocess\n",
        "import wikipedia\n",
        "import requests\n",
        "from crawl4ai.content_filter_strategy import PruningContentFilter\n",
        "\n",
        "from crawl4ai.markdown_generation_strategy import DefaultMarkdownGenerator\n",
        "from urllib.parse import urlparse\n",
        "from bs4 import BeautifulSoup\n",
        "from googlesearch import search\n",
        "from crawl4ai import LLMConfig, LLMExtractionStrategy, CrawlerRunConfig,CacheMode\n",
        "from crawl4ai.deep_crawling.filters import FilterChain, ContentRelevanceFilter\n",
        "from crawl4ai.deep_crawling import BFSDeepCrawlStrategy\n",
        "import json\n",
        "\n",
        "from playwright.async_api import async_playwright\n",
        "\n",
        "from crawl4ai.extraction_strategy import CosineStrategy\n",
        "\n",
        "from crawl4ai.async_configs import BrowserConfig\n",
        "\n",
        "from crawl4ai import AsyncWebCrawler,GeolocationConfig\n",
        "\n",
        "import requests\n",
        "from urllib.parse import urlparse\n",
        "\n",
        "import asyncio\n",
        "import time\n",
        "import requests\n",
        "import nest_asyncio\n",
        "import httpx\n",
        "\n",
        "API_BASE = \"https://www.nearestdoor.com\"  # Replace with actual server URL\n",
        "CLIENT_ID = \"client001\"\n",
        "HEARTBEAT_INTERVAL = 60  # seconds\n",
        "SHOP_FLOW_STATIC = [\n",
        "    \"search\", \"aggregate\", \"createplan\", \"create\",\n",
        "    \"find_available_fields\", \"extract_fields_from_aggregate\", \"fillintheshop\"\n",
        "]\n",
        "# --------------------------------------------------------------------------- #\n",
        "# ðŸ§   LIGHTâ€‘WEIGHT LOCAL LLM EXECUTION                                       #\n",
        "# --------------------------------------------------------------------------- #\n",
        "class OllamaRunner:\n",
        "    \"\"\"\n",
        "    `ollama run â€¦`\n",
        "\n",
        "    \"\"\"\n",
        "    def __init__(self, default_model: str = \"gemma3:1b\", default_timeout: int = 600):\n",
        "        self.default_model = default_model\n",
        "        self.default_timeout = default_timeout\n",
        "\n",
        "    def run(self, prompt: str, model: str | None = None, timeout: int | None = None) -> str:\n",
        "        model = model or self.default_model\n",
        "        timeout = timeout or self.default_timeout\n",
        "        print(f\"ðŸ§  Running Ollama: {model}\")\n",
        "\n",
        "        try:\n",
        "            proc = subprocess.run(\n",
        "                [\"ollama\", \"run\", model],\n",
        "                input=prompt.encode(\"utf-8\"),\n",
        "                stdout=subprocess.PIPE,\n",
        "                stderr=subprocess.PIPE,\n",
        "                timeout=timeout,\n",
        "            )\n",
        "\n",
        "            raw_output = proc.stdout.decode(\"utf-8\").strip()\n",
        "            return re.sub(r\"<think>.*?</think>\", \"\", raw_output, flags=re.DOTALL).strip()\n",
        "        except Exception as e:\n",
        "            print(f\"âŒ Ollama execution failed: {e}\")\n",
        "            return \"\"\n",
        "\n",
        "\n",
        "# --------------------------------------------------------------------------- #\n",
        "# ðŸŒ  LOOKâ€‘UP ENGINE                                                          #\n",
        "# --------------------------------------------------------------------------- #\n",
        "class LookupEngine:\n",
        "    \"\"\"\n",
        "    â€“ Validates every URL first\n",
        "    â€“ Google results exclude Yelp & Reddit and are contentâ€‘checked\n",
        "    â€“ Yelp & Reddit results are *also* contentâ€‘checked before â€˜battlingâ€™\n",
        "    â€“ At most one Yelp URL & one Reddit URL are returned\n",
        "    â€“ Wikipedia returns at most one page (auto_suggest)\n",
        "    \"\"\"\n",
        "    def __init__(self,  ollama_runner: OllamaRunner | None = None):\n",
        "\n",
        "        self.llm_config = LLMConfig(provider=\"ollama/gemma3:1b\")\n",
        "        self.ollama = ollama_runner or OllamaRunner()\n",
        "        self.crawler_manager = self.CrawlerManager()\n",
        "    async def initialize(self):\n",
        "        await self.crawler_manager.start()\n",
        "\n",
        "\n",
        "    # ---------------------  LOWâ€‘LEVEL HELPERS  ----------------------------- #\n",
        "    class CrawlerManager:\n",
        "        def __init__(self):\n",
        "            self.crawler = None\n",
        "\n",
        "\n",
        "\n",
        "        async def crawl(self, url: str,browserconfig, config: CrawlerRunConfig):\n",
        "\n",
        "\n",
        "            try:\n",
        "                async with AsyncWebCrawler(config=browserconfig) as crawler:\n",
        "                    result = await crawler.arun(url=url, config=config)\n",
        "                    return result\n",
        "            except Exception as e:\n",
        "                print(f\"âŒ crawl error for {url}: {e}\")\n",
        "                return None\n",
        "\n",
        "\n",
        "        async def _normalize_and_validate_url(self, url: str) -> str | None:\n",
        "          try:\n",
        "              url = url.lower()\n",
        "              if not url.startswith((\"http://\", \"https://\")):\n",
        "                  url = \"https://\" + url\n",
        "\n",
        "              parsed = urlparse(url)\n",
        "              if (\n",
        "                  parsed.scheme not in [\"http\", \"https\"]\n",
        "                  or not parsed.netloc\n",
        "                  or \".\" not in parsed.netloc\n",
        "                  or \" \" in parsed.netloc\n",
        "                  or \"/http\" in parsed.netloc\n",
        "              ):\n",
        "                  return None  # Invalid URL\n",
        "\n",
        "              # âœ… Check if the URL is reachable using httpx (this was incorrectly indented before)\n",
        "              async with httpx.AsyncClient(timeout=5) as client:  # Timeout should be in seconds, not 800ms\n",
        "                  try:\n",
        "                      response = await client.head(url, follow_redirects=True)\n",
        "                      if response.status_code < 400:\n",
        "                          return url\n",
        "                      # Some servers reject HEAD, fallback to GET\n",
        "                      response = await client.get(url, follow_redirects=True)\n",
        "                      if response.status_code < 400:\n",
        "                          return url\n",
        "                      return False  # URL unreachable\n",
        "                  except httpx.RequestError as e:\n",
        "                      print(f\"âŒ HTTP check failed: {url} ({e})\")\n",
        "                      return None\n",
        "\n",
        "          except Exception as e:\n",
        "              print(f\"âŒ URL normalization failed: {e}\")\n",
        "              return None\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    async def _extract_snippet(self, url, max_chars, min_chars):\n",
        "        try:\n",
        "            async with async_playwright() as p:\n",
        "                browser = await p.chromium.launch(headless=True)\n",
        "                context = await browser.new_context(\n",
        "                    user_agent=\"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/123.0.0.0 Safari/537.36\",\n",
        "                    locale=\"en-US\",\n",
        "                    java_script_enabled=False,\n",
        "                    permissions=[\"geolocation\"],\n",
        "\n",
        "    viewport={\"width\": 1280, \"height\": 720}\n",
        "                )\n",
        "                page = await context.new_page()\n",
        "\n",
        "                print(f\"Fetching: {url}\")\n",
        "                await page.goto(url, wait_until=\"domcontentloaded\", timeout=20000)\n",
        "\n",
        "                await page.wait_for_timeout(random.randint(1000, 3000))  # Randomized delay\n",
        "\n",
        "\n",
        "                title = await page.title()\n",
        "                desc = None\n",
        "\n",
        "                # Try standard meta description first\n",
        "                try:\n",
        "                    desc = await page.locator('meta[name=\"description\"]').get_attribute('content')\n",
        "                except Exception:\n",
        "                    # Try OpenGraph and Twitter metadata as fallback\n",
        "                    for meta_tag in [\"meta[property='og:description']\", \"meta[name='twitter:description']\"]:\n",
        "                        try:\n",
        "                            desc = await page.locator(meta_tag).get_attribute('content')\n",
        "                            if desc:\n",
        "                                break\n",
        "                        except Exception:\n",
        "                            continue\n",
        "                    if not desc:\n",
        "                        print(f\"No meta description found for {url}\")\n",
        "\n",
        "\n",
        "                parts = []\n",
        "                if title:\n",
        "                  parts.append(\"Title: \" + title.strip())\n",
        "                if desc:\n",
        "                  parts.append(\"Desc: \" + desc.strip())\n",
        "\n",
        "                await browser.close()\n",
        "\n",
        "                result = \"\\n\".join(parts)\n",
        "\n",
        "\n",
        "                print(\"ddj\")\n",
        "                if len(str(result)) < min_chars:\n",
        "                    print(f\"âŒ Extracted content too short: {len(result)} chars\")\n",
        "                    return None\n",
        "                result = result[:max_chars]\n",
        "                return f\"Snippet From {url}:\\n{result[:max_chars]}\"\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"âŒ Playwright extraction failed for {url}: {e}\")\n",
        "            return None\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    async def _basic_url_checker(self, snippet,url: str, shop_name: str, shop_type: str, state: str, city:str) -> bool:\n",
        "        try:\n",
        "\n",
        "            \"\"\"\n",
        "            Improved relevance check for a URL:\n",
        "            1. Uses Crawl4AI's ContentRelevanceFilter for semantic similarity.\n",
        "            2. Falls back to LLM prompt decision if semantic check is inconclusive.\n",
        "            \"\"\"\n",
        "\n",
        "            if not url:\n",
        "                return False\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "            # Step 2: Fallback â€” Quick Snippet and LLM Yes/No Decision\n",
        "\n",
        "            if not snippet:\n",
        "                print(\"no snippet\")\n",
        "                return False\n",
        "\n",
        "            prompt = (\n",
        "                f\"Is the website {url} related at all to '{shop_name}' or in any way related to the place its located in, {state}, {city}? \"\n",
        "                f\"Be super lient and allow all websites related to {shop_type} to pass. If the name {shop_name} or {state}, {city} is present or any related info like the town, the category, ect then let it pass. Be super lient. Answer only `true` or `false` or `none`.\\n\\n{snippet}\"\n",
        "            )\n",
        "\n",
        "            decision = self.ollama.run(prompt, 'qwen3:0.6b')\n",
        "            print(decision)\n",
        "            print(prompt)\n",
        "            if \"true\" in decision.lower():\n",
        "                print(f\"âœ… LLM confirmed relevance for: {url}\")\n",
        "                return True\n",
        "\n",
        "            print(f\"âš ï¸ URL deemed irrelevant: {url}\")\n",
        "            return False\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"error in basicc checker\", {url}, {shop_name}, {shop_type}, e)\n",
        "            return False\n",
        "    @staticmethod\n",
        "    def get_semantic_query(shop_type, shop_name):\n",
        "        queries = {\n",
        "            \"church\": f\"{shop_type}, {shop_name}, history, review, hours, muslim, phone, church, christian, church events, holiday schedules, mass times, sermons, church history, community programs, accessibility options, FAQs, donation methods, parking, contact information\",\n",
        "            \"plasma_center\": f\"{shop_type}, {shop_name}, history, review, stocked brands, review, hours, phone, plasma, plasma donation requirements, compensation rates, donor reward, donor eligibility, contact details, operating hours, health guidelines, FAQ, appointment scheduling, safety procedures\",\n",
        "            \"thrift_store\": f\"{shop_type}, {shop_name}, history, review, stocked brands, second hand,  review, hours, phone, thrift, store hours, donation guidelines, accepted items, discounts, sales events, store history, accessibility, contact info, volunteer programs, reviews\",\n",
        "            \"dog_park\": f\"{shop_type}, {shop_name}, history, review, water, shade, agility equipment, park, review, hours, phone, dog, dog park hours, leash rules, pet-friendly areas, dog-friendly facilities, park amenities, accessibility options, entry fees, safety tips, events, pet policies, reviews\",\n",
        "        }\n",
        "        return queries.get(shop_type.lower(), \"business information, contact details, operating hours, reviews, FAQs, history\")\n",
        "\n",
        "    async def _get_site_content(\n",
        "\n",
        "            self,\n",
        "\n",
        "            url: str,\n",
        "            shop_name: str,\n",
        "            shop_type: str,\n",
        "state:str, city:str\n",
        "            ) -> str | None:\n",
        "        try:\n",
        "            print(\"scraping\")\n",
        "        # Step 1: Semantic Filter Based on Shop Type\n",
        "            #semantic_query = self.get_semantic_query(shop_type, shop_name)\n",
        "\n",
        "\n",
        "            prune_filter = PruningContentFilter(\n",
        "                        threshold=0.05,\n",
        "                        threshold_type=\"dynamic\",  # or \"dynamic\"\n",
        "                        min_word_threshold=5\n",
        "                    )\n",
        "\n",
        "            md_generator = DefaultMarkdownGenerator(content_filter=prune_filter)\n",
        "\n",
        "\n",
        "            crawl_config = CrawlerRunConfig(\n",
        "\n",
        "                  markdown_generator=md_generator,\n",
        "\n",
        "\n",
        "                  excluded_tags=[\"style\", \"script\", \"footer\"],\n",
        "  cache_mode=CacheMode.BYPASS,\n",
        "    page_timeout=60000,\n",
        "\n",
        "\n",
        "            )\n",
        "            bconfig = BrowserConfig(\n",
        "            headless=True,\n",
        "            viewport_width=1280,\n",
        "                    viewport_height=720,\n",
        "                   user_agent_mode=\"random\",\n",
        "                    text_mode=True\n",
        "            )\n",
        "            result = await self.crawler_manager.crawl(url, bconfig,config=crawl_config)\n",
        "\n",
        "\n",
        "            if result.success:\n",
        "\n",
        "                  print(result.markdown.fit_markdown)\n",
        "                  return result.markdown.fit_markdown\n",
        "            else:\n",
        "                return None\n",
        "\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"âŒ Failed to parse site content: {e}\")\n",
        "            return None\n",
        "    # ---------------------  LOOKâ€‘UP ROUTINES  ------------------------------ #\n",
        "    async def wikipedia_lookup(self, name: str, city: str, shop_type: str) -> str | None:\n",
        "        try:\n",
        "            query = f\"{name} {city} {shop_type}\".strip()\n",
        "            print(f\"ðŸ“š Wikipedia lookup â†’ {query}\")\n",
        "            page = wikipedia.page(query, auto_suggest=True)\n",
        "            content = page.content\n",
        "\n",
        "            if len(content) <= 2000:\n",
        "                return content\n",
        "            chunks = [content[i:i + 500] for i in range(0, len(content), 500)]\n",
        "            # Fallback-safe middle extraction\n",
        "            if len(chunks) > 6:\n",
        "                middle = chunks[2:-2]  # Remove first and last 2 chunks\n",
        "                if not middle:\n",
        "                    middle = chunks  # If middle is empty, fallback to all chunks\n",
        "            else:\n",
        "                middle = chunks\n",
        "\n",
        "            # Intelligent selection\n",
        "            if len(middle) > 6:\n",
        "                selected = random.sample(middle, 6)  # Randomly select 6 if too many\n",
        "            else:\n",
        "                selected = middle  # Take all available if 6 or fewer\n",
        "            formatted_chunks = [f\"\\nWIKI CHUNK {idx + 1}:\\n{chunk}\" for idx, chunk in enumerate(selected)]\n",
        "\n",
        "            return f\"ALL EXTRACTED WIKIPEDIA SEARCH INFO FOR {name}:\\n\" + \"\\n\".join(formatted_chunks)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"âŒ Wikipedia fetch failed: {e}\")\n",
        "            return None\n",
        "\n",
        "    async def search_lookup(self,  name: str,  shop_type: str, query: str, placename: str, amount: int,state:str, city:str, isyelp: bool) -> str | None:\n",
        "        try:\n",
        "            print(f\"ðŸ”Ž {placename} search â†’ {query}\")\n",
        "            print(\"dd\")\n",
        "            raw = list(search(query, amount))\n",
        "            if not isyelp:\n",
        "                print(\"ddf\")\n",
        "                candidate_urls = [\n",
        "                      u for u in raw\n",
        "                      if all(excl not in str(u).lower() for excl in [\"yelp\", \"reddit\", \"wiki\", \"nearestdoor\", \"facebook\", \"twitter\"])\n",
        "                  ]\n",
        "                print(\"bfd\")\n",
        "            else:\n",
        "                print(\"rgrg\")\n",
        "                candidate_urls = [\n",
        "                      u for u in raw\n",
        "                      if (\"yelp\" in str(u).lower() or \"reddit\" in str(u).lower())\n",
        "                      and all(excl not in str(u).lower() for excl in [\"wiki\", \"nearestdoor\", \"facebook\", \"twitter\"])\n",
        "                  ]\n",
        "                print(\"frg\")\n",
        "\n",
        "            good_content = []\n",
        "\n",
        "            print(\"ddd\")\n",
        "            for i, url in enumerate(candidate_urls):\n",
        "                print(url, \"url canidate\")\n",
        "                urld = await self.crawler_manager._normalize_and_validate_url(url)\n",
        "                if not urld:\n",
        "                    continue\n",
        "                snippet = await self._extract_snippet(url, 750, 40)\n",
        "                if not await self._basic_url_checker(snippet, urld, name, shop_type, state, city):\n",
        "                    continue\n",
        "\n",
        "                content = await self._get_site_content(urld, name, shop_type,state, city)\n",
        "                if content:\n",
        "                    good_content.append(f\"\\nâ†Â {placename} SEARCHÂ DATAÂ SITE {i} FROM: {url}\\n {content}\")\n",
        "\n",
        "            return f\"ALL EXTRACTED {placename} SEARCH DATA FOR {name}, {city}\\n\".join(good_content) if good_content else None\n",
        "        except Exception as e:\n",
        "            print(f\"âŒ Failed to parse {placename} search lookup results: {e}\")\n",
        "            return None\n",
        "    # ---------------------  PUBLIC ENTRY POINT  ---------------------------- #\n",
        "    async def combined_search(self, name: str, city: str, state: str, shop_type: str, website_url: str) -> tuple[bool, str | None, None]:\n",
        "        print(\"ðŸŒ Starting combined searchâ€¦\")\n",
        "\n",
        "        Google_query = f\"{name} {city} {state} {shop_type} \"\n",
        "\n",
        "        if website_url:\n",
        "            Official_query = f\"{name} site: {website_url} \"\n",
        "\n",
        "        g_res = await self.search_lookup(name, shop_type, Google_query, \"Google\", 10,state, city,  False)\n",
        "        w_res = await self.wikipedia_lookup(name, city, shop_type)\n",
        "        o_res = None\n",
        "        if website_url:\n",
        "            o_res = await self.search_lookup(name, shop_type, Official_query, f\"Official Website of {name}\", 5,state, city, True)\n",
        "        main = \"\"\n",
        "\n",
        "\n",
        "        if g_res:\n",
        "            main += g_res\n",
        "        if w_res:\n",
        "            main += w_res\n",
        "        if o_res:\n",
        "            main += o_res\n",
        "        print('sss')\n",
        "        if len(main) < 500:\n",
        "            print(\"âŒ Not enough content gathered.\")\n",
        "            return False, None, None\n",
        "\n",
        "        print(\"âœ… Combined search complete.\")\n",
        "        return True, main, None\n",
        "# --------------------------------------------------------------------------- #\n",
        "# ðŸ“¦  HIGHâ€‘LEVEL CONTENTÂ SUMMARIZER                                          #\n",
        "# --------------------------------------------------------------------------- #\n",
        "class ContentSummarizer:\n",
        "    \"\"\"\n",
        "    Reduce a large blob of text about a specific business down to â‰¤â€¯max_final_chars\n",
        "    while preserving highâ€‘value facts. Uses multi-stage LLM summarisation with\n",
        "    chunk filtering and escalation if necessary.\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "        self,\n",
        "        ollama_runner: OllamaRunner,\n",
        "        shop_name: str,\n",
        "        shop_type: str,\n",
        "        city: str | None = None,\n",
        "        state: str | None = None,\n",
        "        max_final_chars: int = 6000,\n",
        "        min_final_chars: int = 500,\n",
        "    ):\n",
        "        self.ollama = ollama_runner\n",
        "        self.shop_name = shop_name\n",
        "        self.shop_type = shop_type\n",
        "        self.city = city or \"\"\n",
        "        self.state = state or \"\"\n",
        "        self.max_final_chars = max_final_chars\n",
        "        self.min_final_chars = min_final_chars\n",
        "\n",
        "\n",
        "\n",
        "    def _chunk_text(self, text: str, chunk_size: int) -> list[str]:\n",
        "        return [text[i:i + chunk_size] for i in range(0, len(text), chunk_size)]\n",
        "\n",
        "    def _filter_chunks(self, chunks: list[str], model: str = \"qwen3:0.6b\") -> list[str]:\n",
        "        try:\n",
        "            good = []\n",
        "            print(f\"Filtering {len(chunks)} chunks...\")\n",
        "            for chunk in chunks:\n",
        "                prompt = (\n",
        "                    f\"Is the following contain any info related to {self.shop_type}, {self.city} {self.state}\"\n",
        "                    f\"'{self.shop_name}'. Be super lient and allow all data. Only reply 'true' or 'false'.\\n\\n{chunk}\"\n",
        "                )\n",
        "                print(\"prompt\", prompt)\n",
        "                decision = self.ollama.run(prompt, model=model).strip().lower()\n",
        "                print(\"decision\", decision)\n",
        "                if \"true\" in decision:\n",
        "                    good.append(chunk)\n",
        "\n",
        "            return good\n",
        "        except Exception as e:\n",
        "            print(f\"âŒ Failed to filter chunk: {e}\")\n",
        "            return None\n",
        "\n",
        "    def _build_prompt(self, text_chunk: str) -> str:\n",
        "        return (\n",
        "            f\"You are creating a SHORT unformatted summary for \"\n",
        "            f\"{self.shop_type} **{self.shop_name}** \"\n",
        "            f\"{'in ' + self.city if self.city else ''}{', ' + self.state if self.state else ''}.\\n\\n\"\n",
        "            f\"KEEP USEFUL DATA\"\n",
        "            \"DO NOT USE ASTERISKS OR * OR **\"\n",
        "            \"KEEP SERVICES.\\n\"\n",
        "            f\"KEEP URLS ONLY WHEN IT IS THE LITERAL {self.shop_name}'s WEBSITE.\\n\"\n",
        "            f\"KEEP ALL GOOD INFO AND HISTORY, FACTS, INFO, Extract all usefull info,\\n\"\n",
        "\n",
        "            f\" remove weird info.\\n\"\n",
        "\n",
        "            f\"--- SOURCE TEXT START ---\\n{text_chunk}\\n--- SOURCE TEXT END ---\"\n",
        "\n",
        "        )\n",
        "\n",
        "    def _summarize_with_ollama(self, text: str, model: str) -> str:\n",
        "        try:\n",
        "            prompt = self._build_prompt(text)\n",
        "            print(\"prompt summarize\", prompt)\n",
        "            return self.ollama.run(prompt, model=model)\n",
        "        except Exception as e:\n",
        "            print(f\"âŒ Failed to summarize w ollama: {e}\")\n",
        "            return None\n",
        "    def summarize_chunks(\n",
        "        self,\n",
        "        content: str,\n",
        "\n",
        "        initial_model: str = \"gemma3:1b\",\n",
        "\n",
        "    ) -> str:\n",
        "        try:\n",
        "            print(content)\n",
        "            if len(content) < self.min_final_chars:\n",
        "                print(\"filtered less than min\")\n",
        "                return None\n",
        "            if len(content) > self.max_final_chars:\n",
        "\n",
        "                chunks = self._chunk_text(content, 1000)\n",
        "\n",
        "                content = self._filter_chunks(chunks)\n",
        "                if not content:\n",
        "                    content = chunks\n",
        "                content = ''.join(content)\n",
        "\n",
        "            if len(content) < self.min_final_chars:\n",
        "                print(\"filtered less than min2\")\n",
        "                return None\n",
        "            chunks = self._chunk_text(content, 3000)\n",
        "\n",
        "            summarized_chunks = []\n",
        "\n",
        "            for idx, chunk in enumerate(chunks, start=1):\n",
        "                print(f\"ðŸ“š Summarizing chunk {idx}/{len(chunks)}...\")\n",
        "                summary = self._summarize_with_ollama(chunk, model=initial_model)\n",
        "                print(\"summary\", summary)\n",
        "                if not summary or len(summary) < 50:\n",
        "                    print(f\"âš ï¸ Failed to summarize chunk {idx}, keeping raw content.\")\n",
        "                    summary = chunk  # Fallback to raw content if summary failed\n",
        "\n",
        "                summarized_chunks.append(f\"### CHUNK {idx} SUMMARY:\\n{summary}\")\n",
        "\n",
        "                # Early exit: check if adding all remaining raw chunks without summarizing fits within limit\n",
        "                combined_so_far = \"\\n\\n\".join(summarized_chunks)\n",
        "                remaining_raw = \"\".join(chunks[idx:])  # Remaining chunks after current one\n",
        "\n",
        "                if len(combined_so_far) + len(remaining_raw) <= self.max_final_chars:\n",
        "                    print(f\"âœ… Early exit: current summary + remaining raw fits within limit. Skipping further summarization.\")\n",
        "                    for r_idx, remaining_chunk in enumerate(chunks[idx:], start=idx + 1):\n",
        "                        summarized_chunks.append(f\"### CHUNK {r_idx} (Raw):\\n{remaining_chunk}\")\n",
        "                    break\n",
        "\n",
        "            combined_summary = \"\\n\\n\".join(summarized_chunks)\n",
        "            if len(combined_summary) < self.min_final_chars:\n",
        "                print(\"smmariez less than min\")\n",
        "                return None\n",
        "            # Final trim if absolutely necessary\n",
        "            if len(combined_summary) > self.max_final_chars:\n",
        "                print(\"âš ï¸ Final combined summary exceeds character limit. Trimming result.\")\n",
        "                return combined_summary[:self.max_final_chars]\n",
        "\n",
        "            return combined_summary\n",
        "        except Exception as e:\n",
        "            print(f\"âŒ Failed to sumarrize chunks: {e}\")\n",
        "            return None\n",
        "\n",
        "\n",
        "    def summarize_content(self, raw_content: str) -> str:\n",
        "\n",
        "\n",
        "        print(\"summarizing\")\n",
        "        final_summary = self.summarize_chunks(\n",
        "        content=raw_content,           # The large raw text content you want to reduce\n",
        "               # Size of each chunk before summarizing\n",
        "        initial_model=\"gemma3:1b\",      # Start with the lightweight model\n",
        "\n",
        "    )\n",
        "        print(final_summary)\n",
        "        if final_summary is None:\n",
        "            print(\"âŒ Summarization failed. Returning none instead.\")\n",
        "            return '', False\n",
        "\n",
        "        print(\"ðŸŽ‰ Final summarization complete.\")\n",
        "        return final_summary, True\n",
        "\n",
        "import re\n",
        "import json\n",
        "\n",
        "class Smartypants:\n",
        "    def __init__(self, ollama_runner: OllamaRunner):\n",
        "        self.ollama = ollama_runner\n",
        "\n",
        "    def _run4(self, prompt: str) -> str:\n",
        "        return self.ollama.run(prompt, model=\"gemma3:4b\",)\n",
        "    def _run1(self, prompt: str) -> str:\n",
        "        return self.ollama.run(prompt, model=\"gemma3:1b\")\n",
        "\n",
        "    # ------------ PLAN ------------ #\n",
        "    def create_plan(self, aggregate: str,shop_name: str, shop_type: str,  city: str, state: str) -> tuple[bool, list[str]]:\n",
        "        prompt = (\n",
        "            \"You have an aggregated summary about a \"\n",
        "\n",
        "            f\"place called {shop_name} {shop_type} in {city}, {state}\\n\\n\"\n",
        "            f\"{aggregate}\\n\\n\"\n",
        "            \"Which content sections can confidently be generated based on this?\\n\"\n",
        "            \"Options: article, faq, history.\\n\"\n",
        "            \"Reply with a correct python comma-separated list of available sections to write about, nothing else, Options: article, faq, history.\"\n",
        "        )\n",
        "        try:\n",
        "            count = 0\n",
        "            resp = self._run4(prompt).lower()\n",
        "            valid = {\"article\", \"faq\", \"history\"}\n",
        "            print(resp)\n",
        "            for s in valid:\n",
        "                if s not in resp:\n",
        "                    count +=1\n",
        "            if count == 3:\n",
        "                return False, []\n",
        "\n",
        "            return True, [s for s in valid if s in resp]\n",
        "        except Exception as e:\n",
        "            print(f\"âŒ create_plan error: {e}\")\n",
        "            return False, []\n",
        "\n",
        "    def check_aggregate_quality(self, shop_name: str, aggregate: str,shop_type: str,  city: str, state: str) -> bool:\n",
        "        prompt = (\n",
        "            f\"Check if this content contains usefull info about {shop_name} {shop_type} in {city}, {state}.\\n\\n{aggregate}\\n\\n\"\n",
        "            \"Reply only `true` or `false`.\"\n",
        "        )\n",
        "        try:\n",
        "            return \"true\" in self._run1(prompt).lower()\n",
        "        except Exception as e:\n",
        "            print(f\"âŒ quality check error: {e}\")\n",
        "            return False\n",
        "\n",
        "    # ------------ SECTION VALIDATION / FIX ------------ #\n",
        "    def validate_section_html(self, shop_name: str, section: str, text: str) -> bool:\n",
        "        prompt = (\n",
        "\n",
        "            f\"Validate the following text for section '{section}'. It is supposed to be about '{shop_name}'.\\n\\n{text}\\n\\n\"\n",
        "            \"Rules: DO NOT ALLOW ASTERISKS, DO NOT ALLOW * OR **.\\n- No HTML.\\n- No irrelevant info. Is it useful and no format or weird characters? Nothing Else, Nothing before or after our content\\n\"\n",
        "            \"- Only factual, structured, and clear content.\\n- Reply `true` or `false` only.\"\n",
        "        )\n",
        "        print(\"validate html\", prompt)\n",
        "        return \"true\" in self._run1(prompt).lower()\n",
        "\n",
        "    def fix_section_html(self, shop_name: str, section: str, text: str) -> str | None:\n",
        "        prompt = (\n",
        "            f\"Clean and fix this section '{section}'s format. It is about '{shop_name}'.\\n\\n{text}\\n\\n\"\n",
        "            \"Rules:DO NOT USE ASTERISKS, DO NOT USE * OR **. \\n- No HTML, Is it useful and and no format or weird characters? asterisks, or irrelevant info.\\n\"\n",
        "            \"Return only the final cleaned text for consumers on nearestdoor.com to read, no junk, no explanations, nothing else, nothing before or after our content. Only return the corrected text.\"\n",
        "        )\n",
        "        print(\"fixing html\",prompt)\n",
        "        return self._run4(prompt).strip()\n",
        "\n",
        "    # ------------ JSON & FIELD EXTRACTION ------------ #\n",
        "\n",
        "    def extract_clean_json_structure(self,text: str, field_name: str = None) -> dict | list | None:\n",
        "        try:\n",
        "            # âœ… Extract content inside ```json ... ```\n",
        "            json_block = re.search(r\"```json\\s*(.*?)\\s*```\", text, re.IGNORECASE | re.DOTALL)\n",
        "            if json_block:\n",
        "                text = json_block.group(1).strip()\n",
        "            else:\n",
        "                text = text.replace(\"```json\", \"\").replace(\"```\", \"\").strip()\n",
        "\n",
        "            # âœ… Extract JSON object or array\n",
        "            match = re.search(r\"(\\{.*?\\}|\\[.*?\\])\", text, re.DOTALL)\n",
        "            if not match:\n",
        "                return None\n",
        "\n",
        "            json_ready = match.group(0)\n",
        "            match_text_lower = json_ready.lower()\n",
        "\n",
        "            # âœ… Exclude meaningless content\n",
        "            exclusion_keywords = ['n/a', 'n-a', 'none', 'false', 'na', 'cant', 'not', 'found', 'unable', '{{', '()', 'unavailable']\n",
        "            if any(bad in match_text_lower for bad in exclusion_keywords):\n",
        "                return None\n",
        "\n",
        "            # âœ… Clean JSON formatting issues\n",
        "            json_ready = json_ready.replace(\"'\", '\"')\n",
        "            json_ready = re.sub(r\",\\s*([\\]}])\", r\"\\1\", json_ready)\n",
        "\n",
        "            parsed = json.loads(json_ready)\n",
        "\n",
        "            # âœ… Handle List: Deduplicate and Title Case\n",
        "            if isinstance(parsed, list):\n",
        "                seen = set()\n",
        "                cleaned_list = []\n",
        "                for item in parsed:\n",
        "                    if isinstance(item, str):\n",
        "                        cleaned_item = item.strip().title()\n",
        "                        if cleaned_item and cleaned_item.lower() not in exclusion_keywords and cleaned_item not in seen:\n",
        "                            seen.add(cleaned_item)\n",
        "                            cleaned_list.append(cleaned_item)\n",
        "                result = cleaned_list if cleaned_list else None\n",
        "\n",
        "            # âœ… Handle Dict: Clean keys and values\n",
        "            elif isinstance(parsed, dict):\n",
        "                cleaned_dict = {}\n",
        "                for k, v in parsed.items():\n",
        "                    if isinstance(v, str):\n",
        "                        v_clean = v.strip().lower()\n",
        "                        if v_clean in exclusion_keywords:\n",
        "                            continue\n",
        "                        cleaned_dict[k.title()] = v.title()\n",
        "                    else:\n",
        "                        cleaned_dict[k.title()] = v\n",
        "                result = cleaned_dict if cleaned_dict else None\n",
        "\n",
        "            else:\n",
        "                result = None\n",
        "\n",
        "            # âœ… Final Validation Using FIELD_VALIDATORS\n",
        "            if field_name and field_name in FIELD_VALIDATORS:\n",
        "                validator = FIELD_VALIDATORS[field_name]\n",
        "                if not validator(result):\n",
        "                    print(f\"âŒ Validation failed for field: {field_name} with value: {result}\")\n",
        "                    return None\n",
        "\n",
        "            return result\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"âŒ JSON extraction failed: {e}\")\n",
        "            return None\n",
        "\n",
        "\n",
        "\n",
        "    def extract_available_fields(self, aggregate: str,shop_name: str, shop_type: str,  city: str, state: str) -> tuple[bool, list[str]]:\n",
        "        try:\n",
        "            field_list = list(FIELD_EXTRACTORS.keys())\n",
        "            field_str = ', '.join(field_list)\n",
        "            prompt = (\n",
        "                f\"Analyze the content:\\n\\n{aggregate}\\n\\n\"\n",
        "                f\"Whos data we want {shop_type}, {shop_name}. \"\n",
        "\n",
        "                f\"Which of these fields can be confidently extracted from the content?\\n{field_str}\\n\"\n",
        "                \"Reply ONLY with the field keys that are present in the text, as ONLY the correct format requested. no junk. Nothing else. \"\n",
        "                \"If none, reply exactly 'none'.\"\n",
        "            )\n",
        "            response = self._run4(prompt).strip().lower()\n",
        "            if \"none\" in response:\n",
        "                return True, []\n",
        "            detected = [field for field in field_list if field.lower() in response]\n",
        "            return True, detected\n",
        "        except Exception as e:\n",
        "            print(f\"âŒ extract_available_fields error: {e}\")\n",
        "            return False, []\n",
        "    def validate_extracted_field_value(self, field: str,fieldextractprompt, value) -> bool:\n",
        "        \"\"\"\n",
        "        Validate the extracted field value using LLM and manual schema checks.\n",
        "\n",
        "        - If it's a JSON list, remove invalid entries.\n",
        "        - If it's invalid after cleaning, return False.\n",
        "        \"\"\"\n",
        "        # LLM-Based Validation Prompt\n",
        "        prompt = (\n",
        "            f\"Validate this extracted value for field '{field}':\\n\\n{value}\\n\\n, {fieldextractprompt} \"\n",
        "            \"Is this a valid and correct value and format for the specified field requested? Is it weird for the field or contain none values? Reply ONLY `true` or `false`.\"\n",
        "        )\n",
        "        print(\"validate field\", prompt)\n",
        "        llm_decision = \"true\" in self._run1(prompt).lower()\n",
        "        print(\"field valid decision\", llm_decision)\n",
        "        # If LLM says it's invalid, fail immediately\n",
        "        if not llm_decision:\n",
        "            print(f\"âŒ LLM validation failed for field '{field}'.\")\n",
        "            return False\n",
        "\n",
        "\n",
        "\n",
        "        # Final check for singular values\n",
        "        return True\n",
        "\n",
        "    def extract_fields(\n",
        "        self, aggregate: str, available_fields: list[str],\n",
        "        shop_name: str, shop_type: str, city: str, state: str\n",
        "    ) -> tuple[bool, dict]:\n",
        "        extracted = {}\n",
        "        try:\n",
        "            for field in available_fields:\n",
        "                try:\n",
        "                    print(field)\n",
        "                    prompt = (\n",
        "                        f\"{FIELD_EXTRACTORS[field]}\\n\\nContent:\\n{aggregate}\\n\\n\"\n",
        "                        f\"Return ONLY the valid structure requested. Respond with nothing but the correct format requested. \"\n",
        "                        f\"If none, say 'none'. Nothing else, nothing before or after our content. Data about {shop_type}, {shop_name}.\"\n",
        "                    )\n",
        "                    print(\"aggregate\",aggregate)\n",
        "                    print(\"extracting fields\",prompt )\n",
        "                    raw_value = self._run4(prompt).strip()\n",
        "                    print(\"raw field\", raw_value)\n",
        "                    final_value = self.extract_clean_json_structure(raw_value, field)\n",
        "                    if final_value is None:\n",
        "                        print(\"final value none\")\n",
        "                        continue\n",
        "                    if self.validate_extracted_field_value(field,{FIELD_EXTRACTORS[field]}, final_value):\n",
        "                        print(\"final value\", final_value)\n",
        "                        extracted[field] = final_value\n",
        "                    else:\n",
        "                        print(\"final value failed validate\")\n",
        "                        continue\n",
        "                except Exception as inner_e:\n",
        "                    print(f\"âš ï¸ Field extraction failed for '{field}': {inner_e}\")\n",
        "                    continue\n",
        "\n",
        "            return True, extracted if extracted else {}\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"âš ï¸ extract_fields failed: {e}\")\n",
        "            return False, {}\n",
        "\n",
        "\n",
        "    # ------------ SECTION GENERATION ------------ #\n",
        "    def create_sections(\n",
        "        self, shop_name: str, shop_type: str, aggregate: str,\n",
        "        approved_sections: list[str], city: str | None = None, state: str | None = None\n",
        "    ) -> tuple[bool, dict]:\n",
        "        def _generate(section: str, prompt: str) -> str | None:\n",
        "            raw = self._run4(prompt).strip()\n",
        "            if self.validate_section_html(shop_name, section, raw):\n",
        "                print(\"validated\")\n",
        "                return raw\n",
        "            fixed = self.fix_section_html(shop_name, section, raw)\n",
        "            print(\"fixed html\", fixed)\n",
        "\n",
        "            return fixed if fixed and self.validate_section_html(shop_name, section, fixed) else None\n",
        "\n",
        "        location = f\"in {city}, {state}\" if city or state else \"\"\n",
        "        base_instr = (\n",
        "            f\"You are writing for nearestdoor.com about our listing, about the {shop_type} '{shop_name}' {location}. \"\n",
        "            f\"You will get a summary of this place and write useful information according to your assignment which consumers will read as you write it on the nearestdoor.com website listing page for {shop_name}, no bad info or bad formatting. Urls will be https://example.com formatted.\"\n",
        "            \"Be factual, SEO-friendly, help the users learn use this place and learn about it. no unrelated info, no HTML and no asterisks. NO ASTERISKS, NO **, nothing else, nothing before or after our content. DO NOT USE * \"\n",
        "        )\n",
        "\n",
        "        sections = {}\n",
        "        try:\n",
        "            print(\"approved sections\", approved_sections)\n",
        "            if \"article\" in approved_sections:\n",
        "                prompt = f\"{base_instr}\\n\\nContent:\\n{aggregate}\\n\\nAssignment: Write a detailed article. DO NOT USE ASTERISKS, DO NOT USE * OR **. Write an article about {shop_name} for nearestdoor.com.\"\n",
        "                result = _generate(\"article\", prompt)\n",
        "\n",
        "                if result:\n",
        "                    print(\"article\", result)\n",
        "                    sections[\"article\"] = result\n",
        "\n",
        "            if \"faq\" in approved_sections:\n",
        "                prompt = f\"{base_instr}\\n\\nContent:\\n{aggregate}\\n\\nAssignment: Write a detailed FAQ. DO NOT USE ASTERISKS, DO NOT USE * OR **. Write an FAQ about {shop_name} for nearestdoor.com.\"\n",
        "                result = _generate(\"faq\", prompt)\n",
        "                if result:\n",
        "                    print(\"faq\", result)\n",
        "                    sections[\"faq\"] = result\n",
        "\n",
        "            if \"history\" in approved_sections:\n",
        "                prompt = f\"{base_instr}\\n\\nContent:\\n{aggregate}\\n\\nAssignment: DO NOT USE ASTERISKS. DO NOT USE * OR **. Write the history section about {shop_name} for nearestdoor.com.\"\n",
        "                result = _generate(\"history\", prompt)\n",
        "                if result:\n",
        "                    print(\"history\", result)\n",
        "                    sections[\"history\"] = result\n",
        "\n",
        "            return True, sections\n",
        "        except Exception as e:\n",
        "            print(f\"âŒ create_sections error: {e}\")\n",
        "            return False, {}\n",
        "\n",
        "    # ------------ FULL WORKFLOW ------------ #\n",
        "    def process(\n",
        "        self, shop_name: str, shop_type: str, aggregate: str,\n",
        "        city: str | None = None, state: str | None = None\n",
        "    ) -> dict:\n",
        "        result = {\"plan\": [], \"sections\": {}, \"fields\": {}}\n",
        "        print(\"got aggregate checking quality\", aggregate)\n",
        "        if not self.check_aggregate_quality(shop_name, aggregate, shop_type, city, state):\n",
        "            print(\"âŒ Aggregate failed quality check.\")\n",
        "            return None\n",
        "        print(\"making plan\")\n",
        "        ok, plan = self.create_plan(aggregate, shop_name, shop_type, city, state)\n",
        "        if not ok or not plan:\n",
        "            print(\"âŒ No sections can be created.\")\n",
        "            return None\n",
        "        print(\"plan\", plan)\n",
        "        result[\"plan\"] = plan\n",
        "        print(\"making sections\")\n",
        "        ok, sections = self.create_sections(shop_name, shop_type, aggregate, city, state)\n",
        "        if ok:\n",
        "            result[\"sections\"] = sections\n",
        "        print('sections', sections)\n",
        "        print(\"making fields\")\n",
        "        ok, available = self.extract_available_fields(aggregate, shop_name, shop_type, city, state)\n",
        "        print(\"avaliabale\", available)\n",
        "        if ok and available:\n",
        "            print(\"making fields\")\n",
        "            ok, fields = self.extract_fields(aggregate, available,shop_name, shop_type,city, state)\n",
        "\n",
        "            if ok:\n",
        "                print(\"fields\", fields)\n",
        "                result[\"fields\"] = fields\n",
        "\n",
        "        return result\n",
        "\n",
        "import re\n",
        "import json\n",
        "\n",
        "\n",
        "def is_non_empty_string(value) -> bool:\n",
        "    return isinstance(value, str) and len(value.strip()) > 0\n",
        "\n",
        "def is_valid_json(value) -> bool:\n",
        "    if isinstance(value, (dict, list)):\n",
        "        return True\n",
        "    try:\n",
        "        json.loads(value)\n",
        "        return True\n",
        "    except Exception:\n",
        "        return False\n",
        "\n",
        "def is_valid_phone(value) -> bool:\n",
        "    if not isinstance(value, str):\n",
        "        return False\n",
        "    return bool(re.fullmatch(r\"\\d{3}-\\d{3}-\\d{4}\", value.strip()))\n",
        "\n",
        "def is_valid_email(value) -> bool:\n",
        "    if not isinstance(value, str):\n",
        "        return False\n",
        "    return bool(re.fullmatch(r\"[^@\\s]+@[^@\\s]+\\.[a-zA-Z0-9]+\", value.strip()))\n",
        "\n",
        "def is_valid_url(value) -> bool:\n",
        "    return isinstance(value, str) and value.strip().lower().startswith(\"http\")\n",
        "\n",
        "def is_valid_dict(value) -> bool:\n",
        "    if isinstance(value, dict):\n",
        "        return True\n",
        "    try:\n",
        "        return isinstance(json.loads(value), dict)\n",
        "    except Exception:\n",
        "        return False\n",
        "\n",
        "def is_valid_list(value) -> bool:\n",
        "    if isinstance(value, list):\n",
        "        return True\n",
        "    try:\n",
        "        return isinstance(json.loads(value), list)\n",
        "    except Exception:\n",
        "        return False\n",
        "\n",
        "def is_positive_integer_or_string(value) -> bool:\n",
        "    try:\n",
        "        return int(str(value).strip()) > 0\n",
        "    except Exception:\n",
        "        return False\n",
        "\n",
        "\n",
        "FIELD_VALIDATORS = {\n",
        "    # Contact Info\n",
        "    \"extract_phone\": is_valid_phone,\n",
        "    \"extract_email\": is_valid_email,\n",
        "    \"extract_website\": is_valid_url,\n",
        "\n",
        "    # Structured Fields\n",
        "    \"extract_categories\": is_valid_list,\n",
        "    \"extract_operating_hours\": is_valid_dict,\n",
        "    \"extract_holiday_hours\": is_valid_dict,\n",
        "    \"extract_delivery_services\": is_valid_list,\n",
        "    \"extract_social_media\": is_valid_dict,\n",
        "    \"extract_stocked_brands\": is_valid_list,\n",
        "    \"extract_inventory_categories\": is_valid_dict,\n",
        "    \"extract_customer_reviews\": is_valid_list,\n",
        "\n",
        "    # Event / Misc\n",
        "    \"extract_admission\": is_non_empty_string,\n",
        "    \"extract_date_available\": is_non_empty_string,\n",
        "    \"extract_attendance_amount\": is_positive_integer_or_string,\n",
        "    \"extract_exhibitor_amount\": is_positive_integer_or_string,\n",
        "}\n",
        "FIELD_EXTRACTORS = {\n",
        "    # Contact Information\n",
        "    \"extract_phone\": (\n",
        "        \"Extract ONLY the phone number in this format: 727-237-2132. \"\n",
        "        \"Return ONLY the number, no quotes, no text, no comments, no markup.\"\n",
        "    ),\n",
        "    \"extract_email\": (\n",
        "        \"Extract ONLY the email address. Example: example@mail.com. \"\n",
        "        \"Return ONLY the email address, no quotes, no text, no extras.\"\n",
        "    ),\n",
        "    \"extract_website\": (\n",
        "        \"Extract ONLY the official website URL. Must be the offical url for this business/place or return none. Example: https://website.com. \"\n",
        "        \"Return ONLY the URL, no quotes, no text, no markup.\"\n",
        "    ),\n",
        "\n",
        "    # JSON / Structured Fields\n",
        "    \"extract_categories\": (\n",
        "        \"Extract ONLY the SHORT product/service categories in JSON list format. \"\n",
        "        \"Example: ['Thrift Store', 'Charity']. Return ONLY the JSON array.\"\n",
        "    ),\n",
        "    \"extract_operating_hours\": (\n",
        "        \"Extract ONLY weekly operating hours in JSON dictionary format. \"\n",
        "        \"Example: {'monday': '9:00 AM - 5:00 PM', 'sunday': 'Closed'}. \"\n",
        "        \"Return ONLY the JSON object.\"\n",
        "    ),\n",
        "    \"extract_holiday_hours\": (\n",
        "        \"Extract ONLY holiday-specific hours in JSON dictionary format. \"\n",
        "        \"Example: {'2024-12-25': 'Closed', '2024-12-31': '10:00 AM - 4:00 PM'}. \"\n",
        "        \"Return ONLY the JSON object.\"\n",
        "    ),\n",
        "    \"extract_delivery_services\": (\n",
        "        \"Extract ONLY available delivery services in JSON list format. \"\n",
        "        \"Example: ['Uber Eats', 'Self Delivery']. Return ONLY the JSON array.\"\n",
        "    ),\n",
        "    \"extract_social_media\": (\n",
        "        \"Extract ONLY social media links in JSON dictionary format. \"\n",
        "        \"Example: {'facebook': 'https://facebook.com/example', 'instagram': 'https://instagram.com/example'}. \"\n",
        "        \"Return ONLY the JSON object.\"\n",
        "    ),\n",
        "    \"extract_stocked_brands\": (\n",
        "        \"Extract ONLY stocked brands in JSON list format. \"\n",
        "        \"Example: ['Nike', 'Adidas']. Return ONLY the JSON array.\"\n",
        "    ),\n",
        "    \"extract_inventory_categories\": (\n",
        "        \"Extract ONLY inventory categories in JSON dictionary format. \"\n",
        "        \"Example: {'Apparel': ['Shirts', 'Hoodies']}. Return ONLY the JSON object.\"\n",
        "    ),\n",
        "    \"extract_customer_reviews\": (\n",
        "        \"Extract ONLY customer reviews in JSON list format. \"\n",
        "        \"Example: [{'user': 'John', 'comment': 'Great store!', 'rating': 5}]. \"\n",
        "        \"Return ONLY the JSON array.\"\n",
        "    ),\n",
        "\n",
        "    # Event / Scheduling\n",
        "    \"extract_admission\": (\n",
        "        \"Extract ONLY the admission cost or entry fee. Return ONLY the plain text, no prefixes or suffixes.\"\n",
        "    ),\n",
        "    \"extract_date_available\": (\n",
        "        \"Extract ONLY the available date range or date description. \"\n",
        "        \"Example: 'Available from May 1st to June 30th'. Return ONLY the plain text.\"\n",
        "    ),\n",
        "    \"extract_attendance_amount\": (\n",
        "        \"Extract ONLY the expected attendance as a number. Example: 500. Return ONLY the number or numeric string.\"\n",
        "    ),\n",
        "    \"extract_exhibitor_amount\": (\n",
        "        \"Extract ONLY the expected number of exhibitors. Example: 12. Return ONLY the number or numeric string.\"\n",
        "    ),\n",
        "}\n",
        "\n",
        "class NearestDoorClient:\n",
        "    def __init__(self, smartypants, lookup_engine, ollama,  client_id=CLIENT_ID, api_base=API_BASE):\n",
        "        self.client_id = client_id\n",
        "        self.api_base = api_base\n",
        "        self.ollama = ollama\n",
        "        self.lookup_engine = lookup_engine\n",
        "\n",
        "        self.last_heartbeat = 0\n",
        "\n",
        "\n",
        "        self.smartypants = smartypants\n",
        "\n",
        "    def _api_get(self, endpoint, params=None):\n",
        "        try:\n",
        "            print(f\"ðŸ“¡ GET â†’ {endpoint}\")\n",
        "            response = requests.get(f\"{self.api_base}{endpoint}\", params=params or {}, timeout=30)\n",
        "            response.raise_for_status()\n",
        "            return response\n",
        "        except requests.RequestException as e:\n",
        "            print(f\"âŒ GET failed: {e}\")\n",
        "            return None\n",
        "\n",
        "    def _api_post(self, endpoint, data):\n",
        "        try:\n",
        "\n",
        "            print(f\"ðŸ“¡ POST â†’ {endpoint} {data}\")\n",
        "            response = requests.post(f\"{self.api_base}{endpoint}\", json=data, timeout=30)\n",
        "            response.raise_for_status()\n",
        "            return response\n",
        "        except requests.RequestException as e:\n",
        "            print(f\"âŒ POST failed: {e}\")\n",
        "            return None\n",
        "\n",
        "    def get_task(self):\n",
        "        res = self._api_get(\"/next-task\", params={\"client_id\": self.client_id})\n",
        "        if res and res.status_code == 200:\n",
        "            task = res.json()\n",
        "            if isinstance(task, dict) and \"task_id\" in task:\n",
        "                return task\n",
        "            print(f\"âš ï¸ Invalid task structure received: {task}\")\n",
        "        return None\n",
        "\n",
        "    def send_heartbeat(self, current_task_id=None):\n",
        "        data = {\"client_id\": self.client_id}\n",
        "        if current_task_id:\n",
        "            data[\"task_id\"] = current_task_id\n",
        "        self._api_post(\"/heartbeat\", data)\n",
        "        print(\"ðŸ«€ Heartbeat sent.\")\n",
        "\n",
        "    async def handle_task(self, task):\n",
        "        task_id =task.get(\"task_id\")\n",
        "        task_type =task.get(\"task_type\")\n",
        "        if not task_id or not task_type:\n",
        "            print(\"âŒ Invalid task format.\")\n",
        "            return\n",
        "\n",
        "        print(f\"â–¶ï¸ Handling task {task_type} (ID: {task_id})\")\n",
        "\n",
        "        result, summary, mainstring, images = False, None, None, None\n",
        "        aggregateplan, createdinfo, extractedfields, foundfields = None, None, None, None\n",
        "        print(task)\n",
        "        name = task['target'].get(\"name\")\n",
        "\n",
        "        slug = task['target'].get(\"slug\")\n",
        "        city = task['target'].get(\"city\")\n",
        "        state = task['target'].get(\"state\")\n",
        "\n",
        "        print(\"SHOP SLUG\",{city}, {state}, {slug})\n",
        "        website_url = task['target'].get(\"website\", None)\n",
        "\n",
        "        shop_type = task['target'].get(\"shop_type\")\n",
        "        aggregate = task['target'].get(\"aggregate\", \"\")\n",
        "        plan = task['target'].get(\"plan\", [])\n",
        "        fields = task['target'].get(\"fields\", [])\n",
        "        if task_type != 'search':\n",
        "          print(\"AGGREGATE\", aggregate)\n",
        "        match task_type:\n",
        "            case \"search\":\n",
        "                result, mainstring, images = await self.lookup_engine.combined_search(name, city, state, shop_type, website_url)\n",
        "                result = str(result)\n",
        "\n",
        "            case \"aggregate\":\n",
        "\n",
        "                summarizer = ContentSummarizer(self.ollama, name, shop_type, city, state)\n",
        "                summary, result = summarizer.summarize_content(aggregate)\n",
        "\n",
        "\n",
        "            case \"createplan\":\n",
        "                if aggregate != '':\n",
        "                  print(\"creating plan\", aggregate)\n",
        "                  result, aggregateplan = self.smartypants.create_plan(aggregate, name, shop_type, city, state)\n",
        "                  print(\"plan\", aggregateplan)\n",
        "                else:\n",
        "                  print(\"NONE create plan\")\n",
        "                  result = False\n",
        "                  aggregateplan = []\n",
        "            case \"create\":\n",
        "                if aggregate != '':\n",
        "                  print(\"creating\", aggregate)\n",
        "                  result, createdinfo = self.smartypants.create_sections(name, shop_type, aggregate, plan, city, state)\n",
        "                  print(\"created\", createdinfo)\n",
        "                else:\n",
        "                  print(\"NONE created info\")\n",
        "                  result = False\n",
        "                  createdinfo = []\n",
        "            case \"find_available_fields\":\n",
        "                print(\"finding fields\", aggregate)\n",
        "                if aggregate != '':\n",
        "                  result, foundfields = self.smartypants.extract_available_fields(aggregate, name, shop_type, city, state)\n",
        "                else:\n",
        "\n",
        "                  print(\"NONE AGGREGATE FINDfIELDS\")\n",
        "                  result = False\n",
        "                  foundfields = []\n",
        "                print(\"fields\", foundfields)\n",
        "            case \"extract_fields_from_aggregate\":\n",
        "                print(\"extracting fields\", aggregate)\n",
        "                if aggregate != '':\n",
        "\n",
        "                  result, extractedfields = self.smartypants.extract_fields(aggregate, fields, name, shop_type, city, state)\n",
        "                else:\n",
        "                  print(\"NONE AGGREGATE EXTRACTFIELDS\")\n",
        "                  result = False\n",
        "                  extractedfields = {}\n",
        "                print(\"extracted\", extractedfields)\n",
        "            case _:\n",
        "                print(f\"âŒ Unknown task type: {task_type}\")\n",
        "                return\n",
        "        if result:\n",
        "                print(f\"ðŸ“¤ Submitting result for {task_type} ({task_id})\")\n",
        "                try:\n",
        "                    if task_type == 'search':\n",
        "                        res = self._api_post(f\"/submit/{task_id}\", {\"status\": \"success\", \"mainstring\": mainstring, \"client_id\": CLIENT_ID})\n",
        "\n",
        "                    if task_type == 'aggregate':\n",
        "                        if summary:\n",
        "                            res = self._api_post(f\"/submit/{task_id}\", {\"status\": \"success\", \"summary\": summary, \"client_id\": CLIENT_ID})\n",
        "                        else:\n",
        "                            print(\"nosummary\")\n",
        "                            res = self._api_post(f\"/submit/{task_id}\", {\"status\": \"fail\", \"client_id\": CLIENT_ID})\n",
        "\n",
        "\n",
        "                    if task_type == 'createplan':\n",
        "                        res = self._api_post(f\"/submit/{task_id}\", {\"status\": \"success\", \"aggregateplan\": aggregateplan, \"client_id\": CLIENT_ID})\n",
        "                    if task_type == 'create':\n",
        "                        res = self._api_post(f\"/submit/{task_id}\", {\"status\": \"success\", \"createdinfo\":createdinfo, \"client_id\": CLIENT_ID})\n",
        "                    if task_type == 'find_available_fields':\n",
        "\n",
        "                        res = self._api_post(f\"/submit/{task_id}\", {\"status\": \"success\", \"foundfields\": foundfields, \"client_id\": CLIENT_ID})\n",
        "                    if task_type == 'extract_fields_from_aggregate':\n",
        "                        res = self._api_post(f\"/submit/{task_id}\", {\"status\": \"success\", \"extractedfields\": extractedfields, \"client_id\": CLIENT_ID})\n",
        "\n",
        "                    print(f\"Server responded: {res.status_code} - {res.text}\")\n",
        "                    if res:\n",
        "                      if res.status_code == 200:\n",
        "                          print(f\"âœ… Submitted: {task_type}\")\n",
        "                      else:\n",
        "                          print(f\"âŒ Submit failed: {task_type} - {res.status_code}\")\n",
        "                    else:\n",
        "                      print(f\"âŒ Submit failedd: {task_type} - {res.status_code}\")\n",
        "                except Exception as e:\n",
        "                    print(f\"Submit exception: {e}\")\n",
        "        else:\n",
        "\n",
        "            print(f\"Submit Failure {task_type}\")\n",
        "            res = self._api_post(f\"/submit/{task_id}\", {\"status\": \"fail\", \"client_id\": CLIENT_ID})\n",
        "\n",
        "            if res:\n",
        "                if res.status_code == 200:\n",
        "                          print(f\"failed: {task_type}\")\n",
        "                else:\n",
        "                          print(f\"âŒ couldnt failed: {task_type} - {res.status_code}\")\n",
        "            else:\n",
        "                print(\"NO RES\")\n",
        "\n",
        "    async def run(self):\n",
        "\n",
        "\n",
        "        try:\n",
        "            while True:\n",
        "                task = self.get_task()\n",
        "                if task:\n",
        "                    now = time.time()\n",
        "                    if now - self.last_heartbeat > HEARTBEAT_INTERVAL:\n",
        "                        self.send_heartbeat(task.get(\"task_id\"))\n",
        "                        self.last_heartbeat = now\n",
        "                    await self.handle_task(task)\n",
        "                else:\n",
        "                    print(\"â³ No task available, sleeping...\")\n",
        "                    await asyncio.sleep(10)\n",
        "        finally:\n",
        "            print(\"main error\")\n",
        "if __name__ == \"__main__\":\n",
        "    import sys\n",
        "    import asyncio\n",
        "    import nest_asyncio\n",
        "\n",
        "    nest_asyncio.apply()\n",
        "\n",
        "    ollama = OllamaRunner()\n",
        "    smartypants = Smartypants(ollama)\n",
        "    lookup_engine = LookupEngine( ollama)  # Proper initialization\n",
        "\n",
        "    async def main():\n",
        "\n",
        "        client = NearestDoorClient(smartypants, lookup_engine, ollama)\n",
        "        await client.run()\n",
        "\n",
        "    try:\n",
        "\n",
        "        asyncio.run(main())\n",
        "    except KeyboardInterrupt:\n",
        "        print(\"\\nðŸ›‘ Shutting down gracefully...\")\n",
        "        sys.exit(0)"
      ],
      "metadata": {
        "id": "g-2rqy_rMlo7",
        "outputId": "1b1ec52e-b554-4c0f-faaa-91cbea4050c8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nohup: appending output to 'nohup.out'\n",
            "ðŸ“¡ GET â†’ /next-task\n",
            "ðŸ“¡ POST â†’ /heartbeat {'client_id': 'client001', 'task_id': 31199}\n",
            "ðŸ«€ Heartbeat sent.\n",
            "â–¶ï¸ Handling task search (ID: 31199)\n",
            "{'task_id': 31199, 'task_type': 'search', 'object_type': 'shop', 'data': {}, 'target': {'id': 31396, 'name': 'Swansea dog park (at melvin price memorial park)', 'city': 'Swansea', 'state': 'Illinois', 'website': None, 'slug': 'swansea-dog-park-at-melvin-price-memorial-park', 'shop_type': 'Dog Park'}}\n",
            "SHOP SLUG {'Swansea'} {'Illinois'} {'swansea-dog-park-at-melvin-price-memorial-park'}\n",
            "ðŸŒ Starting combined searchâ€¦\n",
            "ðŸ”Ž Google search â†’ Swansea dog park (at melvin price memorial park) Swansea Illinois Dog Park \n",
            "dd\n",
            "ddf\n",
            "bfd\n",
            "ddd\n",
            "/search?num=12 url canidate\n",
            "https://www.swanseail.org/2204/Dog-Park url canidate\n"
          ]
        }
      ]
    }
  ]
}